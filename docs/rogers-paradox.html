<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Rogers’ Paradox | Individual-based models of cultural evolution</title>
  <meta name="description" content="Chapter 8 Rogers’ Paradox | Individual-based models of cultural evolution" />
  <meta name="generator" content="bookdown 0.21.4 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Rogers’ Paradox | Individual-based models of cultural evolution" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Rogers’ Paradox | Individual-based models of cultural evolution" />
  
  
  

<meta name="author" content="Alberto Acerbi" />
<meta name="author" content="Marco Smolla" />
<meta name="author" content="Alex Mesoudi" />


<meta name="date" content="2020-11-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-traits-models.html"/>
<link rel="next" href="rogers-paradox-a-solution.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Individual-based models of cultural evolution</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#aim-of-the-book"><i class="fa fa-check"></i>Aim of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-cultural-evolution"><i class="fa fa-check"></i>What is cultural evolution?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-model"><i class="fa fa-check"></i>Why model?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-individual-based-models"><i class="fa fa-check"></i>Why individual-based models?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book---the-programming"><i class="fa fa-check"></i>How to use this book - the programming</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book---the-simulations"><i class="fa fa-check"></i>How to use this book - the simulations</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions-and-formatting"><i class="fa fa-check"></i>Conventions and formatting</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#further-reading"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="part"><span><b>Basics</b></span></li>
<li class="chapter" data-level="1" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html"><i class="fa fa-check"></i><b>1</b> Unbiased transmission</a><ul>
<li class="chapter" data-level="1.1" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#initialising-the-simulation"><i class="fa fa-check"></i><b>1.1</b> Initialising the simulation</a></li>
<li class="chapter" data-level="1.2" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#execute-generation-turn-over-many-times"><i class="fa fa-check"></i><b>1.2</b> Execute generation turn-over many times</a></li>
<li class="chapter" data-level="1.3" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#plotting-the-model-results"><i class="fa fa-check"></i><b>1.3</b> Plotting the model results</a></li>
<li class="chapter" data-level="1.4" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#write-a-function-to-wrap-the-model-code"><i class="fa fa-check"></i><b>1.4</b> Write a function to wrap the model code</a></li>
<li class="chapter" data-level="1.5" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#run-several-independent-simulations-and-plot-their-results"><i class="fa fa-check"></i><b>1.5</b> Run several independent simulations and plot their results</a></li>
<li class="chapter" data-level="1.6" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#varying-initial-conditions"><i class="fa fa-check"></i><b>1.6</b> Varying initial conditions</a></li>
<li class="chapter" data-level="1.7" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#summary-of-the-model"><i class="fa fa-check"></i><b>1.7</b> Summary of the model</a></li>
<li class="chapter" data-level="1.8" data-path="unbiased-transmission.html"><a href="unbiased-transmission.html#further-reading-1"><i class="fa fa-check"></i><b>1.8</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="unbiased-and-biased-mutation.html"><a href="unbiased-and-biased-mutation.html"><i class="fa fa-check"></i><b>2</b> Unbiased and biased mutation</a><ul>
<li class="chapter" data-level="2.1" data-path="unbiased-and-biased-mutation.html"><a href="unbiased-and-biased-mutation.html#unbiased-mutation"><i class="fa fa-check"></i><b>2.1</b> Unbiased mutation</a></li>
<li class="chapter" data-level="2.2" data-path="unbiased-and-biased-mutation.html"><a href="unbiased-and-biased-mutation.html#biased-mutation"><i class="fa fa-check"></i><b>2.2</b> Biased mutation</a></li>
<li class="chapter" data-level="2.3" data-path="unbiased-and-biased-mutation.html"><a href="unbiased-and-biased-mutation.html#summary-of-the-model-1"><i class="fa fa-check"></i><b>2.3</b> Summary of the model</a></li>
<li class="chapter" data-level="2.4" data-path="unbiased-and-biased-mutation.html"><a href="unbiased-and-biased-mutation.html#further-reading-2"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="biased-transmission-direct-bias.html"><a href="biased-transmission-direct-bias.html"><i class="fa fa-check"></i><b>3</b> Biased transmission: direct bias</a><ul>
<li class="chapter" data-level="3.1" data-path="biased-transmission-direct-bias.html"><a href="biased-transmission-direct-bias.html#a-simple-model-of-directly-biased-transmission"><i class="fa fa-check"></i><b>3.1</b> A simple model of directly biased transmission</a></li>
<li class="chapter" data-level="3.2" data-path="biased-transmission-direct-bias.html"><a href="biased-transmission-direct-bias.html#strength-of-selection"><i class="fa fa-check"></i><b>3.2</b> Strength of selection</a></li>
<li class="chapter" data-level="3.3" data-path="biased-transmission-direct-bias.html"><a href="biased-transmission-direct-bias.html#summary-of-the-model-2"><i class="fa fa-check"></i><b>3.3</b> Summary of the model</a></li>
<li class="chapter" data-level="3.4" data-path="biased-transmission-direct-bias.html"><a href="biased-transmission-direct-bias.html#further-reading-3"><i class="fa fa-check"></i><b>3.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="biased-transmission-frequency-dependent-indirect-bias.html"><a href="biased-transmission-frequency-dependent-indirect-bias.html"><i class="fa fa-check"></i><b>4</b> Biased transmission: frequency-dependent indirect bias</a><ul>
<li class="chapter" data-level="4.1" data-path="biased-transmission-frequency-dependent-indirect-bias.html"><a href="biased-transmission-frequency-dependent-indirect-bias.html#the-logic-of-conformity"><i class="fa fa-check"></i><b>4.1</b> The logic of conformity</a></li>
<li class="chapter" data-level="4.2" data-path="biased-transmission-frequency-dependent-indirect-bias.html"><a href="biased-transmission-frequency-dependent-indirect-bias.html#testing-conformist-transmission"><i class="fa fa-check"></i><b>4.2</b> Testing conformist transmission</a></li>
<li class="chapter" data-level="4.3" data-path="biased-transmission-frequency-dependent-indirect-bias.html"><a href="biased-transmission-frequency-dependent-indirect-bias.html#summary-of-the-model-3"><i class="fa fa-check"></i><b>4.3</b> Summary of the model</a></li>
<li class="chapter" data-level="4.4" data-path="biased-transmission-frequency-dependent-indirect-bias.html"><a href="biased-transmission-frequency-dependent-indirect-bias.html#further-readings"><i class="fa fa-check"></i><b>4.4</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="biased-transmission-demonstrator-based-indirect-bias.html"><a href="biased-transmission-demonstrator-based-indirect-bias.html"><i class="fa fa-check"></i><b>5</b> Biased transmission: demonstrator-based indirect bias</a><ul>
<li class="chapter" data-level="5.1" data-path="biased-transmission-demonstrator-based-indirect-bias.html"><a href="biased-transmission-demonstrator-based-indirect-bias.html#a-simple-demonstrator-bias"><i class="fa fa-check"></i><b>5.1</b> A simple demonstrator bias</a></li>
<li class="chapter" data-level="5.2" data-path="biased-transmission-demonstrator-based-indirect-bias.html"><a href="biased-transmission-demonstrator-based-indirect-bias.html#predicting-the-winning-trait"><i class="fa fa-check"></i><b>5.2</b> Predicting the ‘winning’ trait</a></li>
<li class="chapter" data-level="5.3" data-path="biased-transmission-demonstrator-based-indirect-bias.html"><a href="biased-transmission-demonstrator-based-indirect-bias.html#summary-of-the-model-4"><i class="fa fa-check"></i><b>5.3</b> Summary of the model</a></li>
<li class="chapter" data-level="5.4" data-path="biased-transmission-demonstrator-based-indirect-bias.html"><a href="biased-transmission-demonstrator-based-indirect-bias.html#further-readings-1"><i class="fa fa-check"></i><b>5.4</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vertical-and-horizontal-transmission.html"><a href="vertical-and-horizontal-transmission.html"><i class="fa fa-check"></i><b>6</b> Vertical and horizontal transmission</a><ul>
<li class="chapter" data-level="6.1" data-path="vertical-and-horizontal-transmission.html"><a href="vertical-and-horizontal-transmission.html#vertical-cultural-transmission"><i class="fa fa-check"></i><b>6.1</b> Vertical cultural transmission</a></li>
<li class="chapter" data-level="6.2" data-path="vertical-and-horizontal-transmission.html"><a href="vertical-and-horizontal-transmission.html#horizontal-cultural-transmission"><i class="fa fa-check"></i><b>6.2</b> Horizontal cultural transmission</a></li>
<li class="chapter" data-level="6.3" data-path="vertical-and-horizontal-transmission.html"><a href="vertical-and-horizontal-transmission.html#summary-of-the-model-5"><i class="fa fa-check"></i><b>6.3</b> Summary of the model</a></li>
<li class="chapter" data-level="6.4" data-path="vertical-and-horizontal-transmission.html"><a href="vertical-and-horizontal-transmission.html#further-reading-4"><i class="fa fa-check"></i><b>6.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html"><i class="fa fa-check"></i><b>7</b> Multiple traits models</a><ul>
<li class="chapter" data-level="7.1" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#unbiased-transmission-with-multiple-traits"><i class="fa fa-check"></i><b>7.1</b> Unbiased transmission with multiple traits</a></li>
<li class="chapter" data-level="7.2" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#introducing-innovation"><i class="fa fa-check"></i><b>7.2</b> Introducing innovation</a></li>
<li class="chapter" data-level="7.3" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#optimising-the-code"><i class="fa fa-check"></i><b>7.3</b> Optimising the code</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#the-distribution-of-popularity"><i class="fa fa-check"></i><b>7.4</b> The distribution of popularity</a></li>
<li class="chapter" data-level="7.5" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#summary-of-the-model-6"><i class="fa fa-check"></i><b>7.5</b> Summary of the model</a></li>
<li class="chapter" data-level="7.6" data-path="multiple-traits-models.html"><a href="multiple-traits-models.html#further-readings-2"><i class="fa fa-check"></i><b>7.6</b> Further readings</a></li>
</ul></li>
<li class="part"><span><b>Advanced topics - The evolution of cultural evolution</b></span></li>
<li class="chapter" data-level="8" data-path="rogers-paradox.html"><a href="rogers-paradox.html"><i class="fa fa-check"></i><b>8</b> Rogers’ Paradox</a><ul>
<li class="chapter" data-level="8.1" data-path="rogers-paradox.html"><a href="rogers-paradox.html#modelling-rogers-paradox"><i class="fa fa-check"></i><b>8.1</b> Modelling Rogers’ Paradox</a></li>
<li class="chapter" data-level="8.2" data-path="rogers-paradox.html"><a href="rogers-paradox.html#summary-of-the-model-7"><i class="fa fa-check"></i><b>8.2</b> Summary of the model</a></li>
<li class="chapter" data-level="8.3" data-path="rogers-paradox.html"><a href="rogers-paradox.html#further-reading-5"><i class="fa fa-check"></i><b>8.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rogers-paradox-a-solution.html"><a href="rogers-paradox-a-solution.html"><i class="fa fa-check"></i><b>9</b> Rogers’ Paradox: A Solution</a><ul>
<li class="chapter" data-level="9.1" data-path="rogers-paradox-a-solution.html"><a href="rogers-paradox-a-solution.html#modelling-critical-social-learners"><i class="fa fa-check"></i><b>9.1</b> Modelling critical social learners</a></li>
<li class="chapter" data-level="9.2" data-path="rogers-paradox-a-solution.html"><a href="rogers-paradox-a-solution.html#summary-of-the-model-8"><i class="fa fa-check"></i><b>9.2</b> Summary of the model</a></li>
<li class="chapter" data-level="9.3" data-path="rogers-paradox-a-solution.html"><a href="rogers-paradox-a-solution.html#further-reading-6"><i class="fa fa-check"></i><b>9.3</b> Further reading</a></li>
</ul></li>
<li class="part"><span><b>Advanced topics - Culture and populations</b></span></li>
<li class="chapter" data-level="10" data-path="demography.html"><a href="demography.html"><i class="fa fa-check"></i><b>10</b> Demography</a><ul>
<li class="chapter" data-level="10.1" data-path="demography.html"><a href="demography.html#the-tasmania-case"><i class="fa fa-check"></i><b>10.1</b> The Tasmania Case</a></li>
<li class="chapter" data-level="10.2" data-path="demography.html"><a href="demography.html#modelling-the-tasmania-case"><i class="fa fa-check"></i><b>10.2</b> Modelling the Tasmania Case</a></li>
<li class="chapter" data-level="10.3" data-path="demography.html"><a href="demography.html#calculating-critical-population-sizes-based-on-skill-complexity"><i class="fa fa-check"></i><b>10.3</b> Calculating critical population sizes based on skill complexity</a></li>
<li class="chapter" data-level="10.4" data-path="demography.html"><a href="demography.html#summary-of-the-model-9"><i class="fa fa-check"></i><b>10.4</b> Summary of the model</a></li>
<li class="chapter" data-level="10.5" data-path="demography.html"><a href="demography.html#further-readings-3"><i class="fa fa-check"></i><b>10.5</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="social-network-structure.html"><a href="social-network-structure.html"><i class="fa fa-check"></i><b>11</b> Social network structure</a><ul>
<li class="chapter" data-level="11.1" data-path="social-network-structure.html"><a href="social-network-structure.html#network-basics"><i class="fa fa-check"></i><b>11.1</b> Network basics</a></li>
<li class="chapter" data-level="11.2" data-path="social-network-structure.html"><a href="social-network-structure.html#generating-networks"><i class="fa fa-check"></i><b>11.2</b> Generating networks</a></li>
<li class="chapter" data-level="11.3" data-path="social-network-structure.html"><a href="social-network-structure.html#plotting-networks"><i class="fa fa-check"></i><b>11.3</b> Plotting networks</a><ul>
<li class="chapter" data-level="11.3.1" data-path="social-network-structure.html"><a href="social-network-structure.html#network-layout"><i class="fa fa-check"></i><b>11.3.1</b> Network layout</a></li>
<li class="chapter" data-level="11.3.2" data-path="social-network-structure.html"><a href="social-network-structure.html#network-styling"><i class="fa fa-check"></i><b>11.3.2</b> Network styling</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="social-network-structure.html"><a href="social-network-structure.html#analyse-social-networks"><i class="fa fa-check"></i><b>11.4</b> Analyse social networks</a><ul>
<li class="chapter" data-level="11.4.1" data-path="social-network-structure.html"><a href="social-network-structure.html#network-properties-and-characteristics"><i class="fa fa-check"></i><b>11.4.1</b> Network properties and characteristics</a></li>
<li class="chapter" data-level="11.4.2" data-path="social-network-structure.html"><a href="social-network-structure.html#vertex-properties"><i class="fa fa-check"></i><b>11.4.2</b> Vertex properties</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="social-network-structure.html"><a href="social-network-structure.html#modelling-information-transmission-in-social-networks"><i class="fa fa-check"></i><b>11.5</b> Modelling information transmission in social networks</a><ul>
<li class="chapter" data-level="11.5.1" data-path="social-network-structure.html"><a href="social-network-structure.html#gossip-diffusion-in-networked-populations"><i class="fa fa-check"></i><b>11.5.1</b> Gossip diffusion in networked populations</a></li>
<li class="chapter" data-level="11.5.2" data-path="social-network-structure.html"><a href="social-network-structure.html#complex-versus-simple-contagion-information-transmission"><i class="fa fa-check"></i><b>11.5.2</b> Complex versus simple contagion information transmission</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="social-network-structure.html"><a href="social-network-structure.html#summary-of-the-model-10"><i class="fa fa-check"></i><b>11.6</b> Summary of the model</a></li>
<li class="chapter" data-level="11.7" data-path="social-network-structure.html"><a href="social-network-structure.html#further-reading-7"><i class="fa fa-check"></i><b>11.7</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Individual-based models of cultural evolution</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="rogers-paradox" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Rogers’ Paradox</h1>
<p>The previous chapters all concerned cultural evolutionary dynamics: how different biases and transmission pathways affect the frequency of cultural traits in a population over time. Equally important, though, is to step back and consider where the possibility of culture came from in the first place. That is, we need to also consider the evolution of culture, and the evolution of cultural evolution.</p>
<p>The most basic question we can ask here is why a capacity for social learning (learning from others) evolved, relative to individual learning (learning directly from the environment, on one’s own). An intuitive answer to this question is that social learning is less costly than individual learning. Imagine trying out different foods, some of which may be poisonous. One could try each one, and see if they make you ill. A less risky strategy would be to observe one’s neighbour, and eat what they are eating. Unless they look sickly all the time, this will likely lead to a palatable (and evolutionarily adaptive) choice. Consequently, social learning should increase the mean adaptation of a population.</p>
<p>However, this intuition can be misleading. This was shown in 1988 by Alan Rogers in a now-classic model of the evolution of social learning (<span class="citation">Rogers (<a href="references.html#ref-rogers_does_1988" role="doc-biblioref">1988</a>)</span>). This model is often called “Rogers’ paradox”, because it shows that under certain conditions, social learning does not lead to increased adaptation, even when it is less costly than individual learning. More precisely, the mean fitness of a population containing social learners does not exceed the mean fitness of a population composed entirely of individual learners. Here we will recapitulate Rogers’ mathematical model in an individual-based simulation, to see when and why this counter-intuitive result holds.</p>
<div id="modelling-rogers-paradox" class="section level2">
<h2><span class="header-section-number">8.1</span> Modelling Rogers’ Paradox</h2>
<p>In Rogers’ model there are <span class="math inline">\(N\)</span> individuals. Each individual has a fixed learning strategy: they are either an individual learner, or a social learner. Each individual also exhibits a behaviour, which we will represent, as the traits in the <a href="multiple-traits-models.html#multiple-traits-models">previous chapter</a> with an integer (e.g. “5”, or “32”). (“Trait” and “behaviour” are often used interchangeably in cultural evolution literature.) There is also an environmental state, <span class="math inline">\(E\)</span>, which is also represented with an integer. When an individual’s behaviour matches the environment, they receive increased fitness, compared to when it does not match. A match might represent ‘palatable food’, while a mismatch might represent ‘poisonous food’.</p>
<p>In each generation, individual learners directly sample the environment, and have a probability <span class="math inline">\(p\)</span> of acquiring the ‘correct’, adaptive behaviour that matches the environment (and therefore a probability <span class="math inline">\(1-p\)</span> of adopting the incorrect, maladaptive behaviour). Social learners choose a member of the previous generation at random and copy their behaviour, just like for unbiased transmission considered in <a href="unbiased-transmission.html#unbiased-transmission">Chapter 1</a>.</p>
<p>Unlike previous models, we are interested here not in the behaviours or traits, but in how the learning strategies evolve over time. We therefore want to track the proportion of social learners in the population, which we call <span class="math inline">\(p_{SL}\)</span> (with <span class="math inline">\(1-p_{SL}\)</span> being the proportion of individual learners). We assume these strategies are inherited (perhaps genetically, possibly culturally) from parent to offspring, and are affected by the fitness of the bearers of the strategies. Hence we need to specify fitness parameters.</p>
<p>Each individual starts with a baseline fitness, <span class="math inline">\(w\)</span>. This is typically set at 1, to avoid tricky-to-handle negative fitnesses. Individuals who have behaviour that matches the environment receive a fitness boost of <span class="math inline">\(+b\)</span>. Individuals who have behaviour that does not match the environment receive a fitness penalty of <span class="math inline">\(-b\)</span>. Explicit in the above verbal outline is that social learning is less costly than individual learning. Therefore, individual learners receive a fitness cost of <span class="math inline">\(-b*c\)</span>, and social learners receive a fitness cost of <span class="math inline">\(-b*s\)</span>, where <span class="math inline">\(c&gt;s\)</span>. For simplicity, we can set <span class="math inline">\(s=0\)</span> (social learning is free) and set <span class="math inline">\(c&gt;0\)</span>, so we only have to change one parameter.</p>
<p>The fitness of each individual is then totted up based on the above, and the next generation is created. Each individual reproduces in proportion to the fitness of their strategy, relative to other strategies.</p>
<p>We also assume some mutation during reproduction. With probability <span class="math inline">\(\mu\)</span>, the new individual ‘mutates’ to the other learning strategy. Because we are interested here in how social learning evolves from individual learning, we start with a first generation entirely made up of individual learners. Social learning then appears from the second generation onwards via mutation.</p>
<p>Finally, Rogers was interested in the effect of environmental change. Each generation, there is a probability <span class="math inline">\(u\)</span> of the environment changing to a new state. In Rogers’ original model, the environment flipped between the same two states, back and forth. However, this is problematic when environmental change is very fast, because an individual with out-dated behaviour can receive a fitness benefit if the environment flips back to the previous state. Hence we assume that when environments change, they change to a new value never previously experienced by any individual.</p>
<p>This is a complex model but let’s go step by step. First we create and initialise tibbles to store the output and the population of individuals, just like in previous chapters. The output here needs to be big enough to store data from <span class="math inline">\(r_{max}\)</span> runs and <span class="math inline">\(t_{max}\)</span> generations, like before. We then need to create NA placeholders for <span class="math inline">\(p_{SL}\)</span> (the proportion of social learners) and <span class="math inline">\(W\)</span> (the mean population fitness). The <code>population</code> tibble stores the characteristics of the individuals: learning strategy (‘individual’ or ‘social’), behaviour (initially all NA) and fitness (initially all NA). Finally, we initialise the environment <span class="math inline">\(E\)</span> at zero, which will subsequently increment, meaning that the environment changes.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="rogers-paradox.html#cb100-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb100-2"><a href="rogers-paradox.html#cb100-2"></a></span>
<span id="cb100-3"><a href="rogers-paradox.html#cb100-3"></a>N &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb100-4"><a href="rogers-paradox.html#cb100-4"></a>r_max &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb100-5"><a href="rogers-paradox.html#cb100-5"></a>t_max &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb100-6"><a href="rogers-paradox.html#cb100-6"></a></span>
<span id="cb100-7"><a href="rogers-paradox.html#cb100-7"></a><span class="co"># Create the output tibble</span></span>
<span id="cb100-8"><a href="rogers-paradox.html#cb100-8"></a>output &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">generation =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>t_max, r_max), </span>
<span id="cb100-9"><a href="rogers-paradox.html#cb100-9"></a>                 <span class="dt">run =</span> <span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>r_max, <span class="dt">each =</span> t_max)), </span>
<span id="cb100-10"><a href="rogers-paradox.html#cb100-10"></a>                 <span class="dt">p.SL =</span> <span class="kw">as.numeric</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, t_max <span class="op">*</span><span class="st"> </span>r_max)), </span>
<span id="cb100-11"><a href="rogers-paradox.html#cb100-11"></a>                 <span class="dt">W =</span> <span class="kw">as.numeric</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, t_max <span class="op">*</span><span class="st"> </span>r_max)))</span>
<span id="cb100-12"><a href="rogers-paradox.html#cb100-12"></a></span>
<span id="cb100-13"><a href="rogers-paradox.html#cb100-13"></a><span class="co"># Create the population tibble</span></span>
<span id="cb100-14"><a href="rogers-paradox.html#cb100-14"></a>population &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">learning =</span> <span class="kw">rep</span>(<span class="st">&quot;individual&quot;</span>, N), </span>
<span id="cb100-15"><a href="rogers-paradox.html#cb100-15"></a>                     <span class="dt">behaviour =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, N), </span>
<span id="cb100-16"><a href="rogers-paradox.html#cb100-16"></a>                     <span class="dt">fitness =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, N))</span>
<span id="cb100-17"><a href="rogers-paradox.html#cb100-17"></a></span>
<span id="cb100-18"><a href="rogers-paradox.html#cb100-18"></a><span class="co"># Initialise the environmental state to 0</span></span>
<span id="cb100-19"><a href="rogers-paradox.html#cb100-19"></a>E &lt;-<span class="st"> </span><span class="dv">0</span></span></code></pre></div>
<p>Now let’s go through each event that happens during a single generation. Later we will put it all inside a loop. It’s useful to write out the events that we need:</p>
<ol style="list-style-type: decimal">
<li>Social learning</li>
<li>Individual learning</li>
<li>Calculate fitnesses</li>
<li>Store population characteristics in output tibble</li>
<li>Reproduction</li>
<li>Potential environmental change</li>
</ol>
<p>First, social learning. The following code picks random individuals from the <code>previous_population</code> tibble (which we have yet to create, but will do later), to put into the social learner individuals in the current <code>population</code> tibble. This is similar to what we did in the previous chapters. It only does this if there is at least one social learner. As noted above, we start in the first generation with all individual learners and no social learners, so this will not be fulfilled until the second generation. For now, nothing happens.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="rogers-paradox.html#cb101-1"></a><span class="cf">if</span> (<span class="kw">sum</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb101-2"><a href="rogers-paradox.html#cb101-2"></a>  population<span class="op">$</span>behaviour[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb101-3"><a href="rogers-paradox.html#cb101-3"></a><span class="st">    </span><span class="kw">sample</span>(previous_population<span class="op">$</span>behaviour, <span class="kw">sum</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb101-4"><a href="rogers-paradox.html#cb101-4"></a>}</span></code></pre></div>
<p>The following code implements individual learning. This <em>does</em> apply to the first generation. We first create a vector of <code>TRUE</code> and <code>FALSE</code> values dependent on <span class="math inline">\(p\)</span>, the probability of individual learning resulting in a correct match with the environment. With this probability, individual learners have their behaviour set to the correct <span class="math inline">\(E\)</span> value. Otherwise, they are given the incorrect behaviour <span class="math inline">\(E-1\)</span>. Note the use of the <code>!</code> before <code>learn_correct</code> to give a match when this vector is <code>FALSE</code> (i.e. they do <em>not</em> learn the correct behaviour).</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="rogers-paradox.html#cb102-1"></a>learn_correct &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), N, <span class="dt">prob =</span> <span class="kw">c</span>(p, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb102-2"><a href="rogers-paradox.html#cb102-2"></a>population<span class="op">$</span>behaviour[learn_correct <span class="op">&amp;</span><span class="st"> </span>population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span>E</span>
<span id="cb102-3"><a href="rogers-paradox.html#cb102-3"></a>population<span class="op">$</span>behaviour[<span class="op">!</span>learn_correct <span class="op">&amp;</span><span class="st"> </span>population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span>E <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span></code></pre></div>
<p>Now we obtain the fitnesses for each individual. First we give everyone the baseline fitness, <span class="math inline">\(w\)</span>. Then we add or subtract <span class="math inline">\(b\)</span>, based on whether the individual has the correct or incorrect behaviour. Finally we impose costs, which are different for social and individual learners.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="rogers-paradox.html#cb103-1"></a><span class="co"># Baseline fitness</span></span>
<span id="cb103-2"><a href="rogers-paradox.html#cb103-2"></a>population<span class="op">$</span>fitness &lt;-<span class="st"> </span>w  </span>
<span id="cb103-3"><a href="rogers-paradox.html#cb103-3"></a></span>
<span id="cb103-4"><a href="rogers-paradox.html#cb103-4"></a><span class="co"># For individuals with behaviour matched to the environment, add b</span></span>
<span id="cb103-5"><a href="rogers-paradox.html#cb103-5"></a>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">==</span><span class="st"> </span>E] &lt;-<span class="st"> </span></span>
<span id="cb103-6"><a href="rogers-paradox.html#cb103-6"></a><span class="st">  </span>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">==</span><span class="st"> </span>E] <span class="op">+</span><span class="st"> </span>b  </span>
<span id="cb103-7"><a href="rogers-paradox.html#cb103-7"></a><span class="co"># For individuals with behaviour not matched to the environment, subtract b</span></span>
<span id="cb103-8"><a href="rogers-paradox.html#cb103-8"></a>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">!=</span><span class="st"> </span>E] &lt;-<span class="st"> </span></span>
<span id="cb103-9"><a href="rogers-paradox.html#cb103-9"></a><span class="st">  </span>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">!=</span><span class="st"> </span>E] <span class="op">-</span><span class="st"> </span>b</span>
<span id="cb103-10"><a href="rogers-paradox.html#cb103-10"></a></span>
<span id="cb103-11"><a href="rogers-paradox.html#cb103-11"></a><span class="co"># Impose cost b*c on individual learners:</span></span>
<span id="cb103-12"><a href="rogers-paradox.html#cb103-12"></a>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb103-13"><a href="rogers-paradox.html#cb103-13"></a><span class="st">  </span>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] <span class="op">-</span><span class="st"> </span>b<span class="op">*</span>c  </span>
<span id="cb103-14"><a href="rogers-paradox.html#cb103-14"></a><span class="co"># Impose cost b*s (i.e. 0) on social learners:</span></span>
<span id="cb103-15"><a href="rogers-paradox.html#cb103-15"></a>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb103-16"><a href="rogers-paradox.html#cb103-16"></a><span class="st">  </span>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] <span class="op">-</span><span class="st"> </span>b<span class="op">*</span>s </span></code></pre></div>
<p>The fourth stage is recording the resulting data into the <code>output</code> tibble. First we calculate <span class="math inline">\(p_{SL}\)</span> as the number of social learners divided by the total population size. Then we calculate <span class="math inline">\(W\)</span>, the mean fitness in the entire population. All of these are done with the standard R mean command.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="rogers-paradox.html#cb104-1"></a>output[output<span class="op">$</span>generation <span class="op">==</span><span class="st"> </span>t <span class="op">&amp;</span><span class="st"> </span>output<span class="op">$</span>run <span class="op">==</span><span class="st"> </span>r, ]<span class="op">$</span>p_SL &lt;-<span class="st"> </span><span class="kw">mean</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>)</span>
<span id="cb104-2"><a href="rogers-paradox.html#cb104-2"></a>output[output<span class="op">$</span>generation <span class="op">==</span><span class="st"> </span>t <span class="op">&amp;</span><span class="st"> </span>output<span class="op">$</span>run <span class="op">==</span><span class="st"> </span>r, ]<span class="op">$</span>W &lt;-<span class="st"> </span><span class="kw">mean</span>(population<span class="op">$</span>fitness)</span></code></pre></div>
<p>The fifth stage is reproduction. Here we put the current <code>population</code> tibble into a new tibble, called <code>previous_population</code>, as we have done before. This acts as both a record to now calculate fitnesses, as well as a source of demonstrators for the social learning stage we covered above. After doing this, we reset the behaviour and fitness of the current population. We then over-write the learning strategies based on fitness.</p>
<p>First we get <code>fitness_IL</code>, the fitness of individual learners relative to the fitness of the entire population (assuming there are any individual learners, otherwise we set this to zero). This then serves as the probability of setting new individuals as individual learners in the next generation. We use gain the function <code>sample()</code> to create <code>mutation</code>, denoting the probability of an individual mutating their learning strategy. Finally, we change the learning strategy of the ‘mutant’ individuals. Notice we need to create a temporary new tibble, <code>previous_poulation2</code>, to avoid to mutate twice the individuals that are changed from <code>individual</code> to <code>social</code> learning in the first mutation instruction.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="rogers-paradox.html#cb105-1"></a>previous_population &lt;-<span class="st"> </span>population</span>
<span id="cb105-2"><a href="rogers-paradox.html#cb105-2"></a>population<span class="op">$</span>behaviour &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb105-3"><a href="rogers-paradox.html#cb105-3"></a>population<span class="op">$</span>fitness &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb105-4"><a href="rogers-paradox.html#cb105-4"></a>      </span>
<span id="cb105-5"><a href="rogers-paradox.html#cb105-5"></a><span class="co"># Relative fitness of individual learners (if there are any)</span></span>
<span id="cb105-6"><a href="rogers-paradox.html#cb105-6"></a><span class="cf">if</span> (<span class="kw">sum</span>(previous_population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb105-7"><a href="rogers-paradox.html#cb105-7"></a>  fitness_IL &lt;-<span class="st"> </span><span class="kw">sum</span>(previous_population<span class="op">$</span>fitness[previous_population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>]) <span class="op">/</span><span class="st"> </span></span>
<span id="cb105-8"><a href="rogers-paradox.html#cb105-8"></a><span class="st">    </span><span class="kw">sum</span>(previous_population<span class="op">$</span>fitness)</span>
<span id="cb105-9"><a href="rogers-paradox.html#cb105-9"></a>} <span class="cf">else</span> {</span>
<span id="cb105-10"><a href="rogers-paradox.html#cb105-10"></a>  fitness_IL &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb105-11"><a href="rogers-paradox.html#cb105-11"></a>}</span>
<span id="cb105-12"><a href="rogers-paradox.html#cb105-12"></a></span>
<span id="cb105-13"><a href="rogers-paradox.html#cb105-13"></a><span class="co"># Create the new population </span></span>
<span id="cb105-14"><a href="rogers-paradox.html#cb105-14"></a>population<span class="op">$</span>learning &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;individual&quot;</span>, <span class="st">&quot;social&quot;</span>), <span class="dt">size =</span> N, </span>
<span id="cb105-15"><a href="rogers-paradox.html#cb105-15"></a>             <span class="dt">prob =</span> <span class="kw">c</span>(fitness_IL, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>fitness_IL), <span class="dt">replace =</span> <span class="ot">TRUE</span>)     </span>
<span id="cb105-16"><a href="rogers-paradox.html#cb105-16"></a></span>
<span id="cb105-17"><a href="rogers-paradox.html#cb105-17"></a><span class="co"># Also add mutation, chance of switching learning types</span></span>
<span id="cb105-18"><a href="rogers-paradox.html#cb105-18"></a>mutation &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), N, <span class="dt">prob =</span> <span class="kw">c</span>(mu, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mu), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb105-19"><a href="rogers-paradox.html#cb105-19"></a></span>
<span id="cb105-20"><a href="rogers-paradox.html#cb105-20"></a><span class="co"># Store current population in a tibble to avoid mutating twice</span></span>
<span id="cb105-21"><a href="rogers-paradox.html#cb105-21"></a>previous_population2 &lt;-<span class="st"> </span>population</span>
<span id="cb105-22"><a href="rogers-paradox.html#cb105-22"></a><span class="co"># If an individual is an individual learner plus mutation, then they&#39;re a social learner</span></span>
<span id="cb105-23"><a href="rogers-paradox.html#cb105-23"></a>population<span class="op">$</span>learning[previous_population2<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span> <span class="op">&amp;</span><span class="st"> </span>mutation] &lt;-<span class="st"> &quot;social&quot;</span>  </span>
<span id="cb105-24"><a href="rogers-paradox.html#cb105-24"></a><span class="co"># If an individual is a social learner plus mutation, then they&#39;re an individual learner</span></span>
<span id="cb105-25"><a href="rogers-paradox.html#cb105-25"></a>population<span class="op">$</span>learning[previous_population2<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span> <span class="op">&amp;</span><span class="st"> </span>mutation] &lt;-<span class="st"> &quot;individual&quot;</span>  </span></code></pre></div>
<p>The final stage is the easiest. With probability <span class="math inline">\(u\)</span>, we increment the environmental state <span class="math inline">\(E\)</span> by one. Otherwise, it stays as it is. To do this we pick a random number between 0 and 1 using the <span class="math inline">\(runif\)</span> command, and if <span class="math inline">\(u\)</span> exceeds this, we increment <span class="math inline">\(E\)</span>.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="rogers-paradox.html#cb106-1"></a><span class="cf">if</span> (<span class="kw">runif</span>(<span class="dv">1</span>) <span class="op">&lt;</span><span class="st"> </span>u) E &lt;-<span class="st"> </span>E <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span></code></pre></div>
<p>That covers the six stages that occur in each generation. We can now put them all together into a loop tracking runs, and a loop tracking generations. We can also put all this inside a function. This should all be familiar from previous chapters. Almost all the code is taken from above, and we numbered the different stages (you can find the comments to the specific lines of codes in the chunks above). We also add a parameter check at the start, to make sure that we don’t get negative fitnesses. This uses the new function <code>stop()</code>, that tells R to terminate the execution of the function, and print on screen the message in the parenthesis. Another novelty is that we already set some of the parameters (<span class="math inline">\(w\)</span>, <span class="math inline">\(b\)</span> and <span class="math inline">\(s\)</span>) in the function call. In this way, the parameters are set to these default values if not specified when the function is called. The other parameters need to be instead specified.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="rogers-paradox.html#cb107-1"></a>rogers_model &lt;-<span class="st"> </span><span class="cf">function</span>(N, t_max, r_max, <span class="dt">w =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="fl">0.5</span>, c, <span class="dt">s =</span> <span class="dv">0</span>, mu, p, u) {</span>
<span id="cb107-2"><a href="rogers-paradox.html#cb107-2"></a>  </span>
<span id="cb107-3"><a href="rogers-paradox.html#cb107-3"></a>  <span class="co"># Check parameters to avoid negative fitnesses</span></span>
<span id="cb107-4"><a href="rogers-paradox.html#cb107-4"></a>  <span class="cf">if</span> (b <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>c) <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span> <span class="op">||</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>s) <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb107-5"><a href="rogers-paradox.html#cb107-5"></a>    <span class="kw">stop</span>(<span class="st">&quot;Invalid parameter values: ensure b*(1+c) &lt; 1 and b*(1+s) &lt; 1&quot;</span>)</span>
<span id="cb107-6"><a href="rogers-paradox.html#cb107-6"></a>  }</span>
<span id="cb107-7"><a href="rogers-paradox.html#cb107-7"></a>  </span>
<span id="cb107-8"><a href="rogers-paradox.html#cb107-8"></a>  <span class="co"># Create output tibble</span></span>
<span id="cb107-9"><a href="rogers-paradox.html#cb107-9"></a>  output &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">generation =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>t_max, r_max), </span>
<span id="cb107-10"><a href="rogers-paradox.html#cb107-10"></a>                   <span class="dt">run =</span> <span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>r_max, <span class="dt">each =</span> t_max)), </span>
<span id="cb107-11"><a href="rogers-paradox.html#cb107-11"></a>                   <span class="dt">p_SL =</span> <span class="kw">as.numeric</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, t_max <span class="op">*</span><span class="st"> </span>r_max)), </span>
<span id="cb107-12"><a href="rogers-paradox.html#cb107-12"></a>                   <span class="dt">W =</span> <span class="kw">as.numeric</span>(<span class="kw">rep</span>(<span class="ot">NA</span>, t_max <span class="op">*</span><span class="st"> </span>r_max)))</span>
<span id="cb107-13"><a href="rogers-paradox.html#cb107-13"></a>  </span>
<span id="cb107-14"><a href="rogers-paradox.html#cb107-14"></a>  <span class="cf">for</span> (r <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r_max) {</span>
<span id="cb107-15"><a href="rogers-paradox.html#cb107-15"></a>    </span>
<span id="cb107-16"><a href="rogers-paradox.html#cb107-16"></a>    <span class="co"># Create a population of individuals</span></span>
<span id="cb107-17"><a href="rogers-paradox.html#cb107-17"></a>    population &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">learning =</span> <span class="kw">rep</span>(<span class="st">&quot;individual&quot;</span>, N), </span>
<span id="cb107-18"><a href="rogers-paradox.html#cb107-18"></a>                         <span class="dt">behaviour =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, N), <span class="dt">fitness =</span> <span class="kw">rep</span>(<span class="ot">NA</span>, N))</span>
<span id="cb107-19"><a href="rogers-paradox.html#cb107-19"></a>    </span>
<span id="cb107-20"><a href="rogers-paradox.html#cb107-20"></a>    <span class="co"># Initialise the environment</span></span>
<span id="cb107-21"><a href="rogers-paradox.html#cb107-21"></a>    E &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb107-22"><a href="rogers-paradox.html#cb107-22"></a>    </span>
<span id="cb107-23"><a href="rogers-paradox.html#cb107-23"></a>    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>t_max) {</span>
<span id="cb107-24"><a href="rogers-paradox.html#cb107-24"></a>      </span>
<span id="cb107-25"><a href="rogers-paradox.html#cb107-25"></a>      <span class="co"># 1. Social learning</span></span>
<span id="cb107-26"><a href="rogers-paradox.html#cb107-26"></a>      <span class="cf">if</span> (<span class="kw">sum</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb107-27"><a href="rogers-paradox.html#cb107-27"></a>        population<span class="op">$</span>behaviour[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb107-28"><a href="rogers-paradox.html#cb107-28"></a><span class="st">          </span><span class="kw">sample</span>(previous_population<span class="op">$</span>behaviour, <span class="kw">sum</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb107-29"><a href="rogers-paradox.html#cb107-29"></a>      }</span>
<span id="cb107-30"><a href="rogers-paradox.html#cb107-30"></a>      </span>
<span id="cb107-31"><a href="rogers-paradox.html#cb107-31"></a>      <span class="co"># 2. individual learning</span></span>
<span id="cb107-32"><a href="rogers-paradox.html#cb107-32"></a>      learn_correct &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), N, <span class="dt">prob =</span> <span class="kw">c</span>(p, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb107-33"><a href="rogers-paradox.html#cb107-33"></a>      population<span class="op">$</span>behaviour[learn_correct <span class="op">&amp;</span><span class="st"> </span>population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span>E</span>
<span id="cb107-34"><a href="rogers-paradox.html#cb107-34"></a>      population<span class="op">$</span>behaviour[<span class="op">!</span>learn_correct <span class="op">&amp;</span><span class="st"> </span>population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span>E <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb107-35"><a href="rogers-paradox.html#cb107-35"></a>      </span>
<span id="cb107-36"><a href="rogers-paradox.html#cb107-36"></a>      <span class="co"># 3. Calculate fitnesses</span></span>
<span id="cb107-37"><a href="rogers-paradox.html#cb107-37"></a>      population<span class="op">$</span>fitness &lt;-<span class="st"> </span>w  </span>
<span id="cb107-38"><a href="rogers-paradox.html#cb107-38"></a>      </span>
<span id="cb107-39"><a href="rogers-paradox.html#cb107-39"></a>      population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">==</span><span class="st"> </span>E] &lt;-<span class="st"> </span></span>
<span id="cb107-40"><a href="rogers-paradox.html#cb107-40"></a><span class="st">        </span>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">==</span><span class="st"> </span>E] <span class="op">+</span><span class="st"> </span>b  </span>
<span id="cb107-41"><a href="rogers-paradox.html#cb107-41"></a>      </span>
<span id="cb107-42"><a href="rogers-paradox.html#cb107-42"></a>      population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">!=</span><span class="st"> </span>E] &lt;-<span class="st"> </span></span>
<span id="cb107-43"><a href="rogers-paradox.html#cb107-43"></a><span class="st">        </span>population<span class="op">$</span>fitness[population<span class="op">$</span>behaviour <span class="op">!=</span><span class="st"> </span>E] <span class="op">-</span><span class="st"> </span>b</span>
<span id="cb107-44"><a href="rogers-paradox.html#cb107-44"></a>      </span>
<span id="cb107-45"><a href="rogers-paradox.html#cb107-45"></a>      population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb107-46"><a href="rogers-paradox.html#cb107-46"></a><span class="st">        </span>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>] <span class="op">-</span><span class="st"> </span>b<span class="op">*</span>c  </span>
<span id="cb107-47"><a href="rogers-paradox.html#cb107-47"></a>      </span>
<span id="cb107-48"><a href="rogers-paradox.html#cb107-48"></a>      population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] &lt;-<span class="st"> </span></span>
<span id="cb107-49"><a href="rogers-paradox.html#cb107-49"></a><span class="st">        </span>population<span class="op">$</span>fitness[population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>] <span class="op">-</span><span class="st"> </span>b<span class="op">*</span>s </span>
<span id="cb107-50"><a href="rogers-paradox.html#cb107-50"></a>      </span>
<span id="cb107-51"><a href="rogers-paradox.html#cb107-51"></a>      <span class="co"># 4. Store population characteristics in output</span></span>
<span id="cb107-52"><a href="rogers-paradox.html#cb107-52"></a>      output[output<span class="op">$</span>generation <span class="op">==</span><span class="st"> </span>t <span class="op">&amp;</span><span class="st"> </span>output<span class="op">$</span>run <span class="op">==</span><span class="st"> </span>r, ]<span class="op">$</span>p_SL &lt;-<span class="st"> </span></span>
<span id="cb107-53"><a href="rogers-paradox.html#cb107-53"></a><span class="st">        </span><span class="kw">mean</span>(population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span>)</span>
<span id="cb107-54"><a href="rogers-paradox.html#cb107-54"></a>      output[output<span class="op">$</span>generation <span class="op">==</span><span class="st"> </span>t <span class="op">&amp;</span><span class="st"> </span>output<span class="op">$</span>run <span class="op">==</span><span class="st"> </span>r, ]<span class="op">$</span>W &lt;-<span class="st"> </span></span>
<span id="cb107-55"><a href="rogers-paradox.html#cb107-55"></a><span class="st">        </span><span class="kw">mean</span>(population<span class="op">$</span>fitness)</span>
<span id="cb107-56"><a href="rogers-paradox.html#cb107-56"></a>      </span>
<span id="cb107-57"><a href="rogers-paradox.html#cb107-57"></a>      <span class="co"># 5. Reproduction</span></span>
<span id="cb107-58"><a href="rogers-paradox.html#cb107-58"></a>      previous_population &lt;-<span class="st"> </span>population</span>
<span id="cb107-59"><a href="rogers-paradox.html#cb107-59"></a>      population<span class="op">$</span>behaviour &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb107-60"><a href="rogers-paradox.html#cb107-60"></a>      population<span class="op">$</span>fitness &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb107-61"><a href="rogers-paradox.html#cb107-61"></a>      </span>
<span id="cb107-62"><a href="rogers-paradox.html#cb107-62"></a>      <span class="cf">if</span> (<span class="kw">sum</span>(previous_population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb107-63"><a href="rogers-paradox.html#cb107-63"></a>        fitness_IL &lt;-<span class="st"> </span><span class="kw">sum</span>(previous_population<span class="op">$</span>fitness[previous_population<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span>]) <span class="op">/</span><span class="st"> </span></span>
<span id="cb107-64"><a href="rogers-paradox.html#cb107-64"></a><span class="st">          </span><span class="kw">sum</span>(previous_population<span class="op">$</span>fitness)</span>
<span id="cb107-65"><a href="rogers-paradox.html#cb107-65"></a>      } <span class="cf">else</span> {</span>
<span id="cb107-66"><a href="rogers-paradox.html#cb107-66"></a>        fitness_IL &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb107-67"><a href="rogers-paradox.html#cb107-67"></a>      }</span>
<span id="cb107-68"><a href="rogers-paradox.html#cb107-68"></a></span>
<span id="cb107-69"><a href="rogers-paradox.html#cb107-69"></a>      population<span class="op">$</span>learning &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;individual&quot;</span>, <span class="st">&quot;social&quot;</span>), <span class="dt">size =</span> N, </span>
<span id="cb107-70"><a href="rogers-paradox.html#cb107-70"></a>             <span class="dt">prob =</span> <span class="kw">c</span>(fitness_IL, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>fitness_IL), <span class="dt">replace =</span> <span class="ot">TRUE</span>)     </span>
<span id="cb107-71"><a href="rogers-paradox.html#cb107-71"></a></span>
<span id="cb107-72"><a href="rogers-paradox.html#cb107-72"></a>      mutation &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>), N, <span class="dt">prob =</span> <span class="kw">c</span>(mu, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mu), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb107-73"><a href="rogers-paradox.html#cb107-73"></a>      </span>
<span id="cb107-74"><a href="rogers-paradox.html#cb107-74"></a>      previous_population2 &lt;-<span class="st"> </span>population</span>
<span id="cb107-75"><a href="rogers-paradox.html#cb107-75"></a>      population<span class="op">$</span>learning[previous_population2<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;individual&quot;</span> <span class="op">&amp;</span><span class="st"> </span>mutation] &lt;-<span class="st"> &quot;social&quot;</span>  </span>
<span id="cb107-76"><a href="rogers-paradox.html#cb107-76"></a>      population<span class="op">$</span>learning[previous_population2<span class="op">$</span>learning <span class="op">==</span><span class="st"> &quot;social&quot;</span> <span class="op">&amp;</span><span class="st"> </span>mutation] &lt;-<span class="st"> &quot;individual&quot;</span>  </span>
<span id="cb107-77"><a href="rogers-paradox.html#cb107-77"></a>      </span>
<span id="cb107-78"><a href="rogers-paradox.html#cb107-78"></a>      <span class="co"># 6. Potential environmental change</span></span>
<span id="cb107-79"><a href="rogers-paradox.html#cb107-79"></a>      <span class="cf">if</span> (<span class="kw">runif</span>(<span class="dv">1</span>) <span class="op">&lt;</span><span class="st"> </span>u) E &lt;-<span class="st"> </span>E <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb107-80"><a href="rogers-paradox.html#cb107-80"></a>      </span>
<span id="cb107-81"><a href="rogers-paradox.html#cb107-81"></a>    }</span>
<span id="cb107-82"><a href="rogers-paradox.html#cb107-82"></a>  }</span>
<span id="cb107-83"><a href="rogers-paradox.html#cb107-83"></a>  <span class="co"># Export data from function</span></span>
<span id="cb107-84"><a href="rogers-paradox.html#cb107-84"></a>  output</span>
<span id="cb107-85"><a href="rogers-paradox.html#cb107-85"></a>}</span></code></pre></div>
<p>Now we can run the simulation for <span class="math inline">\(10\)</span> runs, and <span class="math inline">\(200\)</span> generations, with a population of <span class="math inline">\(1000\)</span> individuals. The other parameters we set are the cost associated to individual learning (<code>c = 0.9</code>); the mutation rate, i.e. the probability that an individual that inherit learning strategy (individual or social) will switch to the other (<code>mu = 0.001</code>); the accuracy of individual learning (<code>p = 1</code>); and, finally, the probability of environmental change (<code>u = 0.2</code>). We will later explore other values of these parameters, but feel free to change them and see what happens!</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="rogers-paradox.html#cb108-1"></a>data_model &lt;-<span class="st"> </span><span class="kw">rogers_model</span>(<span class="dt">N =</span> <span class="dv">1000</span>, <span class="dt">t_max =</span> <span class="dv">200</span>, <span class="dt">r_max =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">mu =</span> <span class="fl">0.01</span>, <span class="dt">p =</span> <span class="dv">1</span>, <span class="dt">u =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<p>You can inspect the <code>data_model</code> tibble, but so much data is hard to make sense of. Let’s write a plotting function like in previous chapters. The only difference from our usual <code>plot_multiple_runs()</code> is that instead of plotting the frequency of traits, we want to visualise <span class="math inline">\(p_{SL}\)</span>, the frequency of social learners, so we</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="rogers-paradox.html#cb109-1"></a>plot_multiple_runs_p_SL &lt;-<span class="st"> </span><span class="cf">function</span>(data_model) {</span>
<span id="cb109-2"><a href="rogers-paradox.html#cb109-2"></a>  <span class="kw">ggplot</span>(<span class="dt">data =</span> data_model, <span class="kw">aes</span>(<span class="dt">y =</span> p_SL, <span class="dt">x =</span> generation)) <span class="op">+</span></span>
<span id="cb109-3"><a href="rogers-paradox.html#cb109-3"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> run)) <span class="op">+</span></span>
<span id="cb109-4"><a href="rogers-paradox.html#cb109-4"></a><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb109-5"><a href="rogers-paradox.html#cb109-5"></a><span class="st">    </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb109-6"><a href="rogers-paradox.html#cb109-6"></a><span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb109-7"><a href="rogers-paradox.html#cb109-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;proportion of social learners&quot;</span>)</span>
<span id="cb109-8"><a href="rogers-paradox.html#cb109-8"></a>}</span>
<span id="cb109-9"><a href="rogers-paradox.html#cb109-9"></a></span>
<span id="cb109-10"><a href="rogers-paradox.html#cb109-10"></a><span class="kw">plot_multiple_runs_p_SL</span>(data_model)</span></code></pre></div>
<div class="figure"><span id="fig:8-10"></span>
<img src="IBM-cultevo_files/figure-html/8-10-1.png" alt="On average the proportion of social learners fluctuates around $0.5$ (black line). However, individual runs have a larger spread around this mean (overlapping colored runs)." width="672" />
<p class="caption">
Figure 8.1: On average the proportion of social learners fluctuates around <span class="math inline">\(0.5\)</span> (black line). However, individual runs have a larger spread around this mean (overlapping colored runs).
</p>
</div>
<p>Here we can see that, for these parameter values, the mean proportion of social learners quickly goes to <span class="math inline">\(0.5\)</span>, but then remains fluctuating around this value. However, each run is quite erratic, with a large spread. More important for our understanding of Rogers’ paradox, however, is the mean fitness of the population, and how this compares with a population entirely composed of individual learners. Consequently, we need to plot the mean population fitness over time. This is <code>W</code> in the output of the <code>rogers_model()</code> function. The function below plots this, along with a dotted line denoting the fitness of an individual learner, which by extension will be the same as the mean fitness of a population entirely composed of individual learners. We do not need to extract this from the output of the simulation: the fitness of individual learners is fixed, known a-priori, and can be calculated knowing the values of some of the parameters of the simulation. There are a few new elements in the plotting functions. First, we want to pass to the function, together with the <code>data_model</code> tibble, some other information on the parameters of out simulations, so that that fitness line for individual learners can be draw. As in the main <code>rogers_model()</code> function, <code>w</code> and <code>b</code> are hard coded, and we need to specify <code>c</code> and <code>p</code>. Second, we use the function <code>geom_hline()</code>. This is another ggplot ‘geom’ that plots, as the name suggest, an horizontal line that intercept the y axis where indicated by <code>yintervept</code>, in our case the fitness of individual learners. Finally, we set the upper limit of the y axis to NA, which ggplot interprets as the limit from the range of the data.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="rogers-paradox.html#cb110-1"></a>plot_W &lt;-<span class="st"> </span><span class="cf">function</span>(data_model, <span class="dt">w =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="fl">0.5</span>, c, p) {</span>
<span id="cb110-2"><a href="rogers-paradox.html#cb110-2"></a>  <span class="kw">ggplot</span>(<span class="dt">data =</span> data_model, <span class="kw">aes</span>(<span class="dt">y =</span> W, <span class="dt">x =</span> generation)) <span class="op">+</span></span>
<span id="cb110-3"><a href="rogers-paradox.html#cb110-3"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> run)) <span class="op">+</span></span>
<span id="cb110-4"><a href="rogers-paradox.html#cb110-4"></a><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb110-5"><a href="rogers-paradox.html#cb110-5"></a><span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> w <span class="op">+</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>p <span class="op">-</span><span class="st"> </span>c <span class="op">-</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb110-6"><a href="rogers-paradox.html#cb110-6"></a><span class="st">    </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="ot">NA</span>)) <span class="op">+</span></span>
<span id="cb110-7"><a href="rogers-paradox.html#cb110-7"></a><span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb110-8"><a href="rogers-paradox.html#cb110-8"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;mean population fitness&quot;</span>)</span>
<span id="cb110-9"><a href="rogers-paradox.html#cb110-9"></a>}</span>
<span id="cb110-10"><a href="rogers-paradox.html#cb110-10"></a></span>
<span id="cb110-11"><a href="rogers-paradox.html#cb110-11"></a><span class="kw">plot_W</span>(data_model, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">p =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:8-11"></span>
<img src="IBM-cultevo_files/figure-html/8-11-1.png" alt="Populations with roughly 50% social learners have on average the same fitness (black line) as populations with only individual learners (dashed line). Even though populations with social learners sometimes exceed the average fitness of all-individual learner populations they also sometimes fall far below it." width="672" />
<p class="caption">
Figure 8.2: Populations with roughly 50% social learners have on average the same fitness (black line) as populations with only individual learners (dashed line). Even though populations with social learners sometimes exceed the average fitness of all-individual learner populations they also sometimes fall far below it.
</p>
</div>
<p>This is Rogers’ paradox. Even though social learning is less costly than individual learning (i.e. <span class="math inline">\(s&lt;c\)</span>), our population of roughly <span class="math inline">\(50\%\)</span> social learners do not consistently exceed the dotted line that indicates the fitness of a population of individual learners. Social learning does not increase adaptation. This also runs counter to the common claim that culture - with social learning at its heart - has been a key driver of our species’ ecological success.</p>
<p>The reason for this result is that social learning is frequency-dependent in a changing environment. Individual learners undergo costly individual learning and discover the correct behaviour, initially doing well. Social learners then copy that behaviour, but at lower cost. Social learners therefore then do better than, and outcompete, individual learners. But when the environment changes, the social learners do badly, because they are left copying outdated behaviour. Individual learners then do better, because they can detect the new environmental state. Individual learners increase in frequency, and the cycle continues. This is what the large oscillations of the single runs show. Analytically, it can be shown that they reach an equilibrium at which the frequency of social and individual learners is the same but, by definition, this equilibrium must have the same mean fitness as a population entirely composed of individual learners. Hence, the ‘paradox’.</p>
<p>To explore this further, we can alter the parameters. First, we can reduce the cost of individual learning, from <span class="math inline">\(c=0.9\)</span> to <span class="math inline">\(c=0.4\)</span>.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="rogers-paradox.html#cb111-1"></a>data_model &lt;-<span class="st"> </span><span class="kw">rogers_model</span>(<span class="dt">N =</span> <span class="dv">1000</span>, <span class="dt">t_max =</span> <span class="dv">200</span>, <span class="dt">r_max =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="fl">0.4</span>, <span class="dt">mu =</span> <span class="fl">0.01</span>, <span class="dt">p =</span> <span class="dv">1</span>, <span class="dt">u =</span> <span class="fl">0.2</span>)</span>
<span id="cb111-2"><a href="rogers-paradox.html#cb111-2"></a><span class="kw">plot_multiple_runs_p_SL</span>(data_model)</span></code></pre></div>
<div class="figure"><span id="fig:8-12"></span>
<img src="IBM-cultevo_files/figure-html/8-12-1.png" alt="There are fewer social learners in a population where the cost of individaul learning is lower." width="672" />
<p class="caption">
Figure 8.3: There are fewer social learners in a population where the cost of individaul learning is lower.
</p>
</div>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="rogers-paradox.html#cb112-1"></a><span class="kw">plot_W</span>(data_model, <span class="dt">c =</span> <span class="fl">0.4</span>, <span class="dt">p =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:8-13"></span>
<img src="IBM-cultevo_files/figure-html/8-13-1.png" alt="The fitness of the mixed population remains equal to the fitness of individual learners in a population where the cost of individaul learning is lower." width="672" />
<p class="caption">
Figure 8.4: The fitness of the mixed population remains equal to the fitness of individual learners in a population where the cost of individaul learning is lower.
</p>
</div>
<p>As we might expect, this reduces the proportion of social learners, by giving individual learners less of a penalty for doing their individual learning. Also as expected, the paradox remains. In fact it is even more obvious, given that there are many more individual learners.</p>
<p>We can also reduce the accuracy of individual learning, reducing <span class="math inline">\(p\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(0.7\)</span>.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="rogers-paradox.html#cb113-1"></a>data_model &lt;-<span class="st"> </span><span class="kw">rogers_model</span>(<span class="dt">N =</span> <span class="dv">1000</span>, <span class="dt">t_max =</span> <span class="dv">200</span>, <span class="dt">r_max =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">mu =</span> <span class="fl">0.01</span>, <span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">u =</span> <span class="fl">0.2</span>)</span>
<span id="cb113-2"><a href="rogers-paradox.html#cb113-2"></a><span class="kw">plot_multiple_runs_p_SL</span>(data_model)</span></code></pre></div>
<div class="figure"><span id="fig:8-14"></span>
<img src="IBM-cultevo_files/figure-html/8-14-1.png" alt="When individual learning is accurate, there are more social learners in populations." width="672" />
<p class="caption">
Figure 8.5: When individual learning is accurate, there are more social learners in populations.
</p>
</div>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="rogers-paradox.html#cb114-1"></a><span class="kw">plot_W</span>(data_model, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">p =</span> <span class="fl">0.7</span>)</span></code></pre></div>
<div class="figure"><span id="fig:8-15"></span>
<img src="IBM-cultevo_files/figure-html/8-15-1.png" alt="Even when individual learning is more accurate, the average fitness of mixed populations is close to the fitness of pure individual learners." width="672" />
<p class="caption">
Figure 8.6: Even when individual learning is more accurate, the average fitness of mixed populations is close to the fitness of pure individual learners.
</p>
</div>
<p>Now there are a majority of social learners. Yet the paradox remains: the mostly social learners still do not really exceed the pure individual learning fitness line.</p>
<p>If our explanation above is correct, then making the environment constant should remove the paradox. If the environment stays the same, then behaviour can never be outdated, and individual learners never regain the upper hand. Setting <span class="math inline">\(u=0\)</span> shows this.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="rogers-paradox.html#cb115-1"></a>data_model &lt;-<span class="st"> </span><span class="kw">rogers_model</span>(<span class="dt">N =</span> <span class="dv">1000</span>, <span class="dt">t_max =</span> <span class="dv">200</span>, <span class="dt">r_max =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">mu =</span> <span class="fl">0.01</span>, <span class="dt">p =</span> <span class="dv">1</span>, <span class="dt">u =</span> <span class="dv">0</span>)</span>
<span id="cb115-2"><a href="rogers-paradox.html#cb115-2"></a><span class="kw">plot_multiple_runs_p_SL</span>(data_model)</span></code></pre></div>
<div class="figure"><span id="fig:8-16"></span>
<img src="IBM-cultevo_files/figure-html/8-16-1.png" alt="When the environment is unchanging, social learners will outperform individual learners and take over in populations." width="672" />
<p class="caption">
Figure 8.7: When the environment is unchanging, social learners will outperform individual learners and take over in populations.
</p>
</div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="rogers-paradox.html#cb116-1"></a><span class="kw">plot_W</span>(data_model, <span class="dt">c =</span> <span class="fl">0.9</span>, <span class="dt">p =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure"><span id="fig:8-17"></span>
<img src="IBM-cultevo_files/figure-html/8-17-1.png" alt="Their average fitness (black line) is now much higher than that of indiviudal learners (dashed line)." width="672" />
<p class="caption">
Figure 8.8: Their average fitness (black line) is now much higher than that of indiviudal learners (dashed line).
</p>
</div>
<p>Now the paradox has disappeared: social learners clearly outperform the individual learners after the latter have gone to the trouble of discovering the correct behaviour, and the social learners have higher mean fitness than the individual learning dotted line. (Notice also the oscillations within each run disappeared.) This is just as we would expect. Rogers’ paradox crucially depends on a changing environment. However, nature rarely provides a constant environment. Food sources change location, technology accumulates, languages diverge, and climates change.</p>
</div>
<div id="summary-of-the-model-7" class="section level2">
<h2><span class="header-section-number">8.2</span> Summary of the model</h2>
<p>Rogers’ model is obviously a gross simplification of reality. However, as discussed in earlier chapters, realism is often not the aim of modelling. Models - even simple and grossly unrealistic ones - force us to think through assumptions, and challenge verbal theorising. Rogers’ model is a good example of this. Even though it sounds reasonable that social learning should increase the mean fitness, or adaptation, of a population, in this simple model with these assumptions it does not. We saw one situation in which social learning <em>does</em> increase mean fitness: when environments do not change. This, however, is not very plausible. Environments always change. We therefore need to examine the other assumptions of Rogers’ model. We will do this in the next chapter.</p>
</div>
<div id="further-reading-5" class="section level2">
<h2><span class="header-section-number">8.3</span> Further reading</h2>
<p>An early example of the claim that social learning is adaptive because it reduces the costs of learning can be found in <span class="citation">Boyd and Richerson (<a href="references.html#ref-boyd_culture_1985" role="doc-biblioref">1985</a>)</span>. <span class="citation">Rogers (<a href="references.html#ref-rogers_does_1988" role="doc-biblioref">1988</a>)</span> then challenged this claim, as we have seen in this chapter. In the next chapter we will consider subsequent models that have examined ‘solutions’ to Rogers’ paradox.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-traits-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="rogers-paradox-a-solution.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IBM-cultevo.pdf", "IBM-cultevo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
