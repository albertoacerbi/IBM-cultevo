[["index.html", "Individual-based models of cultural evolution A step-by-step guide using R Introduction Aim of the book What is cultural evolution? Why model? Why individual-based models? How to use this book - the programming How to use this book - the simulations Conventions and formatting Further reading", " Individual-based models of cultural evolution A step-by-step guide using R Alberto Acerbi Marco Smolla Alex Mesoudi 2020-11-18 Introduction Aim of the book The field of cultural evolution has emerged in the last few decades as a thriving, interdisciplinary effort to understand cultural change and cultural diversity within an evolutionary framework and using evolutionary tools, concepts and methods. Given its roots in evolutionary biology, much of cultural evolution is grounded in, or inspired by, formal models. Yet many researchers interested in cultural evolution come from backgrounds that lack training in formal models, such as psychology, anthropology or archaeology. The aim of this book is to partly address this gap by showing readers how to create individual-based models (IBMs, also known as agent-based models, or ABMs) of cultural evolution. We provide example code written in the programming language R, which has been widely adopted in the scientific community. We will go from very simple models of the basic processes of cultural evolution, such as biased transmission and cultural mutation, to more advanced topics such as the evolution of social learning, demographic effects, and social network analysis. Where possible we recreate existing models in the literature, so that readers can better understand those existing models, and perhaps even extend them to address questions of their own interest. What is cultural evolution? The theory of evolution is typically applied to genetic change. Darwin pointed out that the diversity and complexity of living things can be explained in terms of a deceptively simple process: (1) organisms vary in their characteristics, (2) these characteristics are inherited from parent to offspring, and (3) those characteristics that make an organism more likely to survive and reproduce will tend to increase in frequency over time. That’s pretty much it. Since Darwin, biologists have filled in many of the details of this abstract idea. Geneticists have shown that heritable ‘characteristics’ are determined by genes, and worked out where genetic variation comes from (e.g. mutation, recombination) and how genetic inheritance works (e.g. via Mendel’s laws, and DNA). The details of selection have been explored, revealing the many reasons why some genes spread and others don’t. Others realised that not all biological change results from selection, it can also result from random processes like population bottlenecks (genetic drift). The modern theory of cultural evolution began from the observation that culture constitutes a similar evolutionary process to that outlined above. ‘Culture’ is defined as information that passes from one individual to another socially, rather than genetically. This could include things we colloquially call knowledge, beliefs, ideas, attitudes, customs, words, or values. These are all learned from others via various ‘social learning’ mechanisms such as imitation or spoken/written language. The key point is that social learning is an inheritance system. Cultural characteristics (or cultural traits) vary across individuals, they are passed from individual to individual, and in many cases some traits are more likely to spread than others. This is Darwin’s insight, applied to culture. Cultural evolution researchers think that we can use similar evolutionary concepts, tools and methods to explain the diversity and complexity of culture, just as biologists have done for the diversity and complexity of living forms. The models in this book will help you to understand many of the above principles, by creating simulations of various aspects of cultural evolution. Importantly, we do not need to assume that cultural evolution is identical to genetic evolution. Many of the details will be different. To take an obvious example, we get DNA only from our two parents, but we can get ideas from many sources: teachers, strangers on the internet, long-dead authors’ books, or even our parents. Cultural evolution researchers seek to build models and do research to fill in these details. In the last part of the book we will also explore models that go beyond a strict analogy with biological evolution, and focus on features such as the fact that the ‘rules’ that regulate transmission can themselves culturally evolve, or that other processes than inheritance can create and stabilise culture. Why model? A formal model is a simplified version of reality, written in mathematical equations or computer code. Formal models are useful because reality is complex. We can observe changes in species or cultures over time, or particular patterns of biological or cultural diversity, but there are always a vast array of possible causes for any particular pattern or trend, and huge numbers of variables interacting in many different ways. A formal model is a highly simplified recreation of a small part of this complex reality, containing a few elements or processes that the modeller suspects are important. A model, unlike reality, can be manipulated and probed in order to better understand how each part works. No model is ever a complete recreation of reality. That would be pointless: we would have replaced a complex, incomprehensible reality with a complex, incomprehensible model. Instead, models are useful because of their simplicity. Formal modelling is rare in the social sciences (with some exceptions, such as economics). Social scientists tend to be sceptical that very simple models can tell us anything useful about something as immensely complex as human culture. But the clear lesson from biology is that models are extremely useful in precisely this situation. Biologists face similarly immense complexity in the natural world. Despite this, models are useful. Population genetics models of the early 20th century helped to reconcile new findings in genetics with Darwin’s theory of evolution. Ecological models helped understand interactions between species, such as predator-prey cycles. These models are hugely simplified: population genetics models typically make ridiculous assumptions like infinitely large populations and random mating. But they are useful because they precisely specify each part of a complex system, improving understanding of reality. Another way to look at this is that all social scientists use models, but only some use formal models. Most theories in social sciences are verbal models, written in words. The problem is that words can be imprecise, and verbal models contain all kinds of hidden or unstated assumptions. The advantage of formal modelling is that we are forced to precisely specify every element and process that we propose, and make all of our assumptions explicit. Maths and code do not accept any ambiguity: they must be told absolutely everything. Models can also help to understand the consequences of our theories. Social systems, like many others, are typically under the influence of several different interacting forces. In isolation the effects of these forces can be easy to predict. However, when several forces interact the resulting dynamics quickly become non-trivial. This is the basic idea behind defining these systems as ‘complex’ systems. With verbal descriptions, figuring out the effects of interactions is left to our insights. With formal models, we can set up systems with these forces and observe the dynamics of their interactions. Why individual-based models? There are several different types of formal models. Some models describe the behaviour of a system at the population-level, tracking overall frequencies or other descriptive statistics of traits without explicitly modelling individuals. For example, a model can specify that the frequency of a cultural trait \\(A\\) at time \\(t\\) depends on its frequency at time \\(t-1\\). Perhaps it doubles at each time step. Other models, instead, describe the behaviour of a system at the individual-level, explicitly modelling the individual entities that possess the traits. Imagine the same question, but now we specify that, in a population of \\(N\\) individuals, each individual observes each time a random number of other individuals and, if at least one of them has trait \\(A\\), it copies that trait. Another distinction concerns models that are analytically tractable and models that are not. The former are mathematical models that consist of sets of equations that can be solved to find specific answers (e.g. equilibria points). Our population-level model described above would fit this description. A big advantage of these models is that they can provide insight into the dynamics of a system for a wide range of parameters, or exact results for specific questions. However, this approach requires the studied dynamics to be rather simple. It would be more difficult (or perhaps impossible) to write and analytically solve the systems of equations necessary to describe the behaviours of the single individuals in the second model. Often, when we want or need to describe the behaviour at the individual level - if, for example, individuals differ in their characteristics, exhibit learning or adaptation, or are embedded in social networks - trying to write a system of equations may not be the best strategy. Instead, we need to write code and let the computer program run. These are individual-based models (IBMs). These models are both individual-level (i.e. they specifies the characteristics of the individuals and some rules by which those individuals interact or change over time) and simulations (i.e. they are not solved analytically, but simulated through a computer program). Simulations have greater flexibility than analytical models. Due to their structure they are often more intuitive to understand, especially for people with little training in mathematics. However, it is also important to be aware of their downsides. For example, generalisations are often not possible and statements only hold for parameters (or sets thereof) that have been simulated. Another potential downside is that the high flexibility of simulations can quickly lead to models that are too complex, and it can be hard to understand what is happening inside the model. That’s why, hopefully, our IBMs are simple enough to understand, and provide a gateway into cultural evolution modelling. How to use this book - the programming All of the code in this book is written in R. Originally R had a strong focus on statistical data analysis. Its growing user-base has turned R into a more general-purpose programming language. While R is used less often for modelling, it is widely taught in many university departments and is the subject of lots of online tutorials and support forums. It is quite likely that many readers already have some experience in R for data analysis and visualisation which can be used also for IBMs, more easily than learning another programming language. Also, if your IBMs run in R, you can use the same language to analyse the output and plot the results. We have used the bookdown package to create an html version of the book, which you may well be reading now. This is created from RMarkdown (.Rmd) files, which are a mix of regular text and code. As a reader, you can therefore read the online book and, alongside, run the code using an Rmd file. Of course you can just read the book, but running the code as you go will give you more direct experience of how the code executes, and will allow you to play around with parameters and commands. The best way of learning - especially modelling! - is to try it out yourself. We assume that the reader has basic knowledge of R (and RStudio, which provides a powerful user-interface for R), including installing it, setting it up, updating it, installing packages and running code. We strived to proceed from very simple to more complex code in a gradual way, and to explain all the non-obvious newly introduced programming techniques, but a basic knowledge of R as a programming language, e.g. the use of variables, dataframes, functions, subsetting and loops, will greatly facilitate the reading. We use the tidyverse package and follow the underlying logic. For example, we use the tidyverse-typical data structures (tibbles rather than dataframes) and the ggplot graphic system (rather than the base R plot function). These are user-friendly and widely used, and they will make it easier to manipulate data and create professional-looking visualisations. The tidyverse, however, has not been created with IBMs in mind. We have therefore not religiously stuck to tidyverse, and we also use functions, data structures, and programming styles that go beyond the tidyverse (in chapter seven, for example, we show how matrices are more effective than tibbles in computationally-heavy simulations). Beside the tidyverse package, we have limited as much as possible the number of additional packages needed to run the simulations. The few packages needed to compile some of the code are explicitly introduced in the book when needed. How to use this book - the simulations The book is intended - as the title says - as a step-by-step guide. If you are interested in modelling cultural evolution, or in modelling in general, and you do not have previous experience, you should go through the simulations we describe chapter by chapter. The chapters build in complexity both from the programming and from the conceptual point of view. Alternatively, if you are interested in specific models then you can go straight to the relevant chapter. In this case, however, you will need previous programming experience. (And you will have to figure out by yourself at least some of our programming choices!) The book is organised as follows. We start by presenting IBM versions of some of the now-classic mathematical and population-level models described in the foundational cultural evolution books, such as Robert Boyd and Peter Richerson’s Culture and the Evolutionary Process and Luigi-Luca Cavalli-Sforza and Marc Feldman’s Cultural Transmission and Evolution. The models do not add conceptually to the original analytical treatments, but they show how to use them to develop IBMs, and they provide several basic tools to build models that describe cultural evolution. Some of the subsequent chapters develop aspects that are possible only with IBMs, for example, simulating cultural dynamics with many different traits (chapter seven). We then move to what we call ‘Advanced topics’. These chapters deal with more recent work in cultural evolution and include different perspectives, or they concern analyses that are not customary in cultural evolution modelling (for example network analysis in chapter eleven). The book does not present new models, views or findings on cultural evolution. We are trying to provide as much as possible an up-to-date reflection of the field and, mostly, to show some of the possibilities that IBMs offer to cultural evolutionists. If, while reading this book, you are suddenly struck by an idea for a new model or an alteration of one of the models we present here, we have succeeded in our mission. Conventions and formatting In general, we follow the tidyverse style guide for naming functions and variables, and code formatting. Names of functions and variables use underscores to separate words and lowercase letters, e.g. previous_population, biased_mutation. If in the same chapter we have more than one function for the same model (for example because we gradually add parameters), they are numbered as unbiased_transmission_1(), unbiased_transmission_2(), etc. For the text, we use the following conventions: names of functions and data structures: unbiased_transmission(), population, output technical terms: ‘geoms’, ‘chr’ names of variables: \\(p\\), \\(generation\\) Further reading For some recent general books on cultural evolution, you can check Mesoudi (2011), Morin (2015), Henrich (2016), Laland (2017), and Acerbi (2019). The ‘foundational’ books referred in the test above are Cavalli-Sforza and Feldman (1981) and Boyd and Richerson (1985). For more on the virtues of formal models for social scientists, with a cultural evolution perspective, see Smaldino (2017). Smaldino (2020) is dedicated to good practices to translate verbal theories into formal, especially individual-based, models. A good introduction to R programming is Grolemund (2014). Another general introduction, with a specific focus on the tidyverse logic, is Wickham and Grolemund (2017). "],["unbiased-transmission.html", "Chapter 1 Unbiased transmission 1.1 Initialising the simulation 1.2 Execute generation turn-over many times 1.3 Plotting the model results 1.4 Write a function to wrap the model code 1.5 Run several independent simulations and plot their results 1.6 Varying initial conditions 1.7 Summary of the model 1.8 Further reading", " Chapter 1 Unbiased transmission We start by simulating a simple case of unbiased cultural transmission. We will detail each step of the simulation and explain the code line-by-line. In the following chapters, we will reuse most of this initial model, building up the complexity of our simulations. 1.1 Initialising the simulation Here we will simulate a case where \\(N\\) individuals each possess one of two mutually exclusive cultural traits. These alternative traits are denoted \\(A\\) and \\(B\\). For example, \\(A\\) might be eating a vegetarian diet, and \\(B\\) might be eating a non-vegetarian diet. In reality, traits are seldom clear-cut (e.g. what about pescatarians?), but models are designed to cut away all the complexity to give tractable answers to simplified situations. Our model has non-overlapping generations. In each generation, all \\(N\\) individuals are replaced with \\(N\\) new individuals. Again, this is unlike any real biological group but provides a simple way of simulating change over time. Generations here could correspond to biological generations, but could equally be ‘cultural generations’ (or learning episodes), which might be much shorter. Each new individual of each new generation picks a member of the previous generation at random and copies their cultural trait. This is known as unbiased oblique cultural transmission. ‘Unbiased’ refers to the fact that traits are copied entirely at random. The term ‘oblique’ means that members of one generation learn from those of the previous, non-overlapping, generation. This is different from, for example, horizontal cultural transmission, where individuals copy members of the same generation, and vertical cultural transmission, where offspring copy their biological parents. If we assume that the two cultural traits are transmitted in an unbiased way, what does that mean for the average trait frequency in the population? To answer this question, we must track the proportion of individuals who possess trait \\(A\\) over successive generations. We will call this proportion \\(p\\). We could also track the proportion who possess trait \\(B\\), but this will always be \\(1 - p\\) given that the two traits are mutually exclusive. For example, if \\(70\\%\\) of the population have trait \\(A\\) \\((p=0.7)\\), then the remaining \\(30\\%\\) must have trait \\(B\\) (i.e. \\(1-p=1-0.7=0.3\\)). The output of the model will be a plot showing \\(p\\) over all generations up to the last generation. Generations (or time steps) are denoted by \\(t\\), where generation one is \\(t=1\\), generation two is \\(t=2\\), up to the last generation \\(t=t_{\\text{max}}\\). First, we need to specify the fixed parameters of the model. These are quantities that we decide on at the start and do not change during the simulation. In this model these are N (the number of individuals) and t_max (the number of generations). Let’s start with N = 100 and t_max = 200: N &lt;- 100 t_max &lt;- 200 Now we need to create our individuals. The only information we need to keep about our individuals is their cultural trait (\\(A\\) or \\(B\\)). We’ll call population the data structure containing the individuals. The type of data structure we have chosen here is a tibble. This is a more user-friendly version of a dataframe. Tibbles, and the tibble command, are part of the tidyverse library, which we need to call before creating the tibble. We will use other commands from the tidyverse throughout the book. Initially, we’ll give each individual either an \\(A\\) or \\(B\\) at random, using the sample() command. This can be seen in the code chunk below. The sample() command takes three arguments (i.e. inputs or options). The first argument lists the elements to pick at random, in our case, the traits \\(A\\) and \\(B\\). The second argument gives the number of times to pick, in our case \\(N\\) times, once for each individual. The final argument says to replace or reuse the elements specified in the first argument after they’ve been picked (otherwise there would only be one copy of \\(A\\) and one copy of \\(B\\), so we could only give two individuals traits before running out). Within the tibble command, the word trait denotes the name of the variable within the tibble that contains the random \\(A\\)s and \\(B\\)s, and the whole tibble is assigned the name population. library(tidyverse) population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE)) We can see the cultural traits of our population by simply entering its name in the R console: population ## # A tibble: 100 x 1 ## trait ## &lt;chr&gt; ## 1 A ## 2 A ## 3 A ## 4 B ## 5 A ## 6 B ## 7 B ## 8 A ## 9 A ## 10 B ## # … with 90 more rows As expected, there is a single column called trait containing \\(A\\)s and \\(B\\)s. The type of the column, in this case ‘’ (i.e. character), is reported below the name. A specific individual’s trait can be retrieved using the square bracket notation in R. For example, individual 4’s trait can be retrieved by typing: population$trait[4] ## [1] &quot;B&quot; This should match the fourth row in the table above. We also need a tibble to record the output of our simulation, that is, to track the trait frequency \\(p\\) in each generation. This will have two columns with \\(t_{\\text{max}}\\) rows, one row for each generation. The first column is simply a counter of the generations, from 1 to \\(t_{\\text{max}}\\). This will be useful for plotting the output later. The other column should contain the values of \\(p\\) for each generation. At this stage we don’t know what \\(p\\) will be in each generation, so for now let’s fill the output tibble with lots of NAs, which is R’s symbol for Not Available, or missing value. We can use the rep() (repeat) command to repeat NA \\(t_{\\text{max}}\\) times. We’re using NA rather than, say, zero, because zero could be misinterpreted as \\(p=0\\), which would mean that all individuals have trait \\(B\\). This would be misleading, because at the moment we haven’t yet calculated \\(p\\), so it’s nonexistent, rather than zero. output &lt;- tibble(generation = 1:t_max, p = rep(NA, t_max)) We can, however, fill in the first value of p for our already-created first generation of individuals, held in population. The command below sums the number of \\(A\\)s in population and divides by \\(N\\) to get a proportion out of 1 rather than an absolute number. It then puts this proportion in the first slot of p in output, the one for the first generation, \\(t=1\\). We can again write the name of the tibble, output, to see that it worked. output$p[1] &lt;- sum(population$trait == &quot;A&quot;) / N output ## # A tibble: 200 x 2 ## generation p ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.43 ## 2 2 NA ## 3 3 NA ## 4 4 NA ## 5 5 NA ## 6 6 NA ## 7 7 NA ## 8 8 NA ## 9 9 NA ## 10 10 NA ## # … with 190 more rows This first value of p should be around \\(0.5\\), meaning that around 50 individuals have trait \\(A\\), and 50 have trait \\(B\\). Even though sample() returns either trait with equal probability, this does not necessarily mean that we will get exactly 50 \\(A\\)s and 50 \\(B\\)s. This happens with simulations and finite population sizes: they are probabilistic (or stochastic), not deterministic. Analogously, flipping a coin 100 times will not always give exactly 50 heads and 50 tails. Sometimes we will get 51 heads, sometimes 49, etc. To see this in our simulation, you can re-run all of the above code and you should get a different \\(p\\). 1.2 Execute generation turn-over many times Now that we have built the population, we can simulate what individuals do in each generation. We iterate these actions over \\(t_{\\text{max}}\\) generations. In each generation, we need to: copy the current individuals to a separate tibble called previous_population to use as demonstrators for the new individuals; this allows us to implement oblique transmission with its non-overlapping generations, rather than mixing up the generations create a new generation of individuals, each of whose trait is picked at random from the previous_population tibble calculate \\(p\\) for this new generation and store it in the appropriate slot in output To iterate, we’ll use a for-loop, using t to track the generation. We’ve already done generation 1 so we’ll start at generation 2. The random picking of models is done with sample() again, but this time picking from the traits held in previous_population. Note that we have added comments briefly explaining what each line does. This is perhaps superfluous when the code is this simple, but it’s always good practice. Code often gets cut-and-pasted into other places and loses its context. Explaining what each line does lets other people - and a future, forgetful you - know what’s going on. for (t in 2:t_max) { # Copy the population tibble to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation&#39;s individuals population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Get p and put it into the output slot for this generation t output$p[t] &lt;- sum(population$trait == &quot;A&quot;) / N } Now we should have 200 values of p stored in output, one for each generation. You can list them by typing output, but more effective is to plot them. 1.3 Plotting the model results We use ggplot() to plot our data. The syntax of ggplot may be slightly obscure at first, but it forces us to have a clear picture of the data before plotting. In the first line in the code below, we are telling ggplot that the data we want to plot is in the tibble output. Then, with the command aes() we declare the ‘aesthetics’ of the plot, that is, how we want our data mapped in our plot. In this case, we want the values of p on the y-axis, and the values of generation on the x-axis (this is why earlier we created, in the tibble output, a column to keep the count of generations). We then use geom_line(). In ggplot, ‘geoms’ describe what kind of visual representation should be plotted: lines, bars, boxes and so on. This visual representation is independent of the mapping that we declared before with aes(). The same data, with the same mapping, can be visually represented in many different ways. In this case, we are asking ggplot to represent the data as a line. You can change geom_line() in the code below to geom_point() and see what happens (other geoms have less obvious effects, and we will see some of them in later chapters). The other commands are mainly to make the plot look nicer. We want the y-axis to span all the possible values of \\(p\\), from 0 to 1, and we use a particular ‘theme’ for our plot, in this case, a simple black and white (theme_bw) theme. With the command labs() we can provide a more informative label for the y-axis. ggplot automatically labels the axis with the name of the tibble columns that are plotted: this is good for generation, but less so for p. ggplot(data = output, aes(y = p, x = generation)) + geom_line() + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;p (proportion of individuals with trait A)&quot;) Figure 1.1: Random fluctuations of the proportion of trait A under unbiased cultural transmission The proportion of individuals with trait \\(A\\) should start off hovering around 0.5, and then oscillate randomly (it may, in some cases, also reach 0, meaning that all \\(A\\)s have disappeared, or 1, meaning that all \\(B\\)s have disappeared). Unbiased transmission, or random copying, is by definition random, so different runs of this simulation will generate different plots. If you rerun all the code you will get something different. In all likelihood, \\(p\\) might go to 0 or 1 at some point. At \\(p = 0\\) there are no \\(A\\)s and every individual possesses \\(B\\). At \\(p=1\\) there are no \\(B\\)s and every individual possesses \\(A\\). This is a typical feature of cultural drift, analogous to genetic drift: in small populations, with no selection or other directional processes operating, traits can be lost purely by chance after some generations. 1.4 Write a function to wrap the model code Ideally, we would like to repeat the simulation to explore this idea in more detail, perhaps changing some of the parameters. For example, if we increase \\(N\\), are we more or less likely to lose one of the traits? As noted above, individual-based models like this one are probabilistic or stochastic, thus it is essential to run simulations many times to understand what happens. With our code scattered about in chunks, it is hard to quickly repeat the simulation. Instead, we can wrap it all up in a function: unbiased_transmission_1 &lt;- function(N, t_max) { population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE)) output &lt;- tibble(generation = 1:t_max, p = rep(NA, t_max)) output$p[1] &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Get p and put it into output slot for this generation t output$p[t] &lt;- sum(population$trait == &quot;A&quot;) / N } # Export data from function output } This is just all of the code snippets that we already ran above, but all within a function with parameters \\(N\\) and \\(t_{\\text{max}}\\) as arguments to the function. In addition, unbiased_transmission_1() ends with the line output. This means that this tibble will be exported from the function when it is run. This is useful for storing data from simulations wrapped in functions, otherwise that data is lost after the function is executed. Nothing will happen when you run the above code, because all you have done is define the function and not actually run it. The point is that we can now call the function in one go, easily changing the values of \\(N\\) and \\(t_{\\text{max}}\\). Let’s try first with the same values of \\(N\\) and \\(t_{\\text{max}}\\) as before, and save the output from the simulation into data_model, as a record of what happened. data_model &lt;- unbiased_transmission_1(N = 100, t_max = 200) We also need to create another function to plot the data, so we do not need to rewrite all the plotting instructions each time. Whereas this may seem impractical now, it is convenient to separate the function that runs the simulation and the function that plots the data for various reasons. With more complicated models, we do not want to rerun a simulation just because we want to change some detail in the plot. It also makes conceptual sense to keep separate the raw output of the model from the various ways we can visualise it, or the further analysis we want to perform on it. As above, the code is identical to what we already wrote: plot_single_run &lt;- function(data_model) { ggplot(data = data_model, aes(y = p, x = generation)) + geom_line() + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;p (proportion of individuals with trait A)&quot;) } At this point, we can visualise the results: plot_single_run(data_model) Figure 1.2: Random fluctuations of the proportion of trait A under unbiased cultural transmission As anticipated, the plot is different from the simulation we ran before, even though the code is exactly the same. This is due to the stochastic nature of the simulation. Now let’s try changing the parameters. We can call the simulation and the plotting functions together. The code below reruns and plots the simulation with a much larger \\(N\\). data_model &lt;- unbiased_transmission_1(N = 10000, t_max = 200) plot_single_run(data_model) Figure 1.3: Random fluctuations of the proportion of trait A under unbiased cultural transmission and a large population size You should see much less fluctuation. Rarely in a population of \\(N = 10000\\) will either trait go to fixation. Try re-running the previous code chunk to explore the effect of \\(N\\) on long-term dynamics. 1.5 Run several independent simulations and plot their results Wrapping a simulation in a function like this is good because we can easily re-run it with just a single command. However, it’s a bit laborious to manually re-run it. Say we wanted to re-run the simulation 10 times with the same parameter values to see how many times \\(A\\) goes to fixation, and how many times \\(B\\) goes to fixation. Currently, we’d have to manually run the unbiased_transmission_1() function 10 times and record somewhere else what happened in each run. It would be better to automatically re-run the simulation several times and plot each run as a separate line on the same plot. We could also add a line showing the mean value of \\(p\\) across all runs. Let’s use a new parameter \\(r_{\\text{max}}\\) to specify the number of independent runs, and use another for-loop to cycle over the \\(r_{\\text{max}}\\) runs. Let’s rewrite the unbiased_transmission_1() function to handle multiple runs. We will call the new function unbiased_transmission_2(). unbiased_transmission_2 &lt;- function(N, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) # For each run for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE)) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N # For each generation for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } There are a few changes here. First, we need a different output tibble, because we need to store data for all the runs. For that, we initialise the same generation and p columns as before, but with space for all the runs. generation is now built by repeating the count of each generation \\(r_{\\text{max}}\\) times, and p is NA repeated for all generations, for all runs. We also need a new column called run that keeps track of which run the data in the other two columns belongs to. Note that the definition of run is preceded by as.factor(). This specifies the type of data to put in the run column. We want run to be a ‘factor’ or categorical variable so that, even if runs are labelled with numbers (1, 2, 3…), this should not be misinterpreted as a continuous, real number: there is no sense in which run 2 is twice as ‘runny’ as run 1, or run 3 half as ‘runny’ as run 6. Runs could equally have been labelled using letters, or any other arbitrary scheme. While omitting as.factor() does not make any difference when running the simulation, it would create problems when plotting the data because ggplot would treat runs as continuous real numbers rather than discrete categories (you can see this yourself by modifying the definition of output in the previous code chunk). This is a good example of how it is important to have a clear understanding of your data before trying to plot or analyse them. Going back to the function, we then set up a loop which executes once for each run. The code within this loop is mostly the same as before, except that we now use the [output$generation == t &amp; output$run == r, ] notation to put \\(p\\) into the right place in output. The plotting function is also changed to handle multiple runs: plot_multiple_runs &lt;- function(data_model) { ggplot(data = data_model, aes(y = p, x = generation)) + geom_line(aes(colour = run)) + stat_summary(fun = mean, geom = &quot;line&quot;, size = 1) + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;p (proportion of individuals with trait A)&quot;) } To understand how the above code works, we need to explain the general functioning of ggplot. As explained above, aes() specifies the ‘aesthetics’, or how the data are mapped in the plot. This is independent from the possible visual representations of this mapping, or ‘geoms’. If we declare specific aesthetics when we call ggplot(), these aesthetics will be applied to all geoms we call afterwards. Alternatively, we can specify the aesthetics in the geom itself. For example this: ggplot(data = output, aes(y = p, x = generation)) + geom_line() is equivalent to this: ggplot(data = output) + geom_line(aes(y = p, x = generation)) We can use this property to make more complex plots. The plot created in plot_multiple_runs() has a first geom, geom_line(). This inherits the aesthetics specified in the initial call to ggplot() but also has a new mapping specific to geom_line(), colour = run. This tells ggplot to plot each run line with a different colour. The next command, stat_summary(), calculates the mean of all runs. However, this only inherits the mapping specified in the initial ggplot() call. If in the aesthetic of stat_summary() we had also specified colour = run, it would separate the data by run, and it would calculate the mean of each run. This, though, is just the lines we have already plotted with the geom_line() command. For this reason, we did not put colour = run in the ggplot() call, only in geom_line(). As always, there are various ways to obtain the same result. This code: ggplot(data = output) + geom_line(aes(y = p, x = generation, colour = run)) + stat_summary(aes(y = p, x = generation), fun = mean, geom = &quot;line&quot;, size = 1) is equivalent to the code we wrapped in the function above. However, the original code is clearer, as it distinguishes the global mapping, and the mappings specific to each visual representation. stat_summary() is a generic ggplot function which can be used to plot different statistics to summarise our data. In this case, we want to calculate the mean of the data mapped in \\(y\\), we want to plot them with a line, and we want this line to be thicker than the lines for the single runs. The default line size for geom_line is 0.5, so size = 1 doubles the thickness. Let’s now run the function and plot the results for five runs with the same parameters we used at the beginning (\\(N=100\\) and \\(t_{\\text{max}}=200\\)): data_model &lt;- unbiased_transmission_2(N = 100, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 1.4: Unbiased cultural transmission generates different dynamics in multiple runs You should be able to see five independent runs of our simulation shown as regular thin lines, along with a thicker line showing the mean of these lines. Some runs have probably gone to 0 or 1, and the mean should be somewhere in between. The data is stored in data_model, which we can inspect by writing its name. data_model ## # A tibble: 1,000 x 3 ## generation p run ## &lt;int&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 1 0.53 1 ## 2 2 0.6 1 ## 3 3 0.61 1 ## 4 4 0.63 1 ## 5 5 0.62 1 ## 6 6 0.67 1 ## 7 7 0.6 1 ## 8 8 0.68 1 ## 9 9 0.62 1 ## 10 10 0.59 1 ## # … with 990 more rows Now let’s run the unbiased_transmission_2() model with \\(N = 10000\\), to compare with \\(N = 100\\). data_model &lt;- unbiased_transmission_2(N = 10000, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 1.5: Unbiased cultural transmission generates similar dynamics in multiple runs when population sizes are very large The mean line should be almost exactly at \\(p=0.5\\) now, with the five independent runs fairly close to it. 1.6 Varying initial conditions Let’s add one final modification. So far the starting frequencies of \\(A\\) and \\(B\\) have been the same, roughly 0.5 each. But what if we were to start at different initial frequencies of \\(A\\) and \\(B\\)? Say, \\(p=0.2\\) or \\(p=0.9\\)? Would unbiased transmission keep \\(p\\) at these initial values, or would it go to \\(p=0.5\\) as we have found so far? To find out, we can add another parameter, p_0, which specifies the initial probability of an individual having an \\(A\\) rather than a \\(B\\) in the first generation. Previously this was always p_0 = 0.5, but in the new function below we add it to the sample() function to weight the initial allocation of traits. unbiased_transmission_3 &lt;- function(N, p_0, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) # For each run for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } unbiased_transmission_3() is almost identical to the previous function. The only changes are the addition of \\(p_0\\) as an argument to the function, and the \\(prob\\) argument in the sample() command. The \\(prob\\) argument gives the probability of picking each option, in our case \\(A\\) and \\(B\\), in the first generation. The probability of \\(A\\) is now \\(p_0\\), and the probability of \\(B\\) is now \\(1-p_0\\). We can use the same plotting function as before to visualise the result. Let’s see what happens with a different value of \\(p_0\\), for example \\(p_0=0.2\\). data_model &lt;- unbiased_transmission_3(N = 10000, p_0 = 0.2, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 1.6: Unbiased transmission does not change trait frequencies from the starting conditions, barring random fluctuations With \\(p_0=0.2\\), trait frequencies stay at \\(p=0.2\\). Unbiased transmission is truly non-directional: it maintains trait frequencies at whatever they were in the previous generation, barring random fluctuations caused by small population sizes. 1.7 Summary of the model Even this extremely simple model provides some valuable insights. First, unbiased transmission does not in itself change trait frequencies. As long as populations are large, trait frequencies remain the same. Second, the smaller the population size, the more likely traits are to be lost by chance. This is a basic insight from population genetics, known there as genetic drift, but it can also be applied to cultural evolution. Many studies have tested (and some supported) the idea that population size and other demographic factors can shape cultural diversity. Furthermore, generating expectations about cultural change under simple assumptions like random cultural drift can be useful for detecting non-random patterns like selection. If we don’t have a baseline, we won’t know selection or other directional processes when we see them. We have also introduced several programming techniques that will be useful in later simulations. We have seen how to use tibbles to hold characteristics of individuals and the outputs of simulations, how to use loops to cycle through generations and simulation runs, how to use sample() to pick randomly from sets of elements, how to wrap simulations in functions to easily re-run them with different parameter values, and how to use ggplot() to plot the results of simulations. 1.8 Further reading Cavalli-Sforza and Feldman (1981) explored how cultural drift affects cultural evolution, which was extended by Neiman (1995) in an archaeological context. Bentley, Hahn, and Shennan (2004) present models of unbiased transmission for several cultural datasets. Lansing and Cox (2011) and commentaries explore the underlying assumptions of applying random drift to cultural evolution. "],["unbiased-and-biased-mutation.html", "Chapter 2 Unbiased and biased mutation 2.1 Unbiased mutation 2.2 Biased mutation 2.3 Summary of the model 2.4 Further reading", " Chapter 2 Unbiased and biased mutation Evolution doesn’t work without a source of variation that introduces new variation upon which selection, drift and other processes can act. In genetic evolution, mutation is almost always blind with respect to function. Beneficial genetic mutations are no more likely to arise when they are needed than when they are not needed - in fact, most genetic mutations are neutral or detrimental to an organism. Cultural evolution is more interesting, in that novel variation may sometimes be directed to solve specific problems, or systematically biased due to features of our cognition. In the models below, we’ll simulate both unbiased and biased mutation. 2.1 Unbiased mutation First, we will simulate unbiased mutation in the same basic model as used in the previous chapter. We’ll remove unbiased transmission to see the effect of unbiased mutation alone. As in the previous model, we assume \\(N\\) individuals each of whom possesses one of two discrete cultural traits, denoted \\(A\\) and \\(B\\). In each generation, from \\(t=1\\) to \\(t=t_{\\text{max}}\\), the \\(N\\) individuals are replaced with \\(N\\) new individuals. Instead of random copying, each individual now gives rise to a new individual with the same cultural trait as them. (Another way of looking at this is in terms of timesteps, such as years: the same \\(N\\) individual live for \\(t_{\\text{max}}\\) years and keep their cultural trait from one year to the next.) At each generation, however, there is a probability \\(\\mu\\) that each individual mutates from their current trait to the other trait (the Greek letter Mu is the standard notation for the mutation rate in genetic evolution, and it has an analogous function here). For example, vegetarian individuals can decide to eat animal products, and vice versa. Remember, this is not copied from other individuals, as in the previous model, but can be thought of as an individual decision. Another way to see this is that the probability of changing trait applies to each individual independently; whether an individual mutates has no bearing on whether or how many other individuals have mutated. On average, this means that \\(\\mu N\\) individuals mutate each generation. Like in the previous model, we are interested in tracking the proportion \\(p\\) of agents with trait \\(A\\) over time. We’ll wrap this in a function called unbiased_mutation(), using much of the same code as unbiased_transmission_3(). As before, we need to call the tidyverse library in order to use the tibble command, and later commands like ggplot2. library(tidyverse) unbiased_mutation &lt;- function(N, mu, p_0, t_max, r_max) { # Create the output tibble output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Determine &#39;mutant&#39; individuals mutate &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) # If there are &#39;mutants&#39; from A to B if (nrow(population[mutate &amp; previous_population$trait == &quot;A&quot;, ]) &gt; 0) { # Then flip them to B population[mutate &amp; previous_population$trait == &quot;A&quot;, ]$trait &lt;- &quot;B&quot; } # If there are &#39;mutants&#39; from B to A if (nrow(population[mutate &amp; previous_population$trait == &quot;B&quot;, ]) &gt; 0) { # Then flip them to A population[mutate &amp; previous_population$trait == &quot;B&quot;, ]$trait &lt;- &quot;A&quot; } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } The only changes from the previous model are the addition of mu, the parameter that specifies the probability of mutation, in the function definition and new lines of code within the for loop on t which replace the random copying command with unbiased mutation. Let’s examine these lines to see how they work. The most obvious way of implementing unbiased mutation - which is not done above - would have been to set up another for loop. We would cycle through every individual one by one, each time calculating whether it should mutate or not based on mu. This would certainly work, but R is notoriously slow at loops. It’s always preferable in R, where possible, to use ‘vectorised’ code. That’s what is done above in our three added lines, starting from mutate &lt;- sample(). First, we pre-specify the probability of mutating for each individual. For this, we again use the function sample(), picking TRUE (corresponding to being a mutant) or FALSE (not mutating, i.e. keeping the same cultural trait) for \\(N\\) times. The draw, however, is not random: the probability of drawing TRUE is equal to \\(\\mu\\), and the probability of drawing FALSE is \\(1-\\mu\\). You can think about the procedure in this way: each individual in the population flips a biased coin that has \\(\\mu\\) probability to land on, say, heads, and \\(1-\\mu\\) to land on tails. If it lands on heads they change their cultural trait. In the subsequent lines we change the traits for the ‘mutant’ individuals. We need to check whether there are individuals that change their trait, both from \\(A\\) to \\(B\\) and vice versa, using the two if conditionals. If there are no such individuals, then assigning a new value to an empty tibble returns an error. To avoid this, we make sure that the number of rows is greater than 0 (using nrow()&gt;0 within the if). To plot the results, we can use the same function plot_multiple_runs() we wrote in the previous chapter. Let’s now run and plot the model: data_model &lt;- unbiased_mutation(N = 100, mu = 0.05, p_0 = 0.5, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 2.1: Trait frequencies fluctuate around 0.5 under unbiased mutation Unbiased mutation produces random fluctuations over time and does not alter the overall frequency of \\(A\\), which stays around \\(p=0.5\\). Because mutations from \\(A\\) to \\(B\\) are as equally likely as \\(B\\) to \\(A\\), there is no overall directional trend. If you remember from the previous chapter, with unbiased transmission, when populations were small (e.g. \\(N=100\\)) generally one of the traits disappeared after a few generations. Here, though, with \\(N=100\\), both traits remain until the end of the simulation. Why this difference? You can think of it in this way: when one trait becomes popular, say the frequency of \\(A\\) is equal to \\(0.8\\), with unbiased transmission it is more likely that individuals of the new generation will pick up \\(A\\) randomly when copying. The few individuals with trait \\(B\\) will have 80% probability of copying \\(A\\). With unbiased mutation, on the other hand, since \\(\\mu\\) is applied independently to each individual, when \\(A\\) is common then there will be more individuals that will flip to \\(B\\) (specifically, \\(\\mu p N\\) individuals, which in our case is 4) than individuals that will flip to \\(A\\) (equal to \\(\\mu (1-p) N\\) individuals, in our case 1) keeping the traits at similar frequencies. But what if we were to start at different initial frequencies of \\(A\\) and \\(B\\)? Say, \\(p=0.1\\) and \\(p=0.9\\)? Would \\(A\\) disappear? Would unbiased mutation keep \\(p\\) at these initial values, like we saw unbiased transmission does in Model 1? To find out, let’s change \\(p_0\\), which specifies the initial probability of drawing an \\(A\\) rather than a \\(B\\) in the first generation. data_model &lt;- unbiased_mutation(N = 100, mu = 0.05, p_0 = 0.1, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 2.2: Unbiased mutation causes trait frequencies to converge on 0.5, irrespective of starting frequencies You should see \\(p\\) go from \\(0.1\\) up to \\(0.5\\). In fact, whatever the initial starting frequencies of \\(A\\) and \\(B\\), unbiased mutation always leads to \\(p=0.5\\), for the reason explained above: unbiased mutation always tends to balance the proportion of \\(A\\)s and \\(B\\)s. 2.2 Biased mutation A more interesting case is biased mutation. Let’s assume now that there is a probability \\(\\mu_b\\) that an individual with trait \\(B\\) mutates into \\(A\\), but there is no possibility of trait \\(A\\) mutating into trait \\(B\\). Perhaps trait \\(A\\) is a particularly catchy or memorable version of a story or an intuitive explanation of a phenomenon, and \\(B\\) is difficult to remember or unintuitive to understand. The function biased_mutation() captures this unidirectional mutation. biased_mutation &lt;- function(N, mu_b, p_0, t_max, r_max) { # Create the output tibble output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Determine &#39;mutant&#39; individuals mutate &lt;- sample(c(TRUE, FALSE), N, prob = c(mu_b, 1 - mu_b), replace = TRUE) # If there are &#39;mutants&#39; from B to A if (nrow(population[mutate &amp; previous_population$trait == &quot;B&quot;, ]) &gt; 0) { # Then flip them to A population[mutate &amp; previous_population$trait == &quot;B&quot;, ]$trait &lt;- &quot;A&quot; } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } There are just two changes in this code compared to unbiased_mutation(). First, we’ve replaced mu with mu_b to keep the two parameters distinct and avoid confusion. Second, the line in unbiased_mutation() which caused individuals with \\(A\\) to mutate to \\(B\\) has been deleted. Let’s see what effect this has by running biased_mutation(). We’ll start with the population entirely composed of individuals with \\(B\\), i.e. \\(p_0=0\\), to see how quickly and in what manner \\(A\\) spreads via biased mutation. data_model &lt;- biased_mutation(N = 100, mu_b = 0.05, p_0 = 0, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 2.3: Biased mutation causes the favoured trait to replace the unfavoured trait The plot shows a steep increase that slows and plateaus at \\(p=1\\) by around generation \\(t=100\\). There should be a bit of fluctuation in the different runs, but not much. Now let’s try a larger sample size. data_model &lt;- biased_mutation(N = 10000, mu_b = 0.05, p_0 = 0, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 2.4: Increasing the population size does not change the rate at which biased mutation causes the favoured trait to increase in frequency With \\(N = 10000\\) the line should be smooth with little (if any) fluctuation across the runs. But notice that it plateaus at about the same generation, around \\(t=100\\). Population size has little effect on the rate at which a novel trait spreads via biased mutation. \\(\\mu_b\\), on the other hand, does affect this speed. Let’s double the biased mutation rate to 0.1. data_model &lt;- biased_mutation(N = 10000, mu_b = 0.1, p_0 = 0, t_max = 200, r_max = 5) plot_multiple_runs(data_model) Figure 2.5: Increasing the mutation rate increases the rate at which biased mutation causes the favoured trait to increase in frequency Now trait \\(A\\) reaches fixation around generation \\(t=50\\). Play around with \\(N\\) and \\(\\mu_b\\) to confirm that the latter determines the rate of diffusion of trait \\(A\\), and that it takes the same form each time - roughly an ‘r’ shape with an initial steep increase followed by a plateauing at \\(p=1\\). 2.3 Summary of the model With this simple model, we can draw the following insights. Unbiased mutation, which resembles genetic mutation in being non-directional, always leads to an equal mix of the two traits. It introduces and maintains cultural variation in the population. It is interesting to compare unbiased mutation to unbiased transmission from the previous chapter. While unbiased transmission did not change \\(p\\) over time, unbiased mutation always converges on \\(p=0.5\\), irrespective of the starting frequency. (NB \\(p = 0.5\\) assuming there are two traits; more generally, \\(p=1/v\\), where \\(v\\) is the number of traits.) Biased mutation, which is far more common - perhaps even typical - in cultural evolution, shows different dynamics. Novel traits favoured by biased mutation spread in a characteristic fashion - an r-shaped diffusion curve - with a speed characterised by the mutation rate \\(\\mu_b\\). Population size has little effect, whether \\(N = 100\\) or \\(N = 10000\\). Whenever biased mutation is present (\\(\\mu_b&gt;0\\)), the favoured trait goes to fixation, even if it is not initially present. In terms of programming techniques, the major novelty in this model is the use of sample() to determine which individuals should undergo whatever the fixed probability specifies (in our case, mutation). This could be done with a loop, but vectorising code in the way we did here is much faster in R than loops. 2.4 Further reading Boyd and Richerson (1985) model what they call ‘guided variation’, which is equivalent to biased mutation as modelled in this chapter. Henrich (2001) shows how biased mutation / guided variation generates r-shaped curves similar to those generated here. "],["biased-transmission-direct-bias.html", "Chapter 3 Biased transmission: direct bias 3.1 A simple model of directly biased transmission 3.2 Strength of selection 3.3 Summary of the model 3.4 Further reading", " Chapter 3 Biased transmission: direct bias So far we have looked at unbiased transmission (Chapter 1) and mutation, both unbiased and biased (Chapter 2). Let’s complete the set by looking at biased transmission. This occurs when one trait is more likely to be copied than another trait. When the choice depends on the features of the trait, it is often called ‘direct’ or ‘content’ bias. When the choice depends on features of the demonstrators (the individuals from whom one is copying), it is often called ‘indirect’ or ‘context’ bias. Both are sometimes also called ‘cultural selection’ because one trait is selected to be copied over another trait. In this chapter, we will look at trait-based (direct, content) bias. (As an aside, there is a confusing array of terminology in the field of cultural evolution, as illustrated by the preceding paragraph. That’s why models are so useful. Words and verbal descriptions can be ambiguous. Often the writer doesn’t realise that there are hidden assumptions or unrecognised ambiguities in their descriptions. They may not realise that what they mean by ‘cultural selection’ is entirely different from how someone else uses it. Models are great because they force us to precisely specify exactly what we mean by a particular term or process. We can use the words in the paragraph above to describe biased transmission, but it’s only really clear when we model it, making all our assumptions explicit.) 3.1 A simple model of directly biased transmission To simulate biased transmission, following the simulations in Chapter 1, we assume there are two traits \\(A\\) and \\(B\\), and that each individual chooses another individual from the previous generation at random. This time, however, we give the traits two different probabilities of being copied: we can call them \\(s_a\\) and \\(s_b\\) respectively. When an individual encounters another individual with trait \\(A\\), they will copy them with probability \\(s_a\\). When they encounter an individual with trait \\(B\\), they will copy them with probability \\(s_b\\). With \\(s_a=s_b\\), copying is unbiased, and individuals switch to the encountered alternative with the same probability. This reproduces the results of the simulations when the transmission is unbiased. If \\(s_a=s_b=1\\), the model is exactly the same as in Chapter 1. The relevant situation in this chapter is when \\(s_a&gt;s_b\\) (or \\(s_a&lt;s_b\\)) so that we have biased transmission. Perhaps \\(A\\) (or \\(B\\)) is a more effective tool, a more memorable story, or a more easily pronounced word. Let’s first write the function, and then explore what happens in this case. Below is a function biased_transmission_direct() that implements all of these ideas. library(tidyverse) biased_transmission_direct &lt;- function (N, s_a, s_b, p_0, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # For each individual, pick a random individual from the previous generation demonstrator_trait &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Biased probabilities to copy: copy_a &lt;- sample(c(TRUE, FALSE), N, prob = c(s_a, 1 - s_a), replace = TRUE) copy_b &lt;- sample(c(TRUE, FALSE), N, prob = c(s_b, 1 - s_b), replace = TRUE) # If the demonstrator has trait A and the individual wants to copy A, then copy A if (nrow(population[copy_a &amp; demonstrator_trait$trait == &quot;A&quot;, ]) &gt; 0) { population[copy_a &amp; demonstrator_trait$trait == &quot;A&quot;, ]$trait &lt;- &quot;A&quot; } # If the demonstrator has trait B and the individual wants to copy B, then copy B if (nrow(population[copy_b &amp; demonstrator_trait$trait == &quot;B&quot;, ]) &gt; 0) { population[copy_b &amp; demonstrator_trait$trait == &quot;B&quot;, ]$trait &lt;- &quot;B&quot; } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } Most of biased_transmission_direct() is recycled from the previous models. As before, we initialise the data structure output from multiple runs, and in generation \\(t=1\\), we create a population tibble to hold the trait of each individual. The major change is that we now include biased transmission. We first select at random the demonstrators from the previous generation (using the same code we used in unbiased_transmission()) and we store their trait in demonstrator_trait. Then we get the probabilities for copying \\(A\\) and for copying \\(B\\) for the entire population, using the same code used in biased_mutation(). Again using the same code as in biased mutation(), we have the individuals copy the trait at hand with the desired probability. Let’s run our function biased_transmission_direct(). As before, to plot the results, we can use the function plot_multiple_runs() we wrote in the first chapter. As noted above, the interesting case is when one trait is favoured over the other. We can assume, for example, \\(s_a=0.1\\) and \\(s_b=0\\). This means that when individuals encounter another individual with trait \\(A\\) they copy them 1 out every 10 times, but when individuals encounter another individual with trait \\(B\\), they never switch. We can also assume that the favoured trait, \\(A\\), is initially rare in the population (\\(p_0=0.01\\)) to see how selection favours this initially-rare trait (Note that \\(p_0\\) needs to be higher than 0; since there is no mutation in this model, we need to include at least some \\(A\\)s at the beginning of the simulation, otherwise it would never appear). data_model &lt;- biased_transmission_direct(N = 10000, s_a = 0.1, s_b = 0 , p_0 = 0.01, t_max = 150, r_max = 5) plot_multiple_runs(data_model) Figure 3.1: Biased transmission generates an s-shaped diffusion curve With a moderate selection strength, we can see that \\(A\\) gradually replaces \\(B\\) and goes to fixation. It does this in a characteristic manner: the increase is slow at first, then picks up speed, then plateaus. Note the difference from biased mutation. Where biased mutation was r-shaped, with a steep initial increase, biased transmission is s-shaped, with an initial slow uptake. This is because the strength of biased transmission (like selection in general) is proportional to the variation in the population. When \\(A\\) is rare initially, there is only a small chance of picking another individual with \\(A\\). As \\(A\\) spreads, the chances of picking an \\(A\\) individual increases. As \\(A\\) becomes very common, there are few \\(B\\) individuals left to switch. In the case of biased mutation, instead, the probability of switching is independent of the variation in the population. 3.2 Strength of selection On what does the strength of selection depend? First, the strength is independent of the specific values of \\(s_a\\) and \\(s_b\\). What counts is their relative difference, which in the above case is \\(s_a-s_b = 0.1\\). If we run a simulation with, say, \\(s_a=0.6\\) and \\(s_b=0.5\\), we see the same pattern, albeit with slightly more noise. That is, the single runs are more different from one another compared to the previous simulation. This is because switches from \\(A\\) to \\(B\\) are now also possible. data_model &lt;- biased_transmission_direct(N = 10000, s_a = 0.6, s_b = 0.5 , p_0 = 0.01, t_max = 150, r_max = 5) plot_multiple_runs(data_model) Figure 3.2: Biased transmission depends on the relative difference between the transmission parameters of each trait To change the selection strength, we need to modify the difference between \\(s_a\\) and \\(s_b\\). We can double the strength by setting \\(s_a = 0.2\\), and keeping \\(s_b=0\\). data_model &lt;- biased_transmission_direct(N = 10000, s_a = 0.2, s_b = 0 , p_0 = 0.01, t_max = 150, r_max = 5) plot_multiple_runs(data_model) Figure 3.3: Increasing the relative difference between transmission parameters increases the rate at which the favoured trait spreads As we might expect, increasing the strength of selection increases the speed with which \\(A\\) goes to fixation. Note, though, that it retains the s-shape. 3.3 Summary of the model We have seen how biased transmission causes a trait favoured by cultural selection to spread and go to fixation in a population, even when it is initially very rare. Biased transmission differs in its dynamics from biased mutation. Its action is proportional to the variation in the population at the time at which it acts. It is strongest when there is lots of variation (in our model, when there are equal numbers of \\(A\\) and \\(B\\) at \\(p=0.5\\)), and weakest when there is little variation (when \\(p\\) is close to 0 or 1). 3.4 Further reading Boyd and Richerson (1985) modelled direct bias, while Henrich (2001) added directly biased transmission to his guided variation / biased mutation model, showing that this generates s-shaped curves similar to those generated here. Note though that subsequent work has shown that s-shaped curves can be generated via other processes (e.g. Reader (2004)), and should not be considered definite evidence for biased transmission. "],["biased-transmission-frequency-dependent-indirect-bias.html", "Chapter 4 Biased transmission: frequency-dependent indirect bias 4.1 The logic of conformity 4.2 Testing conformist transmission 4.3 Summary of the model 4.4 Further readings", " Chapter 4 Biased transmission: frequency-dependent indirect bias In Chapter 3 we looked at the case where one cultural trait is intrinsically more likely to be copied than another trait. Here we will start looking at the other kind of biased transmission when traits are equivalent, but individuals are more likely to adopt a trait according to the characteristics of the population, and in particular which other individuals already have it. (As we mentioned previously, these are often called ‘indirect’ or ‘context’ biases). 4.1 The logic of conformity A first possibility is that we may be influenced by the frequency of the trait in the population, i.e. how many other individuals already have the trait. Conformity (or ‘positive frequency-dependent bias’) has been most studied. Here, individuals are disproportionately more likely to adopt the most common trait in the population, irrespective of its intrinsic characteristics. (The opposite case, anti-conformity or negative frequency-dependent bias is also possible, where the least common trait is more likely to be copied. This is probably less common in real life.) For example, imagine trait \\(A\\) has a frequency of 0.7 in the population, with the rest possessing trait \\(B\\). An unbiased learner would adopt trait \\(A\\) with a probability exactly equal to 0.7. This is unbiased transmission and is what happens the model described in (Chapter 1: by picking a member of the previous generation at random, the probability of adoption is equal to the frequency of that trait among the previous generation. A conformist learner, on the other hand, would adopt trait \\(A\\) with a probability greater than 0.7. In other words, common traits get an ‘adoption boost’ relative to unbiased transmission. Uncommon traits get an equivalent ‘adoption penalty’. The magnitude of this boost or penalty can be controlled by a parameter, which we will call \\(D\\). Let’s keep things simple in our model. Rather than assuming that individuals sample across the entire population, which in any case might be implausible in large populations, let’s assume they pick only three demonstrators at random. Why three? This is the minimum number of demonstrators that can yield a majority (i.e. 2 vs 1), which we need to implement conformity. When two demonstrators have one trait and the other demonstrator has a different trait, we want to boost the probability of adoption for the majority trait, and reduce it for the minority trait. We can specify the probability of adoption as follows: Table 1: Probability of adopting trait \\(A\\) for each possible combination of traits amongst three demonstrators Demonstrator 1 Demonstrator 2 Demonstrator 3 Probability of adopting trait \\(A\\) \\(A\\) \\(A\\) \\(A\\) 1 \\(A\\) \\(A\\) \\(B\\) \\(2/3 + D/3\\) \\(A\\) \\(B\\) \\(A\\) \\(2/3 + D/3\\) \\(B\\) \\(A\\) \\(A\\) \\(2/3 + D/3\\) \\(A\\) \\(B\\) \\(B\\) \\(1/3 - D/3\\) \\(B\\) \\(A\\) \\(B\\) \\(1/3 - D/3\\) \\(B\\) \\(B\\) \\(A\\) \\(1/3 - D/3\\) \\(B\\) \\(B\\) \\(B\\) 0 The first row says that when all demonstrators have trait \\(A\\), then trait \\(A\\) is definitely adopted. Similarly, the bottom row says that when all demonstrators have trait \\(B\\), then trait \\(A\\) is never adopted, and by implication trait \\(B\\) is always adopted. For the three combinations where there are two \\(A\\)s and one \\(B\\), the probability of adopting trait \\(A\\) is \\(2/3\\), which it would be under unbiased transmission (because two out of three demonstrators have \\(A\\)), plus the conformist adoption boost specified by \\(D\\). As we want \\(D\\) to vary from 0 to 1, it is divided by three, so that the maximum probability of adoption is equal to 1 (when \\(D=1\\)). Similarly, for the three combinations where there are two \\(B\\)s and one \\(A\\), the probability of adopting \\(A\\) is \\(1/3\\) minus the conformist adoption penalty specified by \\(D\\). Let’s implement these assumptions in the kind of individual-based model we’ve been building so far. As before, assume \\(N\\) individuals each of whom possesses one of two traits \\(A\\) or \\(B\\). The frequency of \\(A\\) is denoted by \\(p\\). The initial frequency of \\(A\\) in generation \\(t=1\\) is \\(p_0\\). Rather than going straight to a function, let’s go step by step. First, we’ll specify our parameters, \\(N\\) and \\(p_0\\) as before, plus the new conformity parameter \\(D\\). We also create the usual population tibble and fill it with \\(A\\)s and \\(B\\)s in the proportion specified by \\(p_0\\), again exactly as before. library(tidyverse) N &lt;- 100 p_0 &lt;- 0.5 D &lt;- 1 # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) Now we create another tibble called demonstrators that picks, for each new individual in the next generation, three demonstrators at random from the current population of individuals. It therefore needs three columns/variables, one for each of the demonstrators, and \\(N\\) rows, one for each individual. We fill each column with randomly chosen traits from thepopulation tibble. We can have a look at demonstrators by entering its name in the R console. # Create a tibble with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) # Visualise the tibble demonstrators ## # A tibble: 100 x 3 ## dem1 dem2 dem3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 A B A ## 2 B B A ## 3 B A B ## 4 A B B ## 5 A B B ## 6 B B B ## 7 B A A ## 8 B A B ## 9 A B B ## 10 B A A ## # … with 90 more rows Think of each row here as containing the traits of three randomly-chosen demonstrators chosen by each new next-generation individual. Now we want to calculate the probability of adoption of \\(A\\) for each of these three-trait demonstrator combinations. First we need to get the number of \\(A\\)s in each combination. Then we can replace the traits in population based on the probabilities in Table 1. When all demonstrators have \\(A\\), we set to \\(A\\). When no demonstrators have \\(A\\), we set to \\(B\\). When two out of three demonstrators have \\(A\\), we set to \\(A\\) with probability \\(2/3 + D/3\\) and \\(B\\) otherwise. When one out of three demonstrators have \\(A\\), we set to \\(A\\) with probability \\(1/3 - D/3\\) and \\(B\\) otherwise. # Get the number of As in each 3-demonstrator combinations num_As &lt;- rowSums(demonstrators == &quot;A&quot;) # For 3-demonstrator combinations with all As, set to A population$trait[num_As == 3] &lt;- &quot;A&quot; # For 3-demonstrator combinations with all Bs, set to B population$trait[num_As == 0] &lt;- &quot;B&quot; prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # 3-demonstrator combinations with two As and one B if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # 3-demonstrator combinations with one A and two Bs if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } To check it works, we can add the new population tibble as a column to demonstrators and have a look at it. This will let us see the three demonstrators and the resulting new trait side by side. demonstrators &lt;- add_column(demonstrators, new_trait = population$trait) # Visualise the tibble demonstrators ## # A tibble: 100 x 4 ## dem1 dem2 dem3 new_trait ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 A B A A ## 2 B B A B ## 3 B A B B ## 4 A B B B ## 5 A B B B ## 6 B B B B ## 7 B A A A ## 8 B A B B ## 9 A B B B ## 10 B A A A ## # … with 90 more rows Because we set \\(D=1\\) above, the new trait is always the majority trait among the three demonstrators. This is perfect conformity. We can weaken conformity by reducing \\(D\\). Here is an example with \\(D=0.5\\). All the code is the same as what we already discussed above. D &lt;- 0.5 # create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Create a tibble with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) # Get the number of As in each 3-demonstrator combinations num_As &lt;- rowSums(demonstrators == &quot;A&quot;) # For 3-demonstrator combinations with all As, set to A population$trait[num_As == 3] &lt;- &quot;A&quot; # For 3-demonstrator combinations with all Bs, set to B population$trait[num_As == 0] &lt;- &quot;B&quot; prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # 3-demonstrator combinations with two As and one B if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # 3-demonstrator combinations with one A and two Bs if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } demonstrators &lt;- add_column(demonstrators, new_trait = population$trait) # Visualise the tibble demonstrators ## # A tibble: 100 x 4 ## dem1 dem2 dem3 new_trait ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 A B A A ## 2 A B B B ## 3 B A B B ## 4 B A A A ## 5 A B B B ## 6 A A B A ## 7 A B B B ## 8 B A B B ## 9 B B A B ## 10 B B A B ## # … with 90 more rows Now that conformity is weaker, sometimes the new trait is not the majority amongst the three demonstrators. 4.2 Testing conformist transmission As in the previous chapters, we can put all this code together into a function to see what happens over multiple generations and in multiple runs. There is nothing new in the code below, which is a combination of the code we already wrote in (Chapter 1) and the new bits of code for conformity introduced above. conformist_transmission &lt;- function (N, p_0, D, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Create a tibble with a set of 3 randomly-picked demonstrators for each agent demonstrators &lt;- tibble(dem1 = sample(population$trait, N, replace = TRUE), dem2 = sample(population$trait, N, replace = TRUE), dem3 = sample(population$trait, N, replace = TRUE)) # Get the number of As in each 3-demonstrator combinations num_As &lt;- rowSums(demonstrators == &quot;A&quot;) # For 3-demonstrator combinations with all As, set to A population$trait[num_As == 3] &lt;- &quot;A&quot; # For 3-demonstrator combinations with all Bs, set to B population$trait[num_As == 0] &lt;- &quot;B&quot; prob_majority &lt;- sample(c(TRUE, FALSE), prob = c((2/3 + D/3), 1 - (2/3 + D/3)), N, replace = TRUE) prob_minority &lt;- sample(c(TRUE, FALSE), prob = c((1/3 - D/3), 1 - (1/3 - D/3)), N, replace = TRUE) # 3-demonstrator combinations with two As and one B if (nrow(population[prob_majority &amp; num_As == 2, ]) &gt; 0) { population[prob_majority &amp; num_As == 2, ] &lt;- &quot;A&quot; } if (nrow(population[prob_majority == FALSE &amp; num_As == 2, ]) &gt; 0) { population[prob_majority == FALSE &amp; num_As == 2, ] &lt;- &quot;B&quot; } # 3-demonstrator combinations with one A and two Bs if (nrow(population[prob_minority &amp; num_As == 1, ]) &gt; 0) { population[prob_minority &amp; num_As == 1, ] &lt;- &quot;A&quot; } if (nrow(population[prob_minority == FALSE &amp; num_As == 1, ]) &gt; 0) { population[prob_minority == FALSE &amp; num_As == 1, ] &lt;- &quot;B&quot; } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } We can test the function with perfect conformity (\\(D=1\\)) and plot it (again we use the function plot_multiple_runs() we wrote in Chapter 1). data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.5, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Figure 4.1: Conformity causes one trait to spread and replace the other by favouring whichever trait is initially most common Here we should see some lines going to \\(p=1\\), and some lines going to \\(p=0\\). Conformity acts to favour the majority trait. This will depend on the initial frequency of \\(A\\) in the population. In different runs with \\(p_0=0.5\\), sometimes there will be slightly more \\(A\\)s, sometimes slightly more \\(B\\)s (remember, in our model, this is probabilistic, like flipping coins, so initial frequencies will rarely be precisely 0.5). What happens if we set \\(D=0\\)? data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.5, D = 0, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Figure 4.2: Removing conformist bias recreates unbiased transmission, and does not systematically change trait frequencies This model is equivalent to unbiased transmission. As for the simulations described in Chapter 1, with a sufficiently large \\(N\\), the frequencies fluctuate around \\(p=0.5\\). This underlines the effect of conformity. With unbiased transmission, majority traits are favoured because they are copied in proportion to their frequency (incidentally, it is for this reason that ‘copying the majority’ is not a good description of conformity in the technical sense used in the field of cultural evolution: even with unbiased copying the majority trait is copied more than the minority one). However, they reach fixation only in small populations. With conformity, instead, the majority trait is copied with a probability higher than its frequency, so that conformity drives traits to fixation as they become more and more common. As an aside, note that the last two graphs have roughly the same thick black mean frequency line, which hovers around \\(p=0.5\\). This highlights the dangers of looking at means alone. If we hadn’t plotted the individual runs and relied solely on mean frequencies, we might think that \\(D=0\\) and \\(D=1\\) gave identical results. But in fact, they are very different. Always look at the underlying distribution that generates means. Now let’s explore the effect of changing the initial frequencies by changing \\(p_0\\), and adding conformity back in. data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.55, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Figure 4.3: When trait A is always initially in the majority, it is always favoured by conformity When \\(A\\) starts with a slight majority (\\(p_0=0.55\\)), all (or almost all) of the runs result in \\(A\\) going to fixation. Now let’s try the reverse. data_model &lt;- conformist_transmission(N = 1000, p_0 = 0.45, D = 1, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Figure 4.4: When trait B is always initially in the majority, it is always favoured by conformity When \\(A\\) starts off in a minority (\\(p_0=0.45\\)), all (or almost all) of the runs result in \\(A\\) disappearing. These last two graphs show how initial conditions affect conformity. Whichever trait is more common is favoured by conformist transmission. 4.3 Summary of the model In this chapter, we explored conformist biased cultural transmission. This is where individuals are disproportionately more likely to adopt the most common trait among a set of demonstrators. We can contrast this indirect bias with the direct (or content) biased transmission from [Chapter 3][Biased transmission (direct bias)], where one trait is intrinsically more likely to be copied. With conformity, the traits have no intrinsic difference in attractiveness and are preferentially copied simply because they are common. We saw how conformity increases the frequency of whichever trait is more common. Initial trait frequencies are important here: traits that are initially more common typically go to fixation. This, in turn, makes stochasticity important, which in small populations can affect initial frequencies. We also discussed the subtle but fundamental difference between unbiased copying and conformity. In both, majority traits are favoured, but it is only with conformity that they are disproportionately favoured. In large populations, unbiased transmission rarely leads to trait fixation, whereas conformist transmission often does. Furthermore, as we will see later, conformity also makes majority traits resistant to external disturbances, such as the introduction of other traits via innovation or migration. 4.4 Further readings Boyd and Richerson (1985) introduced conformist or positive frequency-dependent cultural transmission as defined here, and modelled it analytically with similar methods. Henrich and Boyd (1998) modelled the evolution of conformist transmission, while Efferson et al. (2008) provided experimental evidence that at least some people conform in a simple learning task. "],["biased-transmission-demonstrator-based-indirect-bias.html", "Chapter 5 Biased transmission: demonstrator-based indirect bias 5.1 A simple demonstrator bias 5.2 Predicting the ‘winning’ trait 5.3 Summary of the model 5.4 Further readings", " Chapter 5 Biased transmission: demonstrator-based indirect bias In the previous two chapters we examined two forms of biased transmission, one where the bias arises due to characteristics of the traits (or direct bias) and another where the bias arises due to the characteristics of the population (or indirect bias). In the previous chapter we examined frequency-dependent indirect bias which takes into account the frequency of the trait (or conformity). Here we examine indirect bias that takes into account specific features of the demonstrators. This demonstrator-based bias is also called ‘model bias’ or ‘context bias’ in the cultural evolution literature. Whereas the simulations we created previously are fairly standard, indirect demonstrator-based biases can be implemented in several ways. Demonstrator biases result whenever individuals decide whether or not to copy by taking into account any features of the demonstrators, as long as it is not directly tied to the traits. The most studied demonstrator bias is prestige bias, where individuals are more likely to copy from demonstrators who are considered more ‘prestigious’ or high in subjective social status, for example because other individuals show deference to them. Alternatively, individuals can copy demonstrators who are more successful according to some objective criterion (e.g. wealth) independently from how others judge them, or they can copy individuals that are more similar to themselves, or older (or younger) than themselves, and so on. The key point is that the decision is not directly linked to the cultural trait itself, and relates to some characteristic of the demonstrator(s) from whom one is copying. 5.1 A simple demonstrator bias To implement a simple version of demonstrator-biased cultural transmission, we first need to assume that there are some intrinsic differences between individuals within the population. Up until now, our individuals have only been described by the traits they possess. We now want individuals to have some additional feature which others can use when deciding whether to copy that individual. We call this feature ‘status’. For simplicity, an individual’s status is a binary variable that could stand for whether they are prestigious or not, successful or not, and so on. We define a parameter \\(p_s\\) that determines the probability that an individual has high status, as opposed to low status. library(tidyverse) N &lt;- 100 p_0 &lt;- 0.5 p_s &lt;- 0.05 population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0)), status = sample(c(&quot;high&quot;, &quot;low&quot;), N, replace = TRUE, prob = c(p_s, 1 - p_s))) We can inspect the tibble by typing its name in the R console population ## # A tibble: 100 x 2 ## trait status ## &lt;chr&gt; &lt;chr&gt; ## 1 A low ## 2 B low ## 3 A high ## 4 A low ## 5 A low ## 6 B low ## 7 B low ## 8 B low ## 9 A low ## 10 B low ## # … with 90 more rows With \\(p_s=0.05\\) around 5 individuals in a population of 100 will have high status. We now need to make it so that these rare high status individuals are more likely to be copied. One way of doing this is to assume that the probabilities of picking high-status and low-status individuals as demonstrators are different. So far, when using the function sample() to select demonstrators, we did not include any specific probability. This meant that each individual of the previous generation had the same likelihood of being selected and copied. Instead, now we pass to the function a vector of probabilities to weight the choice. We assume that the probability if selecting low-status individuals is given by a further parameter, \\(p_\\text{low}\\), that gives the proportion between the probabilities of choosing a low-status individual versus an high-status individual. When \\(p_\\text{low}=1\\), the simulations correspond to unbiased transmission, as everybody has the same probability of being chosen. When \\(p_\\text{low}=0\\), there is a strict status-based demonstrator bias, where only high-status individuals are ever selected as demonstrators. To implement this, we first store in p_demonstrator the probabilities of being copied for each member of the population: p_low &lt;- 0.01 p_demonstrator &lt;- rep(1, N) p_demonstrator[population$status == &quot;low&quot;] &lt;- p_low Then we sample the traits in the population using these probabilities. Notice the condition if(sum(p_demonstrator) &gt; 0). This is necessary in case there are no high-status individuals (for example when \\(p_s\\approx0\\)) and the probability of selecting a low status demonstrator to copy is 0 (\\(p_\\text{low}=0\\)). This would make the overall probability equal to 0, and without including this control the model would generate an error. if(sum(p_demonstrator) &gt; 0){ demonstrator_index &lt;- sample (N, prob = p_demonstrator, replace = TRUE) population$trait &lt;- population$trait[demonstrator_index] } As usual, we can wrap everything in a function. biased_transmission_demonstrator &lt;- function(N, p_0, p_s, p_low, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0)), status = sample(c(&quot;high&quot;, &quot;low&quot;), N, replace = TRUE, prob = c(p_s, 1 - p_s))) # Assign copying probabilities based on individuals&#39; status p_demonstrator &lt;- rep(1,N) p_demonstrator[population$status == &quot;low&quot;] &lt;- p_low # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Copy traits based on status if(sum(p_demonstrator) &gt; 0){ demonstrator_index &lt;- sample (N, prob = p_demonstrator, replace = TRUE) population$trait &lt;- previous_population$trait[demonstrator_index] } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } We can now test our simulation, assuming a very low, but not zero, probability of selecting low-status individuals as demonstrators. We are using the usual plot_multiple_runs() function to plot the results of the simulations. data_model &lt;- biased_transmission_demonstrator(N = 100, p_s = 0.05, p_low=0.0001, p_0 = 0.5, t_max = 50, r_max = 10) plot_multiple_runs(data_model) Figure 5.1: Indirectly biased transmission causes one trait to spread and the other to be lost. The results are similar to what we saw in the previous chapter for conformity: one of the two traits quickly reaches fixation. In the case of conformity, however, the trait reaching fixation was the one that happened to have a slightly higher frequency at the beginning, because of the random initialisation. With a demonstrator bias, this is not the case. From this perspective, an indirect demonstrator-based bias is more similar to unbiased transmission. If you remember from the first chapter, simulations with unbiased transmission also generally ended up with one trait reaching fixation in small populations (\\(N=100\\)), but in bigger ones (\\(N=10000\\)) the frequencies of the two traits remained around \\(p=0.5\\). What happens with demonstrator-based bias? data_model &lt;- biased_transmission_demonstrator(N = 10000, p_s = 0.005, p_low=0.0001, p_0 = 0.5, t_max = 200, r_max = 10) plot_multiple_runs(data_model) Figure 5.2: Indirectly biased transmission depends on the effective population size, not the overall population size. Even with \\(N=10000\\), if the number of high-status individuals is sufficiently low, as in this case (\\(p_s=0.005\\) means that, on average, 50 individuals are high-status in each run), traits reach fixation. By reducing the pool of demonstrators, demonstrator-based bias makes drift more important for the overall dynamics. The pool of high-status demonstrators (equal to \\(Np_s\\)) is the effective population size, which is much smaller than the actual population size (\\(N\\)). You can experiment with different values of \\(p_s\\) and \\(p_\\text{low}\\). How big can the pool of high-status demonstrators be before the dynamics become indistinguishable from unbiased transmission? 5.2 Predicting the ‘winning’ trait With conformity, as just mentioned, the trait that reaches fixation is the one starting out in the majority. With unbiased transmission the trait that goes to fixation cannot be predicted at the beginning of the simulation. With a demonstrator-based bias, a reasonable guess would be that the ‘winning’ trait is the one that is, at the beginning, most common among the high-status individuals. Can we check this intuition with our model? Currently the output we obtain from the simulations is not suitable for this purpose. On the one hand, we do not have the crucial piece of information that we need: the proportion of each trait among the high-status individuals when the population is initialised. On the other hand, we have much information that we do not need, such as the frequency of the two traits at each time step. However, we just want to know which traits reach fixation. We can therefore rewrite the biased_transmission_demonstrator() function and change the output tibble to suit our needs. biased_transmission_demonstrator_2 &lt;- function(N, p_0, p_s, p_low, t_max, r_max) { output &lt;- tibble(status_A = as.numeric(rep(NA, r_max)), p = as.numeric(rep(NA, r_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0)), status = sample(c(&quot;high&quot;, &quot;low&quot;), N, replace = TRUE, prob = c(p_s, 1 - p_s))) # Assign copying probabilities based on individuals&#39; status p_demonstrator &lt;- rep(1,N) p_demonstrator[population$status == &quot;low&quot;] &lt;- p_low # Add first generation&#39;s frequency of high-status individuals with traits A for run r output[r, ]$status_A &lt;- sum(population$status == &quot;high&quot; &amp; population$trait == &quot;A&quot;) / sum(population$status == &quot;high&quot;) for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Copy traits based on status if(sum(p_demonstrator) &gt; 0){ demonstrator_index &lt;- sample (N, prob = p_demonstrator, replace = TRUE) population$trait &lt;- previous_population$trait[demonstrator_index] } } # Get p at the end of the run output[r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } output # export data from function } Here, status_A gives the starting frequency of A among the high status individuals. \\(p\\), as before, gives the frequency of \\(A\\) in the entire population, but we only record this value at the very end of the simulation, to see if one trait has gone to fixation. The tibble output, as a consequence, has now only \\(r_\\text{max}\\) rows. Let’s run the new function, biased_transmission_demonstrator_2(), for 50 runs (setting r_max = 50) so that we have more independent data points, and inspect the output. data_model &lt;- biased_transmission_demonstrator_2(N = 100, p_s = 0.05, p_low=0.0001, p_0 = 0.5, t_max = 50, r_max = 50) data_model ## # A tibble: 50 x 2 ## status_A p ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.5 0 ## 2 0.4 0 ## 3 0 0 ## 4 0.167 0 ## 5 0.143 0 ## 6 0.5 0 ## 7 0.75 1 ## 8 0.5 0 ## 9 0.455 1 ## 10 1 1 ## # … with 40 more rows Each line of the output is a run of the simulation. The first column (labelled status_A) gives the frequency of \\(A\\) in the high-status individuals, and the second (labelled p) the frequency of \\(A\\) at the end of the simulation. From a cursory inspection of the output, you should be able to see that our guess was correct, and when status_A is higher than 0.5, p should be generally 1, and when status_A is less than 0.5, p should be generally 0. But let’s visualise all the data to be sure. We want to know how the initial proportion of high-status individuals is related to the two possible outcomes (trait \\(A\\) reaches fixation or trait \\(B\\) reaches fixation). A convenient way is to use a boxplot. In the code below, we first eliminate the runs where the traits did not reach fixation (if they exist) using the new function filter(), and, for clarity, we assign the trait name \\(A\\) or \\(B\\) to each run according to which trait reached fixation. We can then plot our output. The main novelties in this code are the new ggplot ‘geoms’ geom_boxplot() and geom_jitter(). Whereas boxplots are useful to detect aggregate information on our simulations, geom_jitter() plots all of the data points, so we can get a better idea of how the proportions of high-status individuals are distributed in the various runs. We could have done this with our usual geom_point(), but geom_jitter() scatters randomly the points in the plot (at a distance specified by the parameter width). This avoids the overlapping of individual data points (known as overplotting). # Filter only lines where p is equal to 1 or to 0 data_model &lt;- filter(data_model, p == 1 | p == 0) data_model$p &lt;- as.character(data_model$p) # Call &quot;A&quot; the runs where p is equal to 1 data_model[data_model$p==1, ]$p &lt;- &quot;A&quot; # Call &quot;B&quot; the runs where p is equal to 0 data_model[data_model$p==0, ]$p &lt;- &quot;B&quot; ggplot(data = data_model, aes(x = p, y = status_A, fill = p)) + geom_boxplot() + geom_jitter(width = 0.05) + labs(y = &quot;proportion of high-status individuals with trait A&quot;, x = &quot;winning trait&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) Figure 5.3: The trait reaching fixation tends to be the trait that was in majority among high-status individuals. The plot shows that when trait \\(A\\) reaches fixation there are more high-status individuals with trait \\(A\\) at the beginning, and vice versa for \\(B\\), confirming our intuition. However, this is far from being a safe bet. Runs with only a quarter of high-status individuals with \\(A\\) ended up with all \\(A\\)s in the population and, conversely, runs with 80% of high-status individuals with \\(A\\) ended up with the fixation of \\(B\\). With bigger populations (e.g. with \\(N=10000\\)), it is even worse. data_model &lt;- biased_transmission_demonstrator_2(N = 10000, p_s = 0.005, p_low=0.0001, p_0 = 0.5, t_max = 200, r_max = 50) # Filter only lines where p is equal to 1 or to 0 data_model &lt;- filter(data_model, p == 1 | p == 0) data_model$p &lt;- as.character(data_model$p) # Call &quot;A&quot; the runs where p is equal to 1 data_model[data_model$p==1, ]$p &lt;- &quot;A&quot; # Call &quot;B&quot; the runs where p is equal to 0 data_model[data_model$p==0, ]$p &lt;- &quot;B&quot; ggplot(data = data_model, aes(x = p, y = status_A, fill = p)) + geom_boxplot() + geom_jitter(width = 0.05) + labs(y = &quot;proportion of high-status individuals with trait A&quot;, x = &quot;winning trait&quot;) + ylim(c(0,1)) + theme_bw() + theme(legend.position = &quot;none&quot;) Figure 5.4: With bigger populations - and bigger pools of high-status demonstrators is more difficult to predict the winning trait. With \\(N=10000\\) and around 50 high-status individuals, the traits are more equally distributed among ‘influential’ demonstrators at the beginning, and there is hardly any difference in the two outcomes. 5.3 Summary of the model In this chapter we modeled an example of indirectly-biased or demonstrator-biased transmission. We assumed that a fraction of individuals in the population were ‘high-status’ and thus more likely to be selected as demonstrators. The results show that in this situation a trait is likely to become predominant even when populations are large. This is due to the fact that a demonstrator bias effectively reduces the pool of demonstrators and accelerates convergence through a similar process as drift / unbiased transmission. We also saw that the possibility of predicting which trait will become predominant depends on the number of high-status demonstrators. When there are few high-status demonstrators, then the most common trait amongst these high-status demonstrators will likely go to fixation. When their number increases, it is more difficult to make such a prediction. We also saw how it is important to modify the output of a model depending on the question we are interested in. We used a novel ggplot aesthetic to produce a boxplot, a convenient way of displaying the distribution of data among different groups. 5.4 Further readings Examples of simulation models implementing indirect, demonstrator-based, biased transmission include Mesoudi (2009), an individual-based model that explores how prestige bias can generate clusters of recurring behaviours, applied to the case of copycat suicides. Henrich Joseph, Chudek Maciej, and Boyd Robert (2015) presents a population-level model that links prestige to the emergence of within-group cooperation. Henrich (2004) describes an analytical, population-level, model, where individuals copy the most successful demonstrator in the population. An earlier analytical treatment of demonstrator-based bias, with extensions on the evolution of symbolic traits that may be associated to demonstrators is in Chapter 8 of Boyd and Richerson (1985). Finally, Henrich and Gil-White (2001) is the classic treatment of prestige bias, and a recent review of the empirical evidence supporting it is Jiménez and Mesoudi (2019). "],["vertical-and-horizontal-transmission.html", "Chapter 6 Vertical and horizontal transmission 6.1 Vertical cultural transmission 6.2 Horizontal cultural transmission 6.3 Summary of the model 6.4 Further reading", " Chapter 6 Vertical and horizontal transmission An important distinction in cultural evolution concerns the pathway of cultural transmission. Vertical cultural transmission occurs when individuals learn from their parents. Oblique cultural transmission occurs when individuals learn from other (non-parental) members of the older generation, such as teachers. Horizontal cultural transmission occurs when individuals learn from members of the same generation. These terms (vertical, oblique and horizontal) are borrowed from epidemiology, where they are used to describe the transmission of diseases. Cultural traits, like diseases, are interesting in that they have multiple pathways of transmission. While genes spread purely vertically (at least in species like ours; horizontal gene transfer is common in plants and bacteria), cultural traits can spread obliquely and horizontally. These latter pathways can increase the rate at which cultural traits can spread, compared to vertical transmission alone. In this chapter we will simulate and test this claim, focusing in particular on horizontal cultural transmission: when and why does horizontal transmission increase the rate of spread of a cultural trait compared to vertical cultural transmission? 6.1 Vertical cultural transmission To simulate vertical cultural transmission we need to decide how people learn from their parents, assuming those two parents possess different combinations of cultural traits. As in previous models, we assume two discrete traits, \\(A\\) and \\(B\\). There are then four combinations of traits amongst two parents: both parents have \\(A\\), both parents have \\(B\\), mother has \\(A\\) and father has \\(B\\), and mother has \\(B\\) and father has \\(A\\). For simplicity, we can assume that when both parents have the same trait, the child adopts that trait. When parents differ, the child faces a choice. To make things more interesting, let’s assume a bias for one trait over the other in such situations (otherwise we would be back to unbiased transmission, and no trait would reliably spread - remember we are interested in how quickly traits spread under vertical vs horizontal transmission). Hence we assume a probability \\(b\\) that, when parents differ in their traits such that there is some uncertainty, the child adopts \\(A\\). With probability \\(1-b\\) they adopt trait \\(B\\). When \\(b=0.5\\), transmission is unbiased. When \\(b&gt;0.5\\), \\(A\\) should be favoured; when \\(b&lt;0.5\\), \\(B\\) should be favoured. Let’s simulate this and test these predictions. The following function vertical_transmission() is very similar to previous simulation functions. The explanation follows. library(tidyverse) vertical_transmission &lt;- function(N, p_0, b, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly pick mothers and fathers mother &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) father &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Prepare next generation population &lt;- tibble(trait = as.character(rep(NA, N))) # Both parents are A, thus child adopts A both_A &lt;- mother$trait == &quot;A&quot; &amp; father$trait == &quot;A&quot; if (sum(both_A) &gt; 0) { population[both_A, ]$trait &lt;- &quot;A&quot; } # Both parents are B, thus child adopts B both_B &lt;- mother$trait == &quot;B&quot; &amp; father$trait == &quot;B&quot; if (sum(both_B) &gt; 0) { population[both_B, ]$trait &lt;- &quot;B&quot; } # If any empty NA slots (i.e. one A and one B parent) are present if (anyNA(population)) { # They adopt A with probability b population[is.na(population)[,1],]$trait &lt;- sample(c(&quot;A&quot;, &quot;B&quot;), sum(is.na(population)), prob = c(b, 1 - b), replace = TRUE) } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } First we set up an output tibble to store the frequency of \\(A\\) (\\(p\\)) over \\(t_{\\text{max}}\\) generations and across \\(r_{\\text{max}}\\) runs. As before we create a population tibble to store our \\(N\\) traits, one per individual. This time, however, in each generation we create two new tibbles, mother and father. These store the traits of two randomly chosen individuals from the previous_population, one pair for each new individual. Note that we are assuming random mating here: parents pair up entirely at random. Alternative mating rules are possible, such as assortative cultural mating, where parents preferentially assort based on their cultural trait. We will leave it to readers to create models of this. Once the mother and father tibbles are created, we can fill in the new individuals’ traits in population. both_A is used to mark with TRUE whether both mother and father have trait \\(A\\), and (assuming some such cases exist), sets all individuals in population for whom this is true to have trait \\(A\\). both_B works equivalently for parents who both possess trait \\(B\\). The remaining cases (identified as still being NA in the population tibble, with the function anyNA()) must have one \\(A\\) and one \\(B\\) parent. We are not concerned with which parent has which in this simple model, so in each of these cases we set the individual’s trait to be \\(A\\) with probability \\(b\\) and \\(B\\) with probability \\(1-b\\). Again, we leave it to readers to modify the code to have separate probabilities for maternal and paternal transmission. Once all generations are finished, we export the output tibble as our data. We can use our existing function plot_multiple_runs() from previous chapters to plot the results. And now run both functions to see what happens. Remember we are interested in how fast the favoured trait spreads, so let’s start it off at a low frequency (\\(p_0=0.01\\)) so we can see it spreading from rarity. We use a small transmission bias \\(b=0.6\\) favouring \\(A\\). data_model &lt;- vertical_transmission(N = 10000, p_0 = 0.01, b = 0.6, t_max = 50, r_max = 5) plot_multiple_runs(data_model) Figure 6.1: The favourite trait, A, spreads in the population under vertical transmission. Here we can see a gradual spread of the favoured trait \\(A\\) from \\(p=0.01\\) to \\(p=1\\). As in our directly biased transmission model, the diffusion curve is s-shaped. To obtain the same result with two different models is encouraging! We can also test our prediction that when \\(b=0.5\\), we recreate our unbiased transmission model from Chapter 1: data_model &lt;- vertical_transmission(N = 10000, p_0 = 0.1, b = 0.5, t_max = 50, r_max = 5) plot_multiple_runs(data_model) Figure 6.2: When no trait is favoured, there is no change in the frequency of trait A under vertical transmission. As predicted, there is no change in starting trait frequencies when \\(b=0.5\\). If you reduce the sample size, you will see much more fluctuation across the runs, with some runs losing \\(A\\) altogether. 6.2 Horizontal cultural transmission Now let’s add horizontal cultural transmission to our model. We will add it to vertical cultural transmission, rather than replace vertical with horizontal, so we can compare both in the same model. First there is vertical transmission as above, with random mating and the parental bias \\(b\\), to create a new generation. Then, the new generation learns from each other. The key difference between vertical and horizontal transmission is that horizontal cultural transmission can occur from more than two individuals. Let’s assume individuals pick \\(n\\) other individuals from their generation. We also assume a bias in favour of \\(A\\) during horizontal transmission. If the learner is \\(B\\), then for each of the \\(n\\) demonstrators who have \\(A\\), there is an independent probability \\(g\\) that the learner switches to \\(A\\). If the learner is already \\(A\\), or if the demonstrator is \\(B\\), then nothing happens. The following code implements this horizontal transmission in a new function vertical_horizontal_transmission(). vertical_horizontal_transmission &lt;- function(N, p_0, b, n, g, t_max, r_max) { output &lt;- tibble(generation = rep(1:t_max, r_max), p = as.numeric(rep(NA, t_max * r_max)), run = as.factor(rep(1:r_max, each = t_max))) for (r in 1:r_max) { # Create first generation population &lt;- tibble(trait = sample(c(&quot;A&quot;, &quot;B&quot;), N, replace = TRUE, prob = c(p_0, 1 - p_0))) # Add first generation&#39;s p for run r output[output$generation == 1 &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N for (t in 2:t_max) { # Vertical transmission -------------------------------------------------- # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly pick mothers and fathers mother &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) father &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Prepare next generation population &lt;- tibble(trait = as.character(rep(NA, N))) # Both parents are A, thus child adopts A both_A &lt;- mother$trait == &quot;A&quot; &amp; father$trait == &quot;A&quot; if (sum(both_A) &gt; 0) { population[both_A, ]$trait &lt;- &quot;A&quot; } # Both parents are B, thus child adopts B both_B &lt;- mother$trait == &quot;B&quot; &amp; father$trait == &quot;B&quot; if (sum(both_B) &gt; 0) { population[both_B, ]$trait &lt;- &quot;B&quot; } # If any empty NA slots (i.e. one A and one B parent) are present if (anyNA(population)) { # They adopt A with probability b population[is.na(population)[,1],]$trait &lt;- sample(c(&quot;A&quot;, &quot;B&quot;), sum(is.na(population)), prob = c(b, 1 - b), replace = TRUE) } # Horizontal transmission ------------------------------------------------ # Previous_population are children before horizontal transmission previous_population &lt;- population # N_B = number of Bs N_B &lt;- length(previous_population$trait[previous_population$trait == &quot;B&quot;]) # If there are B individuals to switch, and n is not zero if (N_B &gt; 0 &amp; n &gt; 0) { # For each B individual... for (i in 1:N_B) { # Pick n demonstrators demonstrator &lt;- sample(previous_population$trait, n, replace = TRUE) # Get probability g copy &lt;- sample(c(TRUE, FALSE), n, prob = c(g, 1-g), replace = TRUE) # if any demonstrators with A are to be copied if ( sum(demonstrator == &quot;A&quot; &amp; copy == TRUE) &gt; 0 ) { # The B individual switches to A population[previous_population$trait == &quot;B&quot;,]$trait[i] &lt;- &quot;A&quot; } } } # Get p and put it into output slot for this generation t and run r output[output$generation == t &amp; output$run == r, ]$p &lt;- sum(population$trait == &quot;A&quot;) / N } } # Export data from function output } The first part of this code is identical to vertical_transmission(). Then there is horizontal transmission. We put population into previous_population again, but now population contains the individuals after horizontal transmission, and previous_population contains the individuals before. N_B holds the individuals in previous_population who are \\(B\\), as they are the only ones we need to concern ourselves with (\\(A\\) individuals do not change). If there are such individuals (\\(N_B&gt;0\\)), and individuals are learning from at least one individual (\\(n&gt;0\\)), then for each individual we pick \\(n\\) demonstrators, and if any of those demonstrators are \\(A\\) plus probability \\(g\\) is fulfilled, we set the individual to \\(A\\). Running horizontal transmission with \\(n=5\\) and \\(g=0.1\\) and without vertical transmission bias (\\(b=0.5\\)) causes, as expected, \\(A\\) to spread. data_model &lt;- vertical_horizontal_transmission(N = 5000, p_0 = 0.01, b = 0.5, n = 5, g = 0.1, t_max = 50, r_max = 5) plot_multiple_runs(data_model) Figure 6.3: The favourite trait, A, spreads in the population under horizontal transmission. This plot above confirms that horizontal cultural transmission, with some direct bias in the form of \\(g\\), again generates an s-shaped curve and causes the favoured trait to spread. But we haven’t yet done what we set out to do, which is compare the speed of the different pathways. The following code generates three datasets, one with only vertical transmission and \\(b=0.6\\), one with only horizontal transmission with \\(n=2\\) and \\(g=0.1\\) which is roughly equivalent to two parents and a bias of \\(b=0.6\\) (0.1 higher than unbiased), and one with only horizontal transmission with \\(n=5\\) and \\(g=0.1\\). data_model_v &lt;- vertical_horizontal_transmission(N = 5000, p_0 = 0.01, b = 0.6, n = 0, g = 0, t_max = 50, r_max = 5) data_model_hn2 &lt;- vertical_horizontal_transmission(N = 5000, p_0 = 0.01, b = 0.5, n = 2, g = 0.1, t_max = 50, r_max = 5) data_model_hn5 &lt;- vertical_horizontal_transmission(N = 5000, p_0 = 0.01, b = 0.5, n = 5, g = 0.1, t_max = 50, r_max = 5) plot_multiple_runs(data_model_v) Figure 6.4: The favourite trait, A, spreads in the population under vertical transmission only. plot_multiple_runs(data_model_hn2) Figure 6.5: Given an equivalent bias strength and two demonstrators, the favourite trait, A, spreads under horizontal transmission at the same speed than in the vertical transmission scenario. plot_multiple_runs(data_model_hn5) Figure 6.6: Given an equivalent bias strength and five demonstrators, the favourite trait, A, spreads under horizontal transmission faster than in the vertical transmission scenario. The first two plots should be very similar. Horizontal cultural transmission from \\(n=2\\) demonstrators is equivalent to vertical cultural transmission, which of course also features two demonstrators, when both pathways have similarly strong direct biases. The third plot shows that increasing the number of demonstrators makes favoured traits spread more rapidly under horizontal transmission, without changing the strength of the biases. Of course, changing the relative strength of the vertical and horizontal biases (\\(b\\) and \\(g\\) respectively) also affects the relative speed. But all else being equal, horizontal transmission with \\(n&gt;2\\) is faster than vertical transmission. 6.3 Summary of the model This model has combined directly biased transmission with vertical and horizontal transmission pathways. The vertical transmission model recreates the patterns from our previous unbiased and directly biased transmission, but explicitly modelling parents and their offspring. Although there were no differences, our vertical transmission model could be modified easily to study different kinds of parental bias (e.g. making maternal influence stronger than paternal influence), or different types of non-random mating. Our horizontal transmission model is similar to the conformist bias simulated in Chapter 4, but slightly different - there is no disproportionate majority copying, and instead one trait is favoured when learning from \\(n\\) demonstrators. Comparing the two pathways, we can see that horizontal cultural transmission is faster than vertical cultural transmission largely because it allows individuals to learn from more than two demonstrators. 6.4 Further reading The above models are based on those by Cavalli-Sforza and Feldman (1981). Their vertical cultural transmission models feature bias parameters for each combination of matings (\\(b_0\\), \\(b_1\\), \\(b_2\\) and \\(b_3\\)); our \\(b\\) is their \\(b_1\\) and \\(b_2\\). Their horizontal transmission model also features \\(n\\) and \\(g\\), which have the same definitions as here. Subsequent models in that volume examine assortative cultural mating and oblique transmission, although the latter is similar to horizontal transmission. "],["multiple-traits-models.html", "Chapter 7 Multiple traits models 7.1 Unbiased transmission with multiple traits 7.2 Introducing innovation 7.3 Optimising the code 7.4 The distribution of popularity 7.5 Summary of the model 7.6 Further readings", " Chapter 7 Multiple traits models In all previous models, individuals could possess one of only two cultural traits, \\(A\\) or \\(B\\). This is a useful simplification, and it represents cases in which cultural traits can be modeled as binary choices, such as voting Republican or Democrat, driving on the left or the right, or being vegetarian or meat-eating. In other cases, however, there are many options: in many countries there are multiple political parties to vote for, there may be many dietary choices (vegan, pescatarian, vegetarian, etc), and so on. What happens when we copy others’ choices given more than two alternatives? To simplify this question, we again assume unbiased copying as in the first chapter: all traits are functionally equivalent and other individuals are copied at random. 7.1 Unbiased transmission with multiple traits The first modification we need to make in the code concerns how traits are represented. Since we have an undetermined number of possible traits we cannot use the two letters \\(A\\) and \\(B\\). Instead we will use numbers, referring to trait “1”, trait “2”, trait “3”, etc. How can we distribute the traits in the initial population? We can assume that there are \\(m\\) possible traits at the beginning, with \\(m \\leq N\\) (as usual, \\(N\\) is the population size). In all the following simulations, we will fix \\(m=N\\), and effectively initialise each individual with a trait randomly chosen between “1” and “100”. library(tidyverse) N &lt;- 100 population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) You can inspect the population tibble by writing its name. population ## # A tibble: 100 x 1 ## trait ## &lt;int&gt; ## 1 23 ## 2 53 ## 3 31 ## 4 42 ## 5 83 ## 6 19 ## 7 76 ## 8 69 ## 9 81 ## 10 28 ## # … with 90 more rows The basic code of the simulation is similar to the code in the first chapter, but what should the output be? Until now, we generally just needed to save the frequency of one of the two traits, because the frequency of the other was always one minus the first’s frequency. Now we need the frequencies of all \\(N\\) traits. (Technically, we only need to track \\(N-1\\) frequencies, with the last inferred by substracting the other frequencies from 1. But for simplicity we’ll track all of the frequencies.) Second, how do we measure the frequency of the traits in each generation? The base R function tabulate() does this for us. tabulate() counts the number of times each element of a vector (population$trait in our case) occurs in the bins that we also pass to the function. In our case the bins are \\(1\\) to \\(N\\). Since we want the frequencies, and not the absolute number, we divide the result by \\(N\\). multiple_traits &lt;- function(N, t_max) { output &lt;- tibble(trait = as.factor(rep(1:N, each = t_max)), generation = rep(1:t_max, N), p = as.numeric(rep(NA, t_max * N))) # Create first generation population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) # Add first generation&#39;s p for all traits output[output$generation == 1, ]$p &lt;- tabulate(population$trait, nbins = N) / N for (t in 2:t_max) { # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Get p for all traits and put it into output slot for this generation t output[output$generation == t, ]$p &lt;- tabulate(population$trait, nbins = N) / N } # Export data from function output } Finally, the function to plot the output is similar to what we have already done when plotting multiple runs. The one difference is that now the colored lines do not represent different runs, but different traits, as indicated below by aes(colour = trait). The new line theme(legend.position = \"none\") simply tells ggplot to not include the legend in the graph, as it is not informative. It would just show 100 or more colors, one for each trait. plot_multiple_traits &lt;- function(data_model) { ggplot(data = data_model, aes(y = p, x = generation)) + geom_line(aes(colour = trait)) + ylim(c(0, 1)) + theme_bw() + theme(legend.position = &quot;none&quot;) } As usual, we can call the function and see what happens: data_model &lt;- multiple_traits(N = 100, t_max = 200) plot_multiple_traits(data_model) Figure 7.1: With small populations, the majority of traits disappear after few generations in a model with multiple traits and unbiased transmission. Usually, only one or two traits are still present in the population after 200 generations, and, if we increase \\(t_\\text{max}\\) for example to 1000, virtually all runs end up with only a single trait reaching fixation: data_model &lt;- multiple_traits(N = 100, t_max = 1000) plot_multiple_traits(data_model) Figure 7.2: With small populations, a single traits reach fixation if there are enough generations in a model with multiple traits and unbiased transmission. This is similar to what we saw with only two traits, \\(A\\) and \\(B\\): with unbiased copying and relatively small populations, drift is a powerful force and quickly erodes cultural diversity. As we already discussed, increasing \\(N\\) reduces the effect of drift. You can experiment with various values for \\(N\\) and \\(t_\\text{max}\\). However, the general point is that variation is gradually lost in all cases. How can we counterbalance the homogenizing effect that drift has in small and isolated population, such as the one we are simulating? 7.2 Introducing innovation One option is to introduce new traits via innovation. We can imagine that, at each time step, a proportion of individuals, \\(\\mu\\), introduces a new trait in the population. We use the same notation that we used for mutation in chapter 2: you can think that ‘mutation’ is when an individual change its trait for one that is already present, whereas an ‘innovation’ happens when an individual introduces a new trait never seen before. The remaining proportion of individuals, \\(1-\\mu\\), copy at random from others, as before. We can start with a small value, such as \\(\\mu=0.01\\). Since \\(N=100\\), this means that in each generation, on average, one new trait will be introduced into the population. The following code adds innovation to the multiple-trait code from above: mu &lt;- 0.01 # Record the last trait introduced in the population last_trait &lt;- max(population) # Copy the population tibble to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Identify the innovators innovators &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) # If there are innovators if( sum(innovators) &gt; 0){ # Replace innovators&#39; traits with new traits population[innovators,]$trait &lt;- (last_trait + 1):(last_trait + sum(innovators)) } There are two modifications here. First, we need to select who are the innovators. For that, we use again the function sample(), biased by \\(\\mu\\), picking TRUE (corresponding to being an innovator) or FALSE (keeping the copied cultural trait) \\(N\\) times. Second, we need to actually introduce the new traits, with the correct number labels. First we record at the beginning of each generation the label of the last trait introduced (at the beginning, with \\(N=100\\), it will likely be 100 because we initialise each individual’s traits by choosing randomly between 1 and 100). When new traits are introduced, we give them consecutive number labels: the first new trait will be called 101, the second 102, and so on. The code above adds all of the new traits into the innovator slots all in one go, which is more efficient than doing it one innovator at a time. We can now, as usual, wrap everything in a function: multiple_traits_2 &lt;- function(N, t_max, mu) { max_traits &lt;- N + N * mu * t_max output &lt;- tibble(trait = as.factor(rep(1:max_traits, each = t_max)), generation = rep(1:t_max, max_traits), p = as.numeric(rep(NA, t_max * max_traits))) # Create first generation population &lt;- tibble(trait = sample(1:N, N, replace = TRUE)) # Add first generation&#39;s p for all traits output[output$generation == 1, ]$p &lt;- tabulate(population$trait, nbins = max_traits) / N for (t in 2:t_max) { # Record what is the last trait introduced in the population last_trait &lt;- max(population) # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- tibble(trait = sample(previous_population$trait, N, replace = TRUE)) # Select the innovators innovators &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) if ((last_trait + sum(innovators)) &lt; max_traits) { if(sum(innovators) &gt; 0){ # Replace innovators&#39; traits with new traits population[innovators,]$trait &lt;- (last_trait + 1):(last_trait + sum(innovators)) } } # Get p for all traits and put it into output slot for this generation t output[output$generation == t, ]$p &lt;- tabulate(population$trait, nbins = max_traits) / N } # Export data output } You should now be familiar with more or less everything within this function, with one exception: the new quantity max_traits. This is a trick we are using to avoid making the code too slow to run. Our output tibble, as you remember, records all the frequencies of all traits. When programming, a good rule-of-thumb is to avoid dynamically modifying the size of your data structures, such as adding new rows to a pre-existing tibble during the simulation. Where possible, set the size of a data structure at the start, and then modify its values during the simulation. So rather than creating a tibble that is expanded dynamically as new traits are introduced via innovation, we create a bigger tibble from the start. How big should it be? We do not know for sure, but a good estimate is that we will need space for the initial traits (\\(N\\)), plus around \\(N\\mu\\) traits that are added each generation. To be absolutely sure we do not exceed this estimate, we wrap the innovation instruction within the if ((last_trait + sum(innovators)) &lt; max_traits) condition. This prevents innovation when the tibble has filled up. This might prevent innovation in the last few generations, but this should have negligible consequences for our purposes. Let’s now run the function with an innovation rate \\(\\mu=0.01\\), a population of 100 individuals, and for 200 generations. data_model &lt;- multiple_traits_2(N = 100, t_max = 200, mu = 0.01) plot_multiple_traits(data_model) Figure 7.3: By adding innovations, more traits can be preserved in the population. With innovation, there should now be more traits at non-zero frequency at the end of the simulation than when innovation was not possible. We can check the exact number, by inspecting how many frequencies are higher than 0 in the last row of our matrix: sum(filter(data_model, generation==200)$p &gt; 0) ## [1] 8 What happens if we increase the number of generations, or time steps, to 1000, as we did before? data_model &lt;- multiple_traits_2(N = 100, t_max = 1000, mu = 0.01) plot_multiple_traits(data_model) Figure 7.4: By adding innovations, traits are preserved even when the model runs for several generations. As you can see in the plot, there should still be several traits that have frequencies higher than 0, even after 1000 generations. Again, we can find the exact number in the final generation: sum(filter(data_model, generation==1000)$p &gt; 0) ## [1] 5 Innovation, in sum, allows the maintenance of variation even in small populations. 7.3 Optimising the code Now for a short technical digression. You may have noticed that running the function multiple_traits_2() is quite time consuming with a population of 1000 individuals. There is a quick way to check the exact time needed, using the function Sys.time(). This returns the current time at the point of its execution. Let’s run the function again and calculate how long it takes. start_time &lt;- Sys.time() data_model &lt;- multiple_traits_2(N = 100, t_max = 1000, mu = 0.01) end_time &lt;- Sys.time() end_time - start_time ## Time difference of 22.71843 secs While this varies from computer to computer, it may take several seconds to finsh. To store the output, we are using a tibble with \\(1100000\\) data points, as max_traits is equal to \\(1100\\), which needs to be updated in each of the \\(1000\\) generations. One way of speeding up the simulation is to record our output in a different data structure. So far, we have been using tibbles to store our simulation output. R, as with all programming languages, can store data in different structures. Depending on what the data are and what one wants to do with them, different structures are more or less suitable. The advantage of tibbles is that they can contain heterogeneous data, depending on what we need to store: for example, in our output tibble, the trait column was specified as a factor, whereas the others two columns, generation and p, were numeric. An alternative is to use vectors and matrices. A vector is a list of data points that are all of the same type, e.g. logical (TRUE/FALSE), integer (whole numbers), numeric (any numbers), or character (text). Matrices are just two-dimensional vectors: they must also contain all the same type of data, but they have rows and columns similar to a tibble, dataframe or Excel spreadsheet. The advantage of vectors and matrices is efficiency: they make simulations much faster than identical code running with tibbles. Let’s rewrite our multiple trait function that runs exactly the same simulation, but using matrices instead of tibbles. The output is now a matrix with t_max rows and max_traits columns. This is initialised with NAs at the beginning. The population is a vector of integers, representing the trait held by each individual. multiple_traits_matrix &lt;- function(N, t_max, mu) { max_traits &lt;- N + N * mu * t_max output &lt;- matrix(data = NA, nrow = t_max, ncol = max_traits) # Create first generation population &lt;- sample(1:N, N, replace = TRUE) output[1, ] &lt;- tabulate(population, nbins = N) / N # Add first generation&#39;s p for all traits for (t in 2:t_max) { # Record what is the last trait introduced in the population last_trait &lt;- max(population) # Copy individuals to previous_population tibble previous_population &lt;- population # Randomly copy from previous generation population &lt;- sample(previous_population, N, replace = TRUE) # Select the innovators innovators &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) if ((last_trait + sum(innovators)) &lt; max_traits) { # Replace innovators&#39; traits with new traits population[innovators] &lt;- (last_trait + 1):(last_trait + sum(innovators)) } # Get p for all traits and put it into output slot for this generation t output[t, ] &lt;- tabulate(population, nbins = max_traits) / N } # Export data output } To plot the output, we re-convert it into a tibble so that it can be handled by ggplot(). We first create a column that explicitly indicates the number of generations, and then we use the function pivot_longer() from the tidyverse to reassemble the columns of the matrix in trait-frequency pairs, the ‘tidy’ format consistent with the functioning of ggplot. plot_multiple_traits_matrix &lt;- function(data_model) { generation &lt;- rep(1:dim(data_model)[1], each = dim(data_model)[2]) data_to_plot &lt;- as_tibble(data_model) %&gt;% pivot_longer(everything(), names_to = &quot;trait&quot;, values_to = &quot;p&quot;) %&gt;% add_column(generation) ggplot(data = data_to_plot, aes(y = p, x = generation)) + geom_line(aes(colour = trait)) + ylim(c(0, 1)) + theme_bw() + theme(legend.position = &quot;none&quot;) } We can now run the new function, checking that it gives the same output as the tibble version, and again calculating the time needed. start_time &lt;- Sys.time() data_model &lt;- multiple_traits_matrix(N = 100, t_max = 1000, mu = 0.01) end_time &lt;- Sys.time() plot_multiple_traits_matrix(data_model) Figure 7.5: We obtain qualitatively the same results of the previous code, in a model with unbiased transmission, multiple traits, and innovation. end_time - start_time ## Time difference of 0.05834985 secs The results are equivalent, but the simulation should be hundreds of times faster! This shows that implementation details are very important when building individual based models. When one needs to run the same simulation many times, or test many different parameter values, implementation choices can make drastic differences. 7.4 The distribution of popularity An interesting aspect of these simulations is that, even if all traits are functionally equivalent and transmission is unbiased, a few traits, for random reasons, are more successful than the others. A way to visualise this is to plot their cumulative popularity, i.e. the sum of their quantities over all generations. Given our matrix, it is easy to calculate this by summing each column and multiplying by N (remember they are frequencies, whereas now we want to visualise their actual quantities). We also need to keep only the values that are higher than zero: values equal to zero are in fact the empty slots created in the initial matrix that were never filled with actual traits. cumulative &lt;- colSums(data_model) * N cumulative &lt;- cumulative[cumulative &gt; 0] Let’s sort them from the most to the least popular and plot the results. data_to_plot &lt;- tibble(cumulative = sort(cumulative, decreasing = TRUE)) ggplot(data = data_to_plot, aes(x = seq_along(cumulative), y = cumulative)) + geom_point() + theme_bw() + labs(x = &quot;trait label&quot;, y = &quot;cumulative popularity&quot;) Figure 7.6: The popularity distribution of traits with unbiased copying is long-tailed, with few very successful traits and many relatively unsuccessful ones. This is an example of a long-tailed distribution. The great majority of traits did not spread in the population, and their cumulative popularity is very close to one. Very few of them—the ones on the left side of the plot—were instead very successful. Long-tailed distributions like the one we just produced are very common for cultural traits: a small number of movies, books, or first names are very popular, while the great majority is not. In addition, in these domains, the popular traits are much more popular than the unpopular ones. The average cumulative popularity of the data we plotted is 106.2, but the most successful trait has a popularity of 23891. It is common to plot these distributions by binning the data in intervals of exponentially increasing size. In other words, we want to know how many traits have a cumulative popularity between 1 and 2, then between 2 and 4, then between 4 and 8, and so on, until we reach the maximum value of cumulative popularity. The code below does that, using a for cycle to find how many traits fall in each bin and further normalising according to bin size. The size is increased 50 times, until an arbitrary maximum bin size of \\(2^{50}\\), to be sure to include all cumulative popularities. bin &lt;- rep(NA, 50) x &lt;- rep(NA, 50) for(i in 1:50){ bin[i] &lt;- sum(cumulative &gt;= 2^(i - 1) &amp; cumulative &lt; 2^i) bin[i] &lt;- (bin[i] / length( cumulative)) / 2^(i - 1); x[i] &lt;- 2^i } We can now visualise the data on a log-log plot, after filtering out the empty bins. A log-log plot is a graph that uses logarithmic scales on both axes. Using logarithmic axes is useful when, as in this case, the data are skewed towards large values. In the previous plot, we were not able to appreciate visually any difference in the great majority of data points, for example points that had cumulative popularity between 1 and 10, as they were all bunched up close to the x-axis. data_to_plot &lt;- tibble(bin = bin, x = x) data_to_plot &lt;- filter(data_to_plot, bin &gt; 0) ggplot(data = data_to_plot, aes(x = x, y = bin)) + geom_point() + labs(x = &quot;cumulative popularity&quot;, y = &quot;proportion of traits&quot;) + scale_x_log10() + scale_y_log10() + stat_smooth(method = &quot;lm&quot;) + theme_bw() Figure 7.7: Popularity distribution of traits on a log-log scale. On a log-log scale, the distribution of cumulative popularity produced by unbiased copying lies approximately on a straight line (this linear best-fit line is produced using the command stat_smooth(method = \"lm\")). This straight line on a log-log plot is known as a “power law” frequency distribution. The goodness of fit and the slope of the line can be used to compare different types of cultural transmission. For example, what would happen to the above power law if we added some degree of conformity? What about demonstrator-based bias? We can also generate equivalent plots for real-world cultural datasets to test hypotheses about the processes that generated these distributions in the real world. 7.5 Summary of the model In this chapter we simulated the case where individuals can possess one of more than two traits. We explored the simplest case of unbiased transmission. We also implemented the possibility of innovation, where individuals introduce, with some probability, new traits into the cultural pool of the population. Individual innovations counterbalance the homogenizing effect of drift, and replace the traits that are gradually lost. To simulate multiple traits and innovation we also needed to deal with a few technical details such as how to keep track of an initially unknown number of new traits. We learned that it is best to create data structures of the desired size at the outset, rather than changing their size dynamically during the simulation. We also saw the importance of using appropriate data structures when simulations start to become more complex. Replacing tibbles with matrices, we were able to make our simulation 100 times faster. Our results showed that unbiased copying produces long-tailed distributions where very few traits are very popular and the great majority are not. An interesting insight from this model is that these extreme distributions do not necessarily result from extreme tendencies at the individual level. Some traits become hugely more popular than others without individuals being biased, for example, towards popular traits. Cultural transmission generates these distributions without biases, but simply because popular traits have the intrinsic advantage of being more likely to be randomly copied. We also introduced a new technique, the log-log plot of binned popularity distributions, to visualise this outcome. 7.6 Further readings Neiman (1995) first introduced a model of unbiased copying with multiple traits to explain popularity distributions in assemblages of Neolithic pottery. Bentley, Hahn, and Shennan (2004) elaborated on this idea, presenting a ‘random copying’ model (equivalent to the one developed in this chapter) and comparing the popularity distributions produced with real datasets, including the frequency distributions of first names in the US and the citations of patents. Mesoudi and Lycett (2009) explored how adding transmission biases (e.g. conformity) to the basic model changes the resulting power-law frequency distribution. "],["rogers-paradox.html", "Chapter 8 Rogers’ Paradox 8.1 Modelling Rogers’ Paradox 8.2 Summary of the model 8.3 Further reading", " Chapter 8 Rogers’ Paradox The previous chapters all concerned cultural evolutionary dynamics: how different biases and transmission pathways affect the frequency of cultural traits in a population over time. Equally important, though, is to step back and consider where the possibility of culture came from in the first place. That is, we need to also consider the evolution of culture, and the evolution of cultural evolution. The most basic question we can ask here is why a capacity for social learning (learning from others) evolved, relative to individual learning (learning directly from the environment, on one’s own). An intuitive answer to this question is that social learning is less costly than individual learning. Imagine trying out different foods, some of which may be poisonous. One could try each one, and see if they make you ill. A less risky strategy would be to observe one’s neighbour, and eat what they are eating. Unless they look sickly all the time, this will likely lead to a palatable (and evolutionarily adaptive) choice. Consequently, social learning should increase the mean adaptation of a population. However, this intuition can be misleading. This was shown in 1988 by Alan Rogers in a now-classic model of the evolution of social learning (Rogers (1988)). This model is often called “Rogers’ paradox”, because it shows that under certain conditions, social learning does not lead to increased adaptation, even when it is less costly than individual learning. More precisely, the mean fitness of a population containing social learners does not exceed the mean fitness of a population composed entirely of individual learners. Here we will recapitulate Rogers’ mathematical model in an individual-based simulation, to see when and why this counter-intuitive result holds. 8.1 Modelling Rogers’ Paradox In Rogers’ model there are \\(N\\) individuals. Each individual has a fixed learning strategy: they are either an individual learner, or a social learner. Each individual also exhibits a behaviour, which we will represent, as the traits in the previous chapter with an integer (e.g. “5”, or “32”). (“Trait” and “behaviour” are often used interchangeably in cultural evolution literature.) There is also an environmental state, \\(E\\), which is also represented with an integer. When an individual’s behaviour matches the environment, they receive increased fitness, compared to when it does not match. A match might represent ‘palatable food’, while a mismatch might represent ‘poisonous food’. In each generation, individual learners directly sample the environment, and have a probability \\(p\\) of acquiring the ‘correct’, adaptive behaviour that matches the environment (and therefore a probability \\(1-p\\) of adopting the incorrect, maladaptive behaviour). Social learners choose a member of the previous generation at random and copy their behaviour, just like for unbiased transmission considered in Chapter 1. Unlike previous models, we are interested here not in the behaviours or traits, but in how the learning strategies evolve over time. We therefore want to track the proportion of social learners in the population, which we call \\(p_{SL}\\) (with \\(1-p_{SL}\\) being the proportion of individual learners). We assume these strategies are inherited (perhaps genetically, possibly culturally) from parent to offspring, and are affected by the fitness of the bearers of the strategies. Hence we need to specify fitness parameters. Each individual starts with a baseline fitness, \\(w\\). This is typically set at 1, to avoid tricky-to-handle negative fitnesses. Individuals who have behaviour that matches the environment receive a fitness boost of \\(+b\\). Individuals who have behaviour that does not match the environment receive a fitness penalty of \\(-b\\). Explicit in the above verbal outline is that social learning is less costly than individual learning. Therefore, individual learners receive a fitness cost of \\(-b*c\\), and social learners receive a fitness cost of \\(-b*s\\), where \\(c&gt;s\\). For simplicity, we can set \\(s=0\\) (social learning is free) and set \\(c&gt;0\\), so we only have to change one parameter. The fitness of each individual is then totted up based on the above, and the next generation is created. Each individual reproduces in proportion to the fitness of their strategy, relative to other strategies. We also assume some mutation during reproduction. With probability \\(\\mu\\), the new individual ‘mutates’ to the other learning strategy. Because we are interested here in how social learning evolves from individual learning, we start with a first generation entirely made up of individual learners. Social learning then appears from the second generation onwards via mutation. Finally, Rogers was interested in the effect of environmental change. Each generation, there is a probability \\(u\\) of the environment changing to a new state. In Rogers’ original model, the environment flipped between the same two states, back and forth. However, this is problematic when environmental change is very fast, because an individual with out-dated behaviour can receive a fitness benefit if the environment flips back to the previous state. Hence we assume that when environments change, they change to a new value never previously experienced by any individual. This is a complex model but let’s go step by step. First we create and initialise tibbles to store the output and the population of individuals, just like in previous chapters. The output here needs to be big enough to store data from \\(r_{max}\\) runs and \\(t_{max}\\) generations, like before. We then need to create NA placeholders for \\(p_{SL}\\) (the proportion of social learners) and \\(W\\) (the mean population fitness). The population tibble stores the characteristics of the individuals: learning strategy (‘individual’ or ‘social’), behaviour (initially all NA) and fitness (initially all NA). Finally, we initialise the environment \\(E\\) at zero, which will subsequently increment, meaning that the environment changes. library(tidyverse) N &lt;- 100 r_max &lt;- 1 t_max &lt;- 10 # Create the output tibble output &lt;- tibble(generation = rep(1:t_max, r_max), run = as.factor(rep(1:r_max, each = t_max)), p.SL = as.numeric(rep(NA, t_max * r_max)), W = as.numeric(rep(NA, t_max * r_max))) # Create the population tibble population &lt;- tibble(learning = rep(&quot;individual&quot;, N), behaviour = rep(NA, N), fitness = rep(NA, N)) # Initialise the environmental state to 0 E &lt;- 0 Now let’s go through each event that happens during a single generation. Later we will put it all inside a loop. It’s useful to write out the events that we need: Social learning Individual learning Calculate fitnesses Store population characteristics in output tibble Reproduction Potential environmental change First, social learning. The following code picks random individuals from the previous_population tibble (which we have yet to create, but will do later), to put into the social learner individuals in the current population tibble. This is similar to what we did in the previous chapters. It only does this if there is at least one social learner. As noted above, we start in the first generation with all individual learners and no social learners, so this will not be fulfilled until the second generation. For now, nothing happens. if (sum(population$learning == &quot;social&quot;) &gt; 0) { population$behaviour[population$learning == &quot;social&quot;] &lt;- sample(previous_population$behaviour, sum(population$learning == &quot;social&quot;), replace = TRUE) } The following code implements individual learning. This does apply to the first generation. We first create a vector of TRUE and FALSE values dependent on \\(p\\), the probability of individual learning resulting in a correct match with the environment. With this probability, individual learners have their behaviour set to the correct \\(E\\) value. Otherwise, they are given the incorrect behaviour \\(E-1\\). Note the use of the ! before learn_correct to give a match when this vector is FALSE (i.e. they do not learn the correct behaviour). learn_correct &lt;- sample(c(TRUE, FALSE), N, prob = c(p, 1 - p), replace = TRUE) population$behaviour[learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E population$behaviour[!learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E - 1 Now we obtain the fitnesses for each individual. First we give everyone the baseline fitness, \\(w\\). Then we add or subtract \\(b\\), based on whether the individual has the correct or incorrect behaviour. Finally we impose costs, which are different for social and individual learners. # Baseline fitness population$fitness &lt;- w # For individuals with behaviour matched to the environment, add b population$fitness[population$behaviour == E] &lt;- population$fitness[population$behaviour == E] + b # For individuals with behaviour not matched to the environment, subtract b population$fitness[population$behaviour != E] &lt;- population$fitness[population$behaviour != E] - b # Impose cost b*c on individual learners: population$fitness[population$learning == &quot;individual&quot;] &lt;- population$fitness[population$learning == &quot;individual&quot;] - b*c # Impose cost b*s (i.e. 0) on social learners: population$fitness[population$learning == &quot;social&quot;] &lt;- population$fitness[population$learning == &quot;social&quot;] - b*s The fourth stage is recording the resulting data into the output tibble. First we calculate \\(p_{SL}\\) as the number of social learners divided by the total population size. Then we calculate \\(W\\), the mean fitness in the entire population. All of these are done with the standard R mean command. output[output$generation == t &amp; output$run == r, ]$p_SL &lt;- mean(population$learning == &quot;social&quot;) output[output$generation == t &amp; output$run == r, ]$W &lt;- mean(population$fitness) The fifth stage is reproduction. Here we put the current population tibble into a new tibble, called previous_population, as we have done before. This acts as both a record to now calculate fitnesses, as well as a source of demonstrators for the social learning stage we covered above. After doing this, we reset the behaviour and fitness of the current population. We then over-write the learning strategies based on fitness. First we get fitness_IL, the fitness of individual learners relative to the fitness of the entire population (assuming there are any individual learners, otherwise we set this to zero). This then serves as the probability of setting new individuals as individual learners in the next generation. We use gain the function sample() to create mutation, denoting the probability of an individual mutating their learning strategy. Finally, we change the learning strategy of the ‘mutant’ individuals. Notice we need to create a temporary new tibble, previous_poulation2, to avoid to mutate twice the individuals that are changed from individual to social learning in the first mutation instruction. previous_population &lt;- population population$behaviour &lt;- NA population$fitness &lt;- NA # Relative fitness of individual learners (if there are any) if (sum(previous_population$learning == &quot;individual&quot;) &gt; 0) { fitness_IL &lt;- sum(previous_population$fitness[previous_population$learning == &quot;individual&quot;]) / sum(previous_population$fitness) } else { fitness_IL &lt;- 0 } # Create the new population population$learning &lt;- sample(c(&quot;individual&quot;, &quot;social&quot;), size = N, prob = c(fitness_IL, 1 - fitness_IL), replace = TRUE) # Also add mutation, chance of switching learning types mutation &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) # Store current population in a tibble to avoid mutating twice previous_population2 &lt;- population # If an individual is an individual learner plus mutation, then they&#39;re a social learner population$learning[previous_population2$learning == &quot;individual&quot; &amp; mutation] &lt;- &quot;social&quot; # If an individual is a social learner plus mutation, then they&#39;re an individual learner population$learning[previous_population2$learning == &quot;social&quot; &amp; mutation] &lt;- &quot;individual&quot; The final stage is the easiest. With probability \\(u\\), we increment the environmental state \\(E\\) by one. Otherwise, it stays as it is. To do this we pick a random number between 0 and 1 using the \\(runif\\) command, and if \\(u\\) exceeds this, we increment \\(E\\). if (runif(1) &lt; u) E &lt;- E + 1 That covers the six stages that occur in each generation. We can now put them all together into a loop tracking runs, and a loop tracking generations. We can also put all this inside a function. This should all be familiar from previous chapters. Almost all the code is taken from above, and we numbered the different stages (you can find the comments to the specific lines of codes in the chunks above). We also add a parameter check at the start, to make sure that we don’t get negative fitnesses. This uses the new function stop(), that tells R to terminate the execution of the function, and print on screen the message in the parenthesis. Another novelty is that we already set some of the parameters (\\(w\\), \\(b\\) and \\(s\\)) in the function call. In this way, the parameters are set to these default values if not specified when the function is called. The other parameters need to be instead specified. rogers_model &lt;- function(N, t_max, r_max, w = 1, b = 0.5, c, s = 0, mu, p, u) { # Check parameters to avoid negative fitnesses if (b * (1 + c) &gt; 1 || b * (1 + s) &gt; 1) { stop(&quot;Invalid parameter values: ensure b*(1+c) &lt; 1 and b*(1+s) &lt; 1&quot;) } # Create output tibble output &lt;- tibble(generation = rep(1:t_max, r_max), run = as.factor(rep(1:r_max, each = t_max)), p_SL = as.numeric(rep(NA, t_max * r_max)), W = as.numeric(rep(NA, t_max * r_max))) for (r in 1:r_max) { # Create a population of individuals population &lt;- tibble(learning = rep(&quot;individual&quot;, N), behaviour = rep(NA, N), fitness = rep(NA, N)) # Initialise the environment E &lt;- 0 for (t in 1:t_max) { # 1. Social learning if (sum(population$learning == &quot;social&quot;) &gt; 0) { population$behaviour[population$learning == &quot;social&quot;] &lt;- sample(previous_population$behaviour, sum(population$learning == &quot;social&quot;), replace = TRUE) } # 2. individual learning learn_correct &lt;- sample(c(TRUE, FALSE), N, prob = c(p, 1 - p), replace = TRUE) population$behaviour[learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E population$behaviour[!learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E - 1 # 3. Calculate fitnesses population$fitness &lt;- w population$fitness[population$behaviour == E] &lt;- population$fitness[population$behaviour == E] + b population$fitness[population$behaviour != E] &lt;- population$fitness[population$behaviour != E] - b population$fitness[population$learning == &quot;individual&quot;] &lt;- population$fitness[population$learning == &quot;individual&quot;] - b*c population$fitness[population$learning == &quot;social&quot;] &lt;- population$fitness[population$learning == &quot;social&quot;] - b*s # 4. Store population characteristics in output output[output$generation == t &amp; output$run == r, ]$p_SL &lt;- mean(population$learning == &quot;social&quot;) output[output$generation == t &amp; output$run == r, ]$W &lt;- mean(population$fitness) # 5. Reproduction previous_population &lt;- population population$behaviour &lt;- NA population$fitness &lt;- NA if (sum(previous_population$learning == &quot;individual&quot;) &gt; 0) { fitness_IL &lt;- sum(previous_population$fitness[previous_population$learning == &quot;individual&quot;]) / sum(previous_population$fitness) } else { fitness_IL &lt;- 0 } population$learning &lt;- sample(c(&quot;individual&quot;, &quot;social&quot;), size = N, prob = c(fitness_IL, 1 - fitness_IL), replace = TRUE) mutation &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) previous_population2 &lt;- population population$learning[previous_population2$learning == &quot;individual&quot; &amp; mutation] &lt;- &quot;social&quot; population$learning[previous_population2$learning == &quot;social&quot; &amp; mutation] &lt;- &quot;individual&quot; # 6. Potential environmental change if (runif(1) &lt; u) E &lt;- E + 1 } } # Export data from function output } Now we can run the simulation for \\(10\\) runs, and \\(200\\) generations, with a population of \\(1000\\) individuals. The other parameters we set are the cost associated to individual learning (c = 0.9); the mutation rate, i.e. the probability that an individual that inherit learning strategy (individual or social) will switch to the other (mu = 0.001); the accuracy of individual learning (p = 1); and, finally, the probability of environmental change (u = 0.2). We will later explore other values of these parameters, but feel free to change them and see what happens! data_model &lt;- rogers_model(N = 1000, t_max = 200, r_max = 10, c = 0.9, mu = 0.01, p = 1, u = 0.2) You can inspect the data_model tibble, but so much data is hard to make sense of. Let’s write a plotting function like in previous chapters. The only difference from our usual plot_multiple_runs() is that instead of plotting the frequency of traits, we want to visualise \\(p_{SL}\\), the frequency of social learners, so we plot_multiple_runs_p_SL &lt;- function(data_model) { ggplot(data = data_model, aes(y = p_SL, x = generation)) + geom_line(aes(colour = run)) + stat_summary(fun = mean, geom = &quot;line&quot;, size = 1) + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;proportion of social learners&quot;) } plot_multiple_runs_p_SL(data_model) Figure 8.1: On average the proportion of social learners fluctuates around \\(0.5\\) (black line). However, individual runs have a larger spread around this mean (overlapping colored runs). Here we can see that, for these parameter values, the mean proportion of social learners quickly goes to \\(0.5\\), but then remains fluctuating around this value. However, each run is quite erratic, with a large spread. More important for our understanding of Rogers’ paradox, however, is the mean fitness of the population, and how this compares with a population entirely composed of individual learners. Consequently, we need to plot the mean population fitness over time. This is W in the output of the rogers_model() function. The function below plots this, along with a dotted line denoting the fitness of an individual learner, which by extension will be the same as the mean fitness of a population entirely composed of individual learners. We do not need to extract this from the output of the simulation: the fitness of individual learners is fixed, known a-priori, and can be calculated knowing the values of some of the parameters of the simulation. There are a few new elements in the plotting functions. First, we want to pass to the function, together with the data_model tibble, some other information on the parameters of out simulations, so that that fitness line for individual learners can be draw. As in the main rogers_model() function, w and b are hard coded, and we need to specify c and p. Second, we use the function geom_hline(). This is another ggplot ‘geom’ that plots, as the name suggest, an horizontal line that intercept the y axis where indicated by yintervept, in our case the fitness of individual learners. Finally, we set the upper limit of the y axis to NA, which ggplot interprets as the limit from the range of the data. plot_W &lt;- function(data_model, w = 1, b = 0.5, c, p) { ggplot(data = data_model, aes(y = W, x = generation)) + geom_line(aes(color = run)) + stat_summary(fun = mean, geom = &quot;line&quot;, size = 1) + geom_hline(yintercept = w + b * (2 * p - c - 1), linetype = 2) + ylim(c(0, NA)) + theme_bw() + labs(y = &quot;mean population fitness&quot;) } plot_W(data_model, c = 0.9, p = 1) Figure 8.2: Populations with roughly 50% social learners have on average the same fitness (black line) as populations with only individual learners (dashed line). Even though populations with social learners sometimes exceed the average fitness of all-individual learner populations they also sometimes fall far below it. This is Rogers’ paradox. Even though social learning is less costly than individual learning (i.e. \\(s&lt;c\\)), our population of roughly \\(50\\%\\) social learners do not consistently exceed the dotted line that indicates the fitness of a population of individual learners. Social learning does not increase adaptation. This also runs counter to the common claim that culture - with social learning at its heart - has been a key driver of our species’ ecological success. The reason for this result is that social learning is frequency-dependent in a changing environment. Individual learners undergo costly individual learning and discover the correct behaviour, initially doing well. Social learners then copy that behaviour, but at lower cost. Social learners therefore then do better than, and outcompete, individual learners. But when the environment changes, the social learners do badly, because they are left copying outdated behaviour. Individual learners then do better, because they can detect the new environmental state. Individual learners increase in frequency, and the cycle continues. This is what the large oscillations of the single runs show. Analytically, it can be shown that they reach an equilibrium at which the frequency of social and individual learners is the same but, by definition, this equilibrium must have the same mean fitness as a population entirely composed of individual learners. Hence, the ‘paradox’. To explore this further, we can alter the parameters. First, we can reduce the cost of individual learning, from \\(c=0.9\\) to \\(c=0.4\\). data_model &lt;- rogers_model(N = 1000, t_max = 200, r_max = 10, c = 0.4, mu = 0.01, p = 1, u = 0.2) plot_multiple_runs_p_SL(data_model) Figure 8.3: There are fewer social learners in a population where the cost of individaul learning is lower. plot_W(data_model, c = 0.4, p = 1) Figure 8.4: The fitness of the mixed population remains equal to the fitness of individual learners in a population where the cost of individaul learning is lower. As we might expect, this reduces the proportion of social learners, by giving individual learners less of a penalty for doing their individual learning. Also as expected, the paradox remains. In fact it is even more obvious, given that there are many more individual learners. We can also reduce the accuracy of individual learning, reducing \\(p\\) from \\(1\\) to \\(0.7\\). data_model &lt;- rogers_model(N = 1000, t_max = 200, r_max = 10, c = 0.9, mu = 0.01, p = 0.7, u = 0.2) plot_multiple_runs_p_SL(data_model) Figure 8.5: When individual learning is accurate, there are more social learners in populations. plot_W(data_model, c = 0.9, p = 0.7) Figure 8.6: Even when individual learning is more accurate, the average fitness of mixed populations is close to the fitness of pure individual learners. Now there are a majority of social learners. Yet the paradox remains: the mostly social learners still do not really exceed the pure individual learning fitness line. If our explanation above is correct, then making the environment constant should remove the paradox. If the environment stays the same, then behaviour can never be outdated, and individual learners never regain the upper hand. Setting \\(u=0\\) shows this. data_model &lt;- rogers_model(N = 1000, t_max = 200, r_max = 10, c = 0.9, mu = 0.01, p = 1, u = 0) plot_multiple_runs_p_SL(data_model) Figure 8.7: When the environment is unchanging, social learners will outperform individual learners and take over in populations. plot_W(data_model, c = 0.9, p = 1) Figure 8.8: Their average fitness (black line) is now much higher than that of indiviudal learners (dashed line). Now the paradox has disappeared: social learners clearly outperform the individual learners after the latter have gone to the trouble of discovering the correct behaviour, and the social learners have higher mean fitness than the individual learning dotted line. (Notice also the oscillations within each run disappeared.) This is just as we would expect. Rogers’ paradox crucially depends on a changing environment. However, nature rarely provides a constant environment. Food sources change location, technology accumulates, languages diverge, and climates change. 8.2 Summary of the model Rogers’ model is obviously a gross simplification of reality. However, as discussed in earlier chapters, realism is often not the aim of modelling. Models - even simple and grossly unrealistic ones - force us to think through assumptions, and challenge verbal theorising. Rogers’ model is a good example of this. Even though it sounds reasonable that social learning should increase the mean fitness, or adaptation, of a population, in this simple model with these assumptions it does not. We saw one situation in which social learning does increase mean fitness: when environments do not change. This, however, is not very plausible. Environments always change. We therefore need to examine the other assumptions of Rogers’ model. We will do this in the next chapter. 8.3 Further reading An early example of the claim that social learning is adaptive because it reduces the costs of learning can be found in Boyd and Richerson (1985). Rogers (1988) then challenged this claim, as we have seen in this chapter. In the next chapter we will consider subsequent models that have examined ‘solutions’ to Rogers’ paradox. "],["rogers-paradox-a-solution.html", "Chapter 9 Rogers’ Paradox: A Solution 9.1 Modelling critical social learners 9.2 Summary of the model 9.3 Further reading", " Chapter 9 Rogers’ Paradox: A Solution In the previous chapter we saw how social learning does not increase the mean fitness of a population relative to a population entirely made up of individual learners, at least in a changing environment. This is colloquially known as Rogers’ paradox, after Alan Rogers’ model which originally showed this. It is a ‘paradox’ because it holds even though social learning is less costly than individual learning, and social learning is often argued to underpin our species’ ecological success. The paradox occurs because social learning is frequency dependent: when environments change, the success of social learning depends on there being individual learners around to copy. Otherwise social learners are left copying each others’ outdated behaviour. Several subsequent models have explored ‘solutions’ to Rogers’ paradox. These involve relaxing the obviously unrealistic assumptions. One of these is that individuals in the model come in one of two fixed types: social learners (who always learn socially), and individual learners (who always learn individually). This is obviously unrealistic. Most organisms that can learn individually can also learn socially, and the two capacities likely rely on the same underlying mechanisms (e.g. associative learning, see e.g. Heyes (2012)). 9.1 Modelling critical social learners To explore how a mixed learning strategy would compete with pure strategies (only social or only individual learning), Enquist, Eriksson, and Ghirlanda (2007) added another type of individual to Rogers’ model: a critical social learner. These individuals first try social learning, and if the result is unsatisfactory, they then try individual learning. The following function modifies the rogers_model() function from the last chapter to include critical learners. We need to change the code in a few places, but the modifications should be all easy to understand at this point. To start with, in the output tibble, we need to take track also of the number of individual learners (before they were simply the individuals that were not social learners) and of the number of the individuals adopting the new strategy, critical social learning. We have now two more variables for this: P_IL and P_CL. Next, we need to add a learning routine for critical learners. This involves repeating the social learning code originally written for the social learners. We then apply the individual learning code to those critical learners who copied the incorrect behaviour, i.e. if their behaviour is different from E (this makes them ‘unsatisfied’). To make it easier to follow, we now insert the fitness updates into the learning section. This is because only those critical learners who are unsatisfied will suffer the costs of individual learning. If we left it to afterwards, it’s easy to lose track of who is paying what fitness costs. Reproduction and mutation are changed to account for the three learning strategies. We now need to get the relative fitness of social and individual learners, and reproduce based on those fitnesses. Individuals left over become critical learners. We could calculate the relative fitness of critical learners, but it’s not really necessary given that the proportion of critical learners will always be 1 minus the proportion of social and individual learners. Similarly, mutation now needs to specify that individuals can mutate into either of the two other learning strategies. We assume this mutation is unbiased, and mutation is equally likely to result in the two other strategies. Notice the use of the function sample() when we set the learning strategies of the new population. So far we always used for binary choices, now we are using it with three elements (c(\"individual\", \"social\", \"critical\") and three probabilities (prob = c(fitness_IL, fitness_SL, 1 - (fitness_SL + fitness_IL))). library(tidyverse) rogers_model2 &lt;- function(N, t_max, r_max, w = 1, b = 0.5, c, s = 0, mu, p, u) { # Check parameters to avoid negative fitnesses if (b * (1 + c) &gt; 1 || b * (1 + s) &gt; 1) { stop(&quot;Invalid parameter values: ensure b*(1+c) &lt; 1 and b*(1+s) &lt; 1&quot;) } # Create output tibble output &lt;- tibble(generation = rep(1:t_max, r_max), run = as.factor(rep(1:r_max, each = t_max)), p_SL = as.numeric(rep(NA, t_max * r_max)), p_IL = as.numeric(rep(NA, t_max * r_max)), p_CL = as.numeric(rep(NA, t_max * r_max)), W = as.numeric(rep(NA, t_max * r_max))) for (r in 1:r_max) { # Create a population of individuals population &lt;- tibble(learning = rep(&quot;individual&quot;, N), behaviour = rep(NA, N), fitness = rep(NA, N)) # Initialise the environment E &lt;- 0 for (t in 1:t_max) { # Now we integrate fitnesses into the learning stage population$fitness &lt;- w # 1. Social learning if (sum(population$learning == &quot;social&quot;) &gt; 0) { # Subtract cost b*s from fitness of social learners population$fitness[population$learning == &quot;social&quot;] &lt;- population$fitness[population$learning == &quot;social&quot;] - b*s # Update behaviour population$behaviour[population$learning == &quot;social&quot;] &lt;- sample(previous_population$behaviour, sum(population$learning == &quot;social&quot;), replace = TRUE) } # 2. Individual learning # Subtract cost b*c from fitness of individual learners population$fitness[population$learning == &quot;individual&quot;] &lt;- population$fitness[population$learning == &quot;individual&quot;] - b*c # Update behaviour learn_correct &lt;- sample(c(TRUE, FALSE), N, prob = c(p, 1 - p), replace = TRUE) population$behaviour[learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E population$behaviour[!learn_correct &amp; population$learning == &quot;individual&quot;] &lt;- E - 1 # 3. Critical social learning if (sum(population$learning == &quot;critical&quot;) &gt; 0) { # Subtract b*s from fitness of socially learning critical learners population$fitness[population$learning == &quot;critical&quot;] &lt;- population$fitness[population$learning == &quot;critical&quot;] - b*s # First critical learners socially learn population$behaviour[population$learning == &quot;critical&quot;] &lt;- sample(previous_population$behaviour, sum(population$learning == &quot;critical&quot;), replace = TRUE) # Subtract b*c from fitness of individually learning critical learners population$fitness[population$learning == &quot;critical&quot; &amp; population$behaviour != E] &lt;- population$fitness[population$learning == &quot;critical&quot; &amp; population$behaviour != E] - b*c # Individual learning for those critical learners who did not copy correct behaviour population$behaviour[learn_correct &amp; population$learning == &quot;critical&quot; &amp; population$behaviour != E] &lt;- E population$behaviour[!learn_correct &amp; population$learning == &quot;critical&quot; &amp; population$behaviour != E] &lt;- E - 1 } # 4. Calculate fitnesses (now only need to do the b bonus or penalty) population$fitness[population$behaviour == E] &lt;- population$fitness[population$behaviour == E] + b population$fitness[population$behaviour != E] &lt;- population$fitness[population$behaviour != E] - b # 5. store population characteristics in output output[output$generation == t &amp; output$run == r, ]$p_SL &lt;- mean(population$learning == &quot;social&quot;) output[output$generation == t &amp; output$run == r, ]$p_IL &lt;- mean(population$learning == &quot;individual&quot;) output[output$generation == t &amp; output$run == r, ]$p_CL &lt;- mean(population$learning == &quot;critical&quot;) output[output$generation == t &amp; output$run == r, ]$W &lt;- mean(population$fitness) # 6. Reproduction previous_population &lt;- population population$behaviour &lt;- NA population$fitness &lt;- NA # Individual learners if (sum(previous_population$learning == &quot;individual&quot;) &gt; 0) { fitness_IL &lt;- sum(previous_population$fitness[previous_population$learning == &quot;individual&quot;]) / sum(previous_population$fitness) } else { fitness_IL &lt;- 0 } # Social learners if (sum(previous_population$learning == &quot;social&quot;) &gt; 0) { fitness_SL &lt;- sum(previous_population$fitness[previous_population$learning == &quot;social&quot;]) / sum(previous_population$fitness) } else { fitness_SL &lt;- 0 } population$learning &lt;- sample(c(&quot;individual&quot;, &quot;social&quot;, &quot;critical&quot;), size = N, prob = c(fitness_IL, fitness_SL, 1 - (fitness_SL + fitness_IL)), replace = TRUE) mutation &lt;- sample(c(TRUE, FALSE), N, prob = c(mu, 1 - mu), replace = TRUE) previous_population2 &lt;- population population$learning[mutation &amp; previous_population2$learning == &quot;individual&quot;] &lt;- sample(c(&quot;critical&quot;, &quot;social&quot;), sum(mutation &amp; previous_population2$learning == &quot;individual&quot;), prob = c(0.5, 0.5), replace = TRUE) population$learning[mutation &amp; previous_population2$learning == &quot;social&quot;] &lt;- sample(c(&quot;critical&quot;, &quot;individual&quot;), sum(mutation &amp; previous_population2$learning == &quot;social&quot;), prob = c(0.5, 0.5), replace = TRUE) population$learning[mutation &amp; previous_population2$learning == &quot;critical&quot;] &lt;- sample(c(&quot;individual&quot;, &quot;social&quot;), sum(mutation &amp; previous_population2$learning == &quot;critical&quot;), prob = c(0.5, 0.5), replace = TRUE) # 7. Potential environmental change if (runif(1) &lt; u) E &lt;- E + 1 } } # Export data from function output } Now we can run rogers_model2(), with the same parameter values as we initially ran rogers_model in the last chapter. data_model &lt;- rogers_model2(N = 1000, t_max = 200, r_max = 10, c = 0.9, mu = 0.01, p = 1, u = 0.2) As before, it’s difficult to see what’s happening unless we plot the data. The following function plot_prop() now plots the proportion of all three learning strategies. To do this we need to convert our wide data_model tibble (where each strategy is in a different column) to long format (where all proportions are in a single column, and a new column indexes the strategy). To do this we use pivot_longer(), similarly to what we did in Chapter 7. For visualisation purposes, we also rename the variables that keep track of the frequencies of the strategies (p_IL, p_SL, p_CL) with full words. For this plot, we only visualise the averages of all run with the stat_summary() function. plot_prop &lt;- function(data_model) { names(data_model)[3:5] &lt;- c(&quot;social&quot;, &quot;individual&quot;, &quot;critical&quot;) data_model_long &lt;- pivot_longer(data_model, -c(W, generation, run), names_to = &quot;learning&quot;, values_to = &quot;proportion&quot;) ggplot(data = data_model_long, aes(y = proportion, x = generation, colour = learning)) + stat_summary(fun = mean, geom = &quot;line&quot;, size = 1) + ylim(c(0, 1)) + theme_bw() + labs(y = &quot;proportion of learners&quot;) } plot_prop(data_model) Figure 9.1: Critical learners quickly spread in populations of social learners and indiviual learners. Here we can see that critical learners have a clear advantage over the other two learning strategies. Critical learners go virtually to fixation, barring mutation which prevents it from going to 100%. It pays off being a flexible, discerning learner who only learns individually when social learning does not work. What about Rogers’ paradox? Do critical learners exceed the mean fitness of a population entirely composed of individual learners? We can use the plot_W() function from the last chapter to find out: plot_W(data_model, c = 0.9, p = 1) Figure 9.2: The average fitness of critical learners (black line) clearly exceeds the average fitness of populations entirely comprised of individual learners. Yes: Even if there is still some noise, critical learners clearly outperform the dotted line indicating a hypothetical 100% individual learning population. Rogers’ paradox is solved. 9.2 Summary of the model Several ‘solutions’ have been demonstrated to Rogers’ paradox. Here we have explored one of them. Critical learners can flexibly employ both social and individual learning, and do this in an adaptive manner (i.e. only individually learn if social learning is unsuccessful). Critical learners outperform the pure individual learning and pure social learning strategies. They therefore solve Rogers’ paradox by exceeding the mean fitness of a population entirely composed of individual learning. One might complain that all this is obvious. Of course real organisms can learn both socially and individually, and adaptively employ both during their lifetimes. But hindsight is a wonderful thing. Before Rogers’ model, scholars did not fully recognise this, and simply argued that social learning is adaptive because it has lower costs than individual learning. We now know this argument is faulty. But it took a simple model to realise it, and to realise the reasons why. 9.3 Further reading There are several other solutions to Rogers’ paradox in the literature. Boyd and Richerson (1995) suggested individuals who initially learn individually and then if unsatisfied learn socially - the reverse of Enquist, Eriksson, and Ghirlanda (2007)‘s critical learners. Boyd and Richerson (1995) also suggested that if culture is cumulative, i.e. each generation builds on the beneficial modifications of the previous generations, then Rogers’ paradox is resolved. "],["demography.html", "Chapter 10 Demography 10.1 The Tasmania Case 10.2 Modelling the Tasmania Case 10.3 Calculating critical population sizes based on skill complexity 10.4 Summary of the model 10.5 Further readings", " Chapter 10 Demography In the previous chapters, we have looked at the transmission of information between individuals. We have seen that relatively simple mechanisms at the individual level can lead to population-level outcomes (e.g. the fixation of a rare cultural trait). We have also seen the importance of the characteristics of individuals (e.g. for success and prestige bias) in cultural processes. What we have not yet looked at is how the characteristics of the population may affect the outcome of cultural dynamics. In the following three chapters we will have a closer look at how population size (demography), population structure (social networks), and group structured populations (with migration) can influence cultural evolution. Why would demography matter to cultural evolution? As long as information is transmitted among individuals and between generations, the size of the population should not play a role. In theory, this statement is true but it relies on a crucial assumption: information transfer is not only complete (all information from the previous generation is transmitted to the next generation) but also error-free. However, from many lab experiments, we know that copying information is an error-prone process. In this chapter, we will look at how those errors affect information accumulation and how population size is augmenting this process. Several studies have looked at population effects. A well-known study is that by Joseph Henrich (2004). His model takes inspiration from the archaeological record of Tasmania, which shows a deterioration of some cultural traits and the persistence of others after Tasmania was cut-off from Australia at the end of the last ice age. Henrich develops a compelling analytical model to show that the same adaptive processes in cultural evolution can result in the improvement and retention of simple skills, but also the deterioration and even loss of complex skills. In the following section, we will take a closer look at this model. 10.1 The Tasmania Case The main idea of Henrich’s model is the following: information transmission from one generation to another (or from one individual to another, here it does not make a difference) has a random component (error rate) that will lead to most individuals failing to achieve the same skill level (denoted with \\(z\\)) as their cultural model, whereas a few will match and - even fewer - exceed that skill level. Imagine a group of students who try to acquire the skills to manufacture a spear. As imitation is imperfect, and memorizing and recalling action sequences is error-prone, some students will end up with a spear that is inferior to the one of their cultural model. A few individuals might achieve a similar or even higher skill level than their cultural model. To simulate imperfect imitation, Henrich’s model uses random values from a Gumbel distribution. This distribution is commonly used to model the distribution of extreme values. Its shape is controlled by two parameters: \\(\\mu\\) (location) and \\(\\sigma\\) (scale, sometimes also denoted as \\(\\beta\\)). Varying \\(\\mu\\) affects how tricky it is to acquire a given skill. If we subtract an amount \\(\\alpha\\) from \\(\\mu\\) we move the distribution to the left, and so fewer individuals will acquire a skill level that is larger than that of the cultural model. The larger \\(\\alpha\\) the harder it is to acquire a given skill. Varying \\(\\sigma\\) on the other hand affects the width of the distribution, and so whether imitators make very similar or systematic mistakes (small \\(\\sigma\\), narrow distribution) or whether errors are very different from each other (large \\(\\sigma\\), wide distribution). By using different values for \\(\\alpha\\) and \\(\\sigma\\), we can simulate different skill complexity and imperfect imitation. Intuitively, whether the average skill level of a population increases, persists, or decreases depends on how likely it is that some imitators will achieve a skill that exceeds the current cultural model. An illustration of Gumbel distributions for a complex and a simple skill is provided in the figure below. Figure 10.1: Shown are the probability distributions to acquire a specific skill level (\\(z\\), x-axis) for two different skills (a simple one that is easy to learn, and a compelx one that is harder to learn). Given that learning is error-prone more individuals will acquire a skill level that is lower than that of a cultural model (its level is indicated by the vertical dashed line) through imitation (left of the dashed line). A few individauls will achieve higher skill levels (right of the dashed line). For the complex skill the probability to be above the skill level of the cultural model is lower (smaller area under the curve) than for simple skills. Additional to the skill complexity, this also depends on how many individuals try to imitate the skill (how many values are drawn from the distribution). The smaller the pool of imitators, the fewer individuals will achieve a higher skill level and so, over time the skill level will decrease. Henrich provides an analytical model to explain how societies below a critical size (of cultural learners) might lose complex (or even simple) cultural skills over time. We will attempt to re-create his results using an individual-based model. 10.2 Modelling the Tasmania Case Our model looks like this: we simulate a population with \\(N\\) individuals. Each individual has a skill level \\(z\\). In each round, we determine the highest skill level in the population, \\(z_{\\text{max}}\\). We will then draw new values of \\(z\\) for each individual in the population. We draw these values from Gumbel distribution where the new mean is the same as the skill level of the most skilled individual minus \\(\\alpha\\), i.e. \\(\\mu = z_{\\text{max}} - \\alpha\\). To keep track of the simulation we will store the average proficiency \\(\\bar z\\) and the change in average proficiency \\(\\Delta \\bar z\\). We begin by loading the packages we will need. We will load the extraDistr package that gives us access to the rgumbel() function, which draws random values from a Gumbel distribution. We will have to define the shape of the distribution by providing two values, \\(\\mu\\) (location) and \\(\\sigma\\) (scale). Next, we set the some of the parameters that we need to run the simulation, that is, population size N and the number of simulation turns t_max. We also create some data structures to store the skill level z for each individual, and the reporting variables z_bar and z_delta_bar for average skill level and the change of the average skill level, respectively. We also set the parameters for the Gumbel distribution, here \\(\\sigma=3\\) and \\(\\alpha=5\\). Finally, we write down a very basic learning loop. The first step in this for() loop is to draw new values of z and store them in z_new. We then calculate the mean of the new skill levels and the change compared to the previous time step and finally update all values stored in z. library(tidyverse) library(extraDistr) # Set population size N &lt;- 1000 # Set number of simulation rounds t_max &lt;- 5000 # Draw random values from a uniform distribution to initialise z z &lt;- rep(1, N) # Set up variable to store average z z_bar &lt;- rep(NA, t_max) # Set up variable to store change in average z z_delta_bar &lt;- rep(NA, t_max) # Set parameters for Gumbel distribution sigma &lt;- 3 alpha &lt;- 5 for(r in 1:t_max){ # Calculate new z z_new &lt;- rgumbel(n = N, mu = max(z) - alpha, sigma = sigma) # Record average skill level z_bar[r] &lt;- mean(z_new) # Record average change in z z_delta_bar[r] &lt;- mean(z_new - z) # Update z z &lt;- z_new } Let us now plot the result of this simulation run. We first transform the output data structures in a tibble, so that can be conveniently be plotted with ggplot: z_delta_bar_val &lt;- tibble(x = 1:length(z_delta_bar), y = z_delta_bar) ggplot(z_delta_bar_val) + geom_line(aes(x = x, y = y)) + xlab(&quot;time&quot;) + ylab(&quot;change in z&quot;) + geom_hline(yintercept = mean(z_delta_bar_val$y), col = &quot;grey&quot;, linetype = 2) + theme_bw() Figure 10.2: While \\(\\bar z\\) is sometimes above and sometimes below \\(0\\), it is on average postive (dashed line), which indicated that the average skill level of the population increases. We find that \\(\\Delta \\bar z\\) quickly plateaus at about 17.5 (grey dashed line). As this is \\(&gt;0\\), on average the population will improve its skill over time. We can see that this is the case when we plot the average skill level over time: z_bar_val &lt;- tibble(x = 1:length(z_bar), y = z_bar) ggplot(z_bar_val) + geom_line(aes(x = x, y = y)) + xlab(&quot;time&quot;) + ylab(&quot;average skill-level&quot;) + theme_bw() Figure 10.3: For the given parameter (\\(\\alpha=5\\), \\(\\sigma=3\\)) the average skill-level increases continously. As in the previous chapters, we can now write a wrapper function that allows us to execute this model repeatedly and for different parameters. In the following, we will use a new function: lapply(). There is a series of apply functions in the R programming language that ‘apply’ a function to the elements of a given data object. Generally, these functions take an argument X (a vector, matrix, list, etc.) and then apply the function FUN to each element. We use lapply here on a vector 1:R_MAX, that is, a vector of the length of the number of repetitions that we want. What will happen is that lapply() will execute the function that we will provide exactly R_MAX times, and then return the result of each calculation in a list at the end. We could also use a for() loop just as we have done it in the previous chapters. However, the advantage of using the apply function over the loop is that each simulation can run independently from each other. That is because the second simulation does not have to wait for the first to be finished. In contrast, we could not use the apply function for the individual turns. Here the second simulation step does rely on the results of the first step. In this case, all simulation steps have to be calculated in sequence. Have a look at our demography_model() wrapper function: demography_model &lt;- function(T_MAX, N, ALPHA, SIGMA, R_MAX){ res &lt;- lapply(1:R_MAX, function(repetition){ z &lt;- rep(1, N) z_delta_bar &lt;- rep(NA, T_MAX) for(turn in 1:T_MAX){ z_new &lt;- rgumbel(n = N, mu = max(z) - ALPHA, sigma = SIGMA) z_delta_bar[turn] &lt;- mean(z_new - z) z &lt;- z_new } return(mean(z_delta_bar)) }) mean(unlist(res)) } We begin by initiating a function called demography_model() that is taking a set of parameters (note, it can be useful to capitalize arguments of a function to differentiate between those values that are calculated within a function (not capitalized) and those that have been provided with the function call). When we execute demography_model() it will first run an lapply() function for R_MAX number of rounds. The lapply() function will now run independent simulations which we have discussed above (i.e. setting up a population of individuals with skill level z, updating these values, and calculating the change in average skill level). The last step is to calculate the mean of z_delta_bar, i.e. the average of the change of the mean skill level. This is value is calculated for each repetition. lapply() returns all of these values in a list called res. As we are interested in the average change of the skill level across all repetitions, we first turn this list into a vector (using the unlist() function) and then calculate the mean. Let us now use the demography_model() function to run repeated simulations for different population sizes and different skill complexity. Here, we use the following parameters for the skill complexities: \\(\\alpha=7, \\sigma=1\\) (simple) and \\(\\alpha=9, \\sigma=1\\) (complex). We first define a variable, sizes, for the different population sizes. We are then again relying on the magic of the lapply() function. As above, the reason is that we can let simulations with different population sizes run independently from each other. Note that we provide sizes as our X argument, and demography_model() as the FUN function argument. Our demography_model() itself requires further arguments to run. In the lapply() function we can simply add them at the end. They will be directly handed over to demography_model() when we execute the lapply() function. In the last line of this chunk, we create a tibble that will hold the final results of the simulations for each skill and the different population sizes. sizes &lt;- c(2, seq(from = 100, to = 6100, by = 500)) simple_skill &lt;- lapply(X = sizes, FUN = demography_model, T_MAX = 200, ALPHA = 7, SIGMA = 1, R_MAX = 20) complex_skill &lt;- lapply(X=sizes, FUN=demography_model, T_MAX = 200, ALPHA = 9, SIGMA = 1, R_MAX = 20) data &lt;- tibble(N = rep(sizes, 2), z_delta_bar = c(unlist(simple_skill), unlist(complex_skill)), skill = rep(c(&quot;simple&quot;,&quot;complex&quot;), each = length(sizes))) Let us now plot the results: ggplot(data) + geom_line(aes(x = N, y = z_delta_bar, color = skill)) + xlab(&quot;effective population size&quot;) + ylab(&quot;change in average skill level, delta z bar&quot;) + geom_hline(yintercept = 0) + theme_bw() Figure 10.4: For a simple skill, effective populaton size (at which the skill can be just maintained in a population) is much smaller than the population that is required to maintain a complext skill. In Fig. @ref(fig:10.7) we can see that, for simple skills, the change in average skill level becomes positive (see where it intercepts the x-axis at \\(0\\)) at much smaller population sizes than the complex skill. This means a simple skill can be maintained by much smaller populations, whereas larger populations of imitators are required for complex skills. 10.3 Calculating critical population sizes based on skill complexity Henrich calls the minimum population size required to maintain a skill the critical population size, \\(N^\\star\\). How can we calculate \\(N^\\star\\) for different skill complexities? We could run simulations for many more population sizes and find the one where \\(\\Delta \\bar z\\) is closest to zero. Alternatively, here is a more elegant and less computationally intensive method, that we will use below. When we plot the previous results over logarithmic population size the resulting graphs are almost linear (see @ref(fig:10.8)). ggplot(data) + geom_line(aes(x = log(N), y = z_delta_bar, color=skill)) + xlab(&quot;log(effective population size)&quot;) + ylab(&quot;change in average skill level, delta z bar&quot;) + geom_hline(yintercept = 0) + theme_bw() Figure 10.5: The same results as in Fig. ?? but using log on population sizes. Thus, we could use a linear fit and then solve for \\(y = 0\\) to calculate \\(N^\\star\\). To do this we use the lm() function, which fits a linear model to the data that we provide. It takes a formula argument that identifies the ‘response variable’ (here z_delta_bar) and the ‘predictor variable’ (here log(N)). The two variables are separated with a ~ sign. To calculate a fit just for the data points of the simple skill simulation, we only hand over that part of the data where the skill column contains the term simple. As usual, we can inspect the results simply writing the variable name where we saved the results of the function, i.e. fit. # Create linear regression for the change in average skill level in response to population size fit &lt;- lm(formula = z_delta_bar ~ log(N), data = data[data$skill == &quot;simple&quot;,]) fit ## ## Call: ## lm(formula = z_delta_bar ~ log(N), data = data[data$skill == ## &quot;simple&quot;, ]) ## ## Coefficients: ## (Intercept) log(N) ## -6.4537 0.9983 The result is a list of information from the linear regression. Here, we are interested in the intercept with the y-axis and the inclination of the linear regression, both of which are displayed under Coefficients. We can calculate the point at which our regression line crosses the x-axis using the linear function \\(y = mx+b\\), setting \\(y=0\\) and then transforming, such that \\(x=-\\frac{b}{m}\\), where \\(b\\) is the y-axis intercept, and \\(m\\) is the inclination. # Solve for y = 0 by using the coefficients of the linear regression: b &lt;- fit$coefficients[1] m &lt;- fit$coefficients[2] N_star_simple &lt;- exp(-(b / m)) # And the same calculation for the complex skill fit &lt;- lm(formula = z_delta_bar ~ log(N), data = data[data$skill == &quot;complex&quot;,]) N_star_complex &lt;- exp(-(fit$coefficients[1] / fit$coefficients[2])) Note that we need to take the exponent (exp()) of the resulting value to revert the log function that we applied to the population size. We see that a simple skill with a low alpha to sigma ratio requires a minimum population size of about 642, whereas a much large population size is required to maintain a complex trait (about 4794). (You can visualise those results by writing N_star_simple and N_star_complex.) When you go back to Fig. (???)(fig:10.7) you can see that these points correspond with the graphs of the simple and complex skill crossing the x-axis. Let us now calculate the \\(N^\\star\\) values for different skill complexities and different population sizes. We first set up the parameter space using expand.grid(). This function essentially creates all possible combinations of input variables. In our case, we want all possible combinations of the different population sizes N and skill complexities, which we will vary using different values for \\(\\alpha\\). Therefore, executing this function will return a two column (for N and alpha) data structure, stored in simulations. We visualise the first lines with the function head(): # Run simulation for the following population sizes sizes &lt;- seq(from = 100, to = 6100, by = 500) # Run simulation for the following values of alpha alphas &lt;- seq(from = 4, to = 9, by = .5) simulations &lt;- expand.grid(N = sizes, alpha = alphas) head(simulations) ## N alpha ## 1 100 4 ## 2 600 4 ## 3 1100 4 ## 4 1600 4 ## 5 2100 4 ## 6 2600 4 Now we can run simulations for all combinations of population sizes and skill compexities: z_delta_bar &lt;- lapply(X = 1:nrow(simulations), FUN = function(s){ demography_model(T_MAX = 200, N = simulations[s, &quot;N&quot;], ALPHA = simulations[s, &quot;alpha&quot;], SIGMA = 1, R_MAX = 5) }) # Add results to population size and skill complexity data &lt;- cbind(simulations, z_delta_bar=unlist(z_delta_bar)) Finally, let us fit a linear regression to each skill complexity to determine the according critical population size \\(N^\\star\\): n_stars &lt;- lapply(X = unique(data$alpha), FUN = function(alpha){ # Only use the results with identical value for alpha subset &lt;- data[data$alpha == alpha,] # Fit regression fit &lt;- lm(formula = z_delta_bar ~ log(N), data = subset) # Solve for n star n_star &lt;- exp(solve(coef(fit)[-1], -coef(fit)[1])) return(n_star) }) # Combine all results in a single tibble results &lt;- tibble(n_star = unlist(n_stars), alpha = unique(data$alpha)) Now, we plot the critical population size as a function of the skill complexity \\(\\alpha\\) over \\(\\sigma\\). Note, that the x-axis label contains Greek letters. There are at least two ways to get ggplot to display Greek letters. The most simple way is to type the unicode equivalents of the symbols and letters. In our case this would look like this: xlab(\"\\u03b1 / \\u03C3\"). Alternatively, we can use the expression() function and type the names of the Greek letters (see below). This will be parsed and translated into the according letters: ggplot(results, aes(x = alpha, y = n_star)) + geom_line() + xlab(expression(alpha/sigma)) + ylab(&quot;critical populaton size, N*&quot;) + theme_bw() Figure 10.6: The critical population size, \\(N^\\star\\), increases exponentially as skill complexity increases. It is interesting to observe that the critical population size increases exponentially with skill complexity. This also suggests that, all being equal, very high skill levels will never be reached by finite population sizes. However, different ways of learning (e.g. teaching) could considerably decrease \\(\\alpha\\) and \\(\\sigma\\) over time and so allow high skill levels. 10.4 Summary of the model Similar to the model in the chapter on Rogers’ paradox, the present model is very simple and is making many simplifications. Nevertheless, it provides an intuitive understanding of how changes (up and down) in population size can affect the cultural repertoire of a population, and how it can be that simple skills thrive, while complex ones disappear. In the next chapter, we will discuss the importance of social networks, i.e. who can interact with whom. We will see that this will also have an effect (additional to the population size). In this chapter we also introduced several new R functions and programming styles. Most important, we used lapply() instead of the usual for loops to run multiple runs of the simulations. We used a different notation for function parameters (all capital letters) to distinguish them from the same values that are calculated within a function). At this point of the book, as long oyu know what you are doing, you may want to experiment with different options and choose the ones that works better for you! 10.5 Further readings Henrich (2004) provides a detailed analytical model of the simulation described in this chapter. Powell, Shennan, and Thomas (2009) is an extension to Henrich’s model that incorporates sub-populations with varying density. A criticism of Henrich’s Tasmanian model is Vaesen et al. (2016). Shennan (2001) is another modelling paper that suggests that innovations are far more successful in larger compared to smaller populations. Ghirlanda, Enquist, and Perc (2010) investigate the interplay between cultural innovations and cultural loss. Shennan (2015) provides a good overview of a variety of approaches and questions in studies of population effects in cultural evolution. "]]
